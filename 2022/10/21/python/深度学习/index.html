

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Kblayt">
  <meta name="keywords" content="">
  
    <meta name="description" content="深度学习的介绍目标  知道什么是深度学习 知道深度学习和机器学习的区别 能够说出深度学习的主要应用场景 知道深度学习的常见框架  1.深度学习的概念深度学习（deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行特征学习的算法。 2.机器学习和深度学习的区别2.1 区别1：特征提取 从特征提取的角度出发：  机器学习需要由人工的特征提取的过程 深度学习没有复杂的人工特">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习">
<meta property="og:url" content="https://kblayt.github.io/2022/10/21/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="深度学习的介绍目标  知道什么是深度学习 知道深度学习和机器学习的区别 能够说出深度学习的主要应用场景 知道深度学习的常见框架  1.深度学习的概念深度学习（deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行特征学习的算法。 2.机器学习和深度学习的区别2.1 区别1：特征提取 从特征提取的角度出发：  机器学习需要由人工的特征提取的过程 深度学习没有复杂的人工特">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230408144050339.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230408144401982.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131346791.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131357167.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131410871.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131422931.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131902590.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B01.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B02.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B03.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B04.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B05.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%901.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%902.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%903.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%904.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/torch%E7%89%88%E6%9C%AC.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A61.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A62.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E5%9B%BE.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97%E5%9B%BE.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97%E5%9B%BE2.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%97.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%972.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%973.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%974.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%922.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96%E5%99%A8%E6%96%B9%E6%B3%95.gif">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/dataset%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MNIST-dataset.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MNIST-dataset-5.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/softmax.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/word_embedding.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A0%B7%E6%9C%AC%E5%90%8D%E7%A7%B0.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB-data%E5%8A%A0%E8%BD%BD1.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%9B%BE.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%B1%95%E5%BC%80.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E7%9A%84RNN%E5%B1%95%E5%BC%80%E5%9B%BE.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%8A%9F%E8%83%BD.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM1.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM2.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM3.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM4.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%98%93%E7%8E%8B%E9%97%A8.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BE%93%E5%85%A5%E9%97%A8.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM-update.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BE%93%E5%87%BA%E9%97%A8.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GRU.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bidir_lstm.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/sigmoid%E5%AF%BC%E6%95%B0.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9B%BF%E6%8D%A2%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E6%A3%80%E7%B4%A2%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798501.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798502.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798503.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798504.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798505.jpeg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/app%E6%88%AA%E5%9B%BE.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chabot.png">
<meta property="og:image" content="https://kblayt.github.io/..%5Cimages%5C2.1%5CQAbot.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%85%B8.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E9%97%AE%E7%AD%94%E5%AF%B9.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/excel%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%99%BE%E5%BA%A6%E7%9B%B8%E4%BC%BC%E9%97%AE%E9%A2%98%E6%90%9C%E7%B4%A2.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%85%B8-168126759923612.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%871.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%872.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/fasttext%E5%8E%9F%E7%90%86.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bow%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Inked%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91%E6%9E%84%E9%80%A0%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81%20-%20%E5%89%AF%E6%9C%AC.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%B4%9F%E9%87%87%E6%A0%B7.png">
<meta property="og:image" content="https://kblayt.github.io/BaiduNetdiskDownload/%25E9%2598%25B6%25E6%25AE%25B59-%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BDNLP%25E9%25A1%25B9%25E7%259B%25AE/NLP%25E8%25AF%25BE%25E4%25BB%25B6%25E7%25BC%2596%25E5%2586%2599/markdown/doc/images/2.2/fasttext%25E8%25B4%259F%25E9%2587%2587%25E6%25A0%25B7.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%B4%9F%E9%87%87%E6%A0%B7%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/seq2seq.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Encoder.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/teacher%20forcing.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E9%BB%84%E9%B8%A1%E8%AF%AD%E6%96%99.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BE%AE%E5%8D%9A%E8%AF%AD%E6%96%991.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BE%AE%E5%8D%9A%E8%AF%AD%E6%96%992.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%90%8E.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%90%8E2.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention1.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention2.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention3.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention4.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention5.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/soft-hard%20attention.jpg">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Bahdanau.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Luong.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/scores.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention6.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/greedy%20search.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/greedy%20search.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/beamsearch.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/grad_clip.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pysparnn.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bm25.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bm25_2.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/deepqa.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AAAI.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/elu.png">
<meta property="og:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1.png">
<meta property="article:published_time" content="2022-10-21T08:39:30.000Z">
<meta property="article:modified_time" content="2023-04-12T02:50:21.128Z">
<meta property="article:author" content="Kblayt">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://kblayt.github.io/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230408144050339.png">
  
  
  
  <title>深度学习 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"kblayt.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深度学习"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-10-21 16:39" pubdate>
          2022年10月21日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          169k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          1409 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">深度学习</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="深度学习的介绍"><a href="#深度学习的介绍" class="headerlink" title="深度学习的介绍"></a>深度学习的介绍</h1><p><strong>目标</strong></p>
<ol>
<li>知道什么是深度学习</li>
<li>知道深度学习和机器学习的区别</li>
<li>能够说出深度学习的主要应用场景</li>
<li>知道深度学习的常见框架</li>
</ol>
<h2 id="1-深度学习的概念"><a href="#1-深度学习的概念" class="headerlink" title="1.深度学习的概念"></a>1.深度学习的概念</h2><p>深度学习（deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行特征学习的算法。</p>
<h2 id="2-机器学习和深度学习的区别"><a href="#2-机器学习和深度学习的区别" class="headerlink" title="2.机器学习和深度学习的区别"></a>2.机器学习和深度学习的区别</h2><h3 id="2-1-区别1：特征提取"><a href="#2-1-区别1：特征提取" class="headerlink" title="2.1 区别1：特征提取"></a>2.1 区别1：特征提取</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230408144050339.png" srcset="/img/loading.gif" lazyload alt="image-20230408144050339"></p>
<p>从特征提取的角度出发：</p>
<ol>
<li>机器学习需要由人工的特征提取的过程</li>
<li>深度学习没有复杂的人工特征提取过程，特征提取的过程可以通过深度神经网络自动完成</li>
</ol>
<h3 id="2-2-区别2：数据量"><a href="#2-2-区别2：数据量" class="headerlink" title="2.2 区别2：数据量"></a>2.2 区别2：数据量</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230408144401982.png" srcset="/img/loading.gif" lazyload alt="image-20230408144401982"></p>
<p>从数据量角度出发：</p>
<ol>
<li>深度学习需要大量的训练数据集，会有更高的效果</li>
<li>深度学习训练深度神经网路需要大量的算力，因为其中有更多的参数</li>
</ol>
<h2 id="3-深度学习的应用场景"><a href="#3-深度学习的应用场景" class="headerlink" title="3.深度学习的应用场景"></a>3.深度学习的应用场景</h2><ol>
<li>图像识别<ol>
<li>物体识别</li>
<li>场景识别</li>
<li>人脸检测跟踪</li>
<li>人脸身份认证</li>
</ol>
</li>
<li>自然语言处理技术<ol>
<li>机器翻译</li>
<li>文本识别</li>
<li>聊天对话</li>
</ol>
</li>
<li>语音技术<ol>
<li>语音识别</li>
</ol>
</li>
</ol>
<h2 id="4-常见的深度学习框架"><a href="#4-常见的深度学习框架" class="headerlink" title="4.常见的深度学习框架"></a>4.常见的深度学习框架</h2><p>目前企业中常见的深度学习框架有很多，TensorFlow，Caffe2，Keras，Theano，PyTorch，Chainer，DyNet，CNTK等等</p>
<p>其中TensorFlow喝Kears是google出品的，使用者很多，但是其语法灰色而且喝python的语法不尽相同，对于入门玩家而言上手难度较高</p>
<p>所有我们将学习facebook推出的PyTorch，PyTorch的使用和Python的语法相同，整个操作类似Numpy的操作，并且PyTorch使用的是动态计算，会让代码的调试变得更加简单</p>
<h1 id="神经网络的介绍"><a href="#神经网络的介绍" class="headerlink" title="神经网络的介绍"></a>神经网络的介绍</h1><p><strong>目标</strong></p>
<ol>
<li>知道神经网络的概念</li>
<li>知道什么是神经元</li>
<li>知道什么是单层神经网络</li>
<li>知道什么是感知机</li>
<li>知道什么是多层神经网络</li>
<li>知道激活函数是什么，有什么作用</li>
<li>理解神经网络的思想</li>
</ol>
<h2 id="1-人工神经网络的概念"><a href="#1-人工神经网络的概念" class="headerlink" title="1.人工神经网络的概念"></a>1.人工神经网络的概念</h2><p>人工神经网络（Artificial Neural Network），简称神经网络（Neural Network）或类神经网络，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型，用于对函数进行估计或近似</p>
<p>和其他机器学习方法一样，神经网络已经被用于解决各种各样的问题，例如机器视觉和语音识别。这戏问题都是很难被传统基于规则的编程所解决的。</p>
<h2 id="2-神经元的概念"><a href="#2-神经元的概念" class="headerlink" title="2.神经元的概念"></a>2.神经元的概念</h2><p>在生物神经网络中，每个神经元与其他神经元相连接，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位i而超过了一个“阈值”，那么它就会被激活，即“兴奋”起来，向其他神经元发送化学物质。</p>
<p>1943年，McCulloch和Pitts将上述情形抽象为上图所示的简单模型，这就是一直沿用至今的M-P神经元模型。把许多这样的神经元按一定的层次结构连接起来，就得到了神经网络。</p>
<p>一个简单的神经元如下图所示：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131346791.png" srcset="/img/loading.gif" lazyload alt="image-20230410131346791"></p>
<p>其中：</p>
<ol>
<li>α1，α2，… αn为各个输入的分量</li>
<li>ω1，ω2，… ωn为各个输入分量对应的权重参数</li>
<li>b为偏置</li>
<li>f为激活函数，常见的激活函数有tanh，sigmold，relu</li>
<li>t为神经元的输出</li>
</ol>
<p>使用数学公式表示就是：<br>$$<br>t &#x3D; f(W^TA+b)<br>$$<br>可见，一个神经元的功能是求得输入向量与权向量的内积后，经过一个非线性传递函数得到一个标量结果。</p>
<h2 id="3-单层神经网络"><a href="#3-单层神经网络" class="headerlink" title="3.单层神经网络"></a>3.单层神经网络</h2><p>是最基本的神经网络形式，由有限个神经元构成，所有数据有的输入向量都是同一个向量，由于每一个神经元都会产生一个标量结果，使用单层神经元的输出是一个向量，向量的维度等于神经元的数目。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131357167.png" srcset="/img/loading.gif" lazyload alt="image-20230410131357167"></p>
<h2 id="4-感知机"><a href="#4-感知机" class="headerlink" title="4.感知机"></a>4.感知机</h2><p>感知机由两层神经网络组成，输入层接收外界输入信号后传递给输出层（输出+1正例，-1反例），输出层都是M-P神经元</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131410871.png" srcset="/img/loading.gif" lazyload alt="image-20230410131410871"></p>
<p>其中ω0，ω1，ω2 … ωn都表示权重</p>
<p><strong>感知机的作用：</strong></p>
<p>把一个n维向量空间用一个超平面分割成两部分，给定一个输入向量，超平面可以判断出这个向量位于超平面的哪一边，得到输入时正类或者是反类，<strong>对应到2为空间就是一条直线把一个平面分为两个部分。</strong></p>
<h2 id="5-多层神经网络"><a href="#5-多层神经网络" class="headerlink" title="5.多层神经网络"></a>5.多层神经网络</h2><p>多层神经网络就是由单层神经网络进行叠加之后得到的，所以就形成了层的概念，常见的多层神经网络有如下结构：</p>
<ul>
<li>输入层（Input layer），众多神经元（Neuron）接受大量非线性输入消息，输入的消息称为输入向量。</li>
<li>输出层（Output layer），消息在神经元连接中传输，分析，权衡，形成输出结果。输出的消息称为输出向量。</li>
<li>隐藏层（Hidden layer），简称“隐层”，是出入层和输出层之间众多神经元和里按揭组成的各个层面。隐层可以有一层或多层。隐层的节点（神经元）数目不定，但数目越多神经网络的非线性越显著，从而神经网络的强健性（robustness）更显著。</li>
</ul>
<p>示意图如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131422931.png" srcset="/img/loading.gif" lazyload alt="image-20230410131422931"></p>
<p><strong>概念：全连接层</strong></p>
<p>全连接层：当前一层和前一层每个神经元相互里按揭，我们称当前这一层为全连接层。</p>
<p>思考：假设第N-1层有m个神经元，第N层有n个神经元，当第N层是全连接层的时候，则N-1和N层之间有多少个参数w，这些参数可以如何表示？</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/image-20230410131902590.png" srcset="/img/loading.gif" lazyload alt="image-20230410131902590"></p>
<p>从上图可以看出，所谓的全连接层就是在前一层的输出的基础上进行一次<br>$$<br>Y&#x3D;Wx+b<br>$$<br>的变化(不考虑激活函数的情况下就是一次线性变化，所谓线性变化就是平移(+b)和缩放的组合(*w))</p>
<h2 id="6-激活函数"><a href="#6-激活函数" class="headerlink" title="6. 激活函数"></a>6. 激活函数</h2><p>在前面的神经元的介绍过程中我们提到了激活函数，那么他到底是干什么的呢？</p>
<p>假设我们有这样一组数据，三角形和四边形，需要把他们分为两类</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B01.png" srcset="/img/loading.gif" lazyload></p>
<p>通过不带激活函数的感知机模型我们可以划出一条线, 把平面分割开</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B02.png" srcset="/img/loading.gif" lazyload></p>
<p>假设我们确定了参数w和b之后，那么带入需要预测的数据，如果y&gt;0,我们认为这个点在直线的右边，也就是正类（三角形），否则是在左边（四边形）</p>
<p>但是可以看出，三角形和四边形是没有办法通过直线分开的，那么这个时候该怎么办？</p>
<p>可以考虑使用多层神经网络来进行尝试，比如<strong>在前面的感知机模型中再增加一层</strong></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B03.png" srcset="/img/loading.gif" lazyload></p>
<p>对上图中的等式进行合并，我们可以得到：<br>$$<br>y &#x3D; (w_{1-11}w_{2-1}+\cdots)x_1+(w_{1-21}w_{2-1}+\cdots)x_2 + (w_{2-1}+\cdots)b_{1-1}<br>$$<br>上式括号中的都为w参数，和公式$y &#x3D; w_1x_1 + w_2x_2 +b$完全相同，依然只能够绘制出直线</p>
<p>所以可以发现，即使是多层神经网络，相比于前面的感知机，没有任何的改进。</p>
<p>但是如果此时，我们在前面感知机的基础上加上<strong>非线性的激活函数</strong>之后，输出的结果就不在是一条直线</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B04.png" srcset="/img/loading.gif" lazyload></p>
<p>如上图，右边是sigmoid函数，对感知机的结果，通过sigmoid函数进行处理</p>
<p>如果给定合适的参数w和b，就可以得到合适的曲线，能够完成对最开始问题的非线性分割</p>
<p>所以激活函数很重要的一个<strong>作用</strong>就是<strong>增加模型的非线性分割能力</strong></p>
<p>常见的激活函数有：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B05.jpg" srcset="/img/loading.gif" lazyload></p>
<p>看图可知：</p>
<ul>
<li>sigmoid 只会输出正数，以及靠近0的输出变化率最大</li>
<li>tanh和sigmoid不同的是，tanh输出可以是负数</li>
<li>Relu是输入只能大于0,如果你输入含有负数，Relu就不适合，如果你的输入是图片格式，Relu就挺常用的，因为图片的像素值作为输入时取值为[0,255]。</li>
</ul>
<p>激活函数的作用除了前面说的<strong>增加模型的非线性分割能力</strong>外，还有</p>
<ul>
<li><strong>提高模型鲁棒性</strong></li>
<li><strong>缓解梯度消失问题</strong></li>
<li><strong>加速模型收敛等</strong></li>
</ul>
<p>这些好处，大家后续会慢慢体会到，这里先知道就行</p>
<h2 id="7-神经网络示例"><a href="#7-神经网络示例" class="headerlink" title="7. 神经网络示例"></a>7. 神经网络示例</h2><p>一个男孩想要找一个女朋友，于是实现了一个<strong>女友判定机</strong>，随着年龄的增长，他的判定机也一直在变化</p>
<p>14岁的时候：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%901.png" srcset="/img/loading.gif" lazyload></p>
<p>无数次碰壁之后，男孩意识到追到女孩的可能性和颜值一样重要，于是修改了判定机：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%902.png" srcset="/img/loading.gif" lazyload></p>
<p>在15岁的时候终于找到呢女朋友，但是一顿时间后他发现有各种难以忍受的习惯，最终决定分手。一段空窗期中，他发现找女朋友很复杂，需要更多的条件才能够帮助他找到女朋友，于是在25岁的时候，他再次修改了判定机：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%903.png" srcset="/img/loading.gif" lazyload></p>
<p>在更新了女友判定机之后，问题又来了，很多指标不能够很好的量化，如何颜值，什么样的叫做颜值高，什么样的叫做性格好等等，为了解决这个问题，他又更新了判定机，最终得到<strong>超级女友判定机</strong></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BE%8B%E5%AD%904.png" srcset="/img/loading.gif" lazyload></p>
<p>上述的超级女友判定机其实就是神经网络，它能够接受基础的输入，通过隐藏层的线性的和非线性的变化最终的到输出</p>
<p>通过上面例子，希望大家能够理解深度学习的<strong>思想</strong>：</p>
<p>输出的最原始、最基本的数据，通过模型来进行特征工程，进行更加高级特征的学习，然后通过传入的数据来确定合适的参数，让模型去更好的拟合数据。</p>
<p>这个过程可以理解为盲人摸象，多个人一起摸，把摸到的结果乘上合适的权重，进行合适的变化，让他和目标值趋近一致。整个过程只需要输入基础的数据，程序自动寻找合适的参数。</p>
<h1 id="Pytorch的安装"><a href="#Pytorch的安装" class="headerlink" title="Pytorch的安装"></a>Pytorch的安装</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道如何安装pytorch</li>
</ol>
<h2 id="1-Pytorch的介绍"><a href="#1-Pytorch的介绍" class="headerlink" title="1. Pytorch的介绍"></a>1. Pytorch的介绍</h2><p>Pytorch是一款facebook发布的深度学习框架，由其易用性，友好性，深受广大用户青睐。</p>
<h2 id="2-Pytorch的版本"><a href="#2-Pytorch的版本" class="headerlink" title="2. Pytorch的版本"></a>2. Pytorch的版本</h2><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/torch%E7%89%88%E6%9C%AC.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="3-Pytorch的安装"><a href="#3-Pytorch的安装" class="headerlink" title="3. Pytorch的安装"></a>3. Pytorch的安装</h2><p>安装地址介绍：<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
<p>带GPU安装步骤：</p>
<p><code>conda install pytorch torchvision cudatoolkit=9.0 -c pytorch</code></p>
<p>不带GPU安装步骤</p>
<p><code>conda install pytorch-cpu torchvision-cpu -c pytorch</code></p>
<p>安装之后打开ipython</p>
<p>输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> torch<br>In [<span class="hljs-number">2</span>]: torch.__version__<br>Out[<span class="hljs-number">2</span>]: <span class="hljs-string">&#x27;1.0.1&#x27;</span><br></code></pre></td></tr></table></figure>

<p>注意：安装模块的时候安装的是<code>pytorch</code> ，但是在代码中都是使用<code>torch</code></p>
<h1 id="Pytorch的入门使用"><a href="#Pytorch的入门使用" class="headerlink" title="Pytorch的入门使用"></a>Pytorch的入门使用</h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道张量和Pytorch中的张量</li>
<li>知道pytorch中如何创建张量</li>
<li>知道pytorch中tensor的常见方法</li>
<li>知道pytorch中tensor的数据类型</li>
<li>知道pytorch中如何实现tensor在cpu和cuda中转化</li>
</ol>
<h2 id="1-张量Tensor"><a href="#1-张量Tensor" class="headerlink" title="1. 张量Tensor"></a>1. 张量Tensor</h2><p>张量是一个统称，其中包含很多类型：</p>
<ol>
<li>0阶张量：标量、常数，0-D Tensor</li>
<li>1阶张量：向量，1-D Tensor</li>
<li>2阶张量：矩阵，2-D Tensor</li>
<li>3阶张量</li>
<li>…</li>
<li>N阶张量</li>
</ol>
<h2 id="2-Pytorch中创建张量"><a href="#2-Pytorch中创建张量" class="headerlink" title="2. Pytorch中创建张量"></a>2. Pytorch中创建张量</h2><ol>
<li><p>使用python中的列表或者序列创建tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.tensor([[<span class="hljs-number">1.</span>, -<span class="hljs-number">1.</span>], [<span class="hljs-number">1.</span>, -<span class="hljs-number">1.</span>]])<br>tensor([[ <span class="hljs-number">1.0000</span>, -<span class="hljs-number">1.0000</span>],<br>        [ <span class="hljs-number">1.0000</span>, -<span class="hljs-number">1.0000</span>]])<br></code></pre></td></tr></table></figure>
</li>
<li><p>使用numpy中的数组创建tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.tensor(np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]]))<br>tensor([[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>]])<br></code></pre></td></tr></table></figure>
</li>
<li><p>使用torch的api创建tensor</p>
<ol>
<li><p><code>torch.empty(3,4)</code>创建3行4列的空的tensor，会用无用数据进行填充</p>
</li>
<li><p><code>torch.ones([3,4])</code> 创建3行4列的<strong>全为1</strong>的tensor</p>
</li>
<li><p><code>torch.zeros([3,4])</code>创建3行4列的<strong>全为0</strong>的tensor</p>
</li>
<li><p><code>torch.rand([3,4])</code> 创建3行4列的<strong>随机值</strong>的tensor，随机值的区间是<code>[0, 1)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>tensor([[ <span class="hljs-number">0.8237</span>,  <span class="hljs-number">0.5781</span>,  <span class="hljs-number">0.6879</span>],<br>[ <span class="hljs-number">0.3816</span>,  <span class="hljs-number">0.7249</span>,  <span class="hljs-number">0.0998</span>]])<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>torch.randint(low=0,high=10,size=[3,4])</code> 创建3行4列的<strong>随机整数</strong>的tensor，随机值的区间是<code>[low, high)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>torch.randint(<span class="hljs-number">3</span>, <span class="hljs-number">10</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>tensor([[<span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>	[<span class="hljs-number">6</span>, <span class="hljs-number">7</span>]])<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>torch.randn([3,4])</code> 创建3行4列的<strong>随机数</strong>的tensor，随机值的分布式均值为0，方差为1</p>
</li>
</ol>
</li>
</ol>
<h2 id="3-Pytorch中tensor的常用方法"><a href="#3-Pytorch中tensor的常用方法" class="headerlink" title="3. Pytorch中tensor的常用方法"></a>3. Pytorch中tensor的常用方法</h2><ol>
<li><p>获取tensor中的数据(当tensor中只有一个元素可用)：<code>tensor.item()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">10</span>]: a = torch.tensor(np.arange(<span class="hljs-number">1</span>))<br><br>In [<span class="hljs-number">11</span>]: a<br>Out[<span class="hljs-number">11</span>]: tensor([<span class="hljs-number">0</span>])<br><br>In [<span class="hljs-number">12</span>]: a.item()<br>Out[<span class="hljs-number">12</span>]: <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
</li>
<li><p>转化为numpy数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">55</span>]: z.numpy()<br>Out[<span class="hljs-number">55</span>]:<br>array([[-<span class="hljs-number">2.5871205</span>],<br>       [ <span class="hljs-number">7.3690367</span>],<br>       [-<span class="hljs-number">2.4918075</span>]], dtype=float32)<br></code></pre></td></tr></table></figure>


</li>
<li><p>获取形状：<code>tensor.size()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">72</span>]: x<br>Out[<span class="hljs-number">72</span>]:<br>tensor([[    <span class="hljs-number">1</span>,     <span class="hljs-number">2</span>],<br>        [    <span class="hljs-number">3</span>,     <span class="hljs-number">4</span>],<br>        [    <span class="hljs-number">5</span>,    <span class="hljs-number">10</span>]], dtype=torch.int32)<br><br>In [<span class="hljs-number">73</span>]: x.size()<br>Out[<span class="hljs-number">73</span>]: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure>


</li>
<li><p>形状改变：<code>tensor.view((3,4))</code>。类似numpy中的reshape，是一种浅拷贝，仅仅是形状发生改变</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">76</span>]: x.view(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br>Out[<span class="hljs-number">76</span>]:<br>tensor([[    <span class="hljs-number">1</span>,     <span class="hljs-number">2</span>,     <span class="hljs-number">3</span>],<br>        [    <span class="hljs-number">4</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">10</span>]], dtype=torch.int32)<br></code></pre></td></tr></table></figure>


</li>
<li><p>获取阶数：<code>tensor.dim()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">77</span>]: x.dim()<br>Out[<span class="hljs-number">77</span>]: <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>


</li>
<li><p>获取最大值：<code>tensor.max()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">78</span>]: x.<span class="hljs-built_in">max</span>()<br>Out[<span class="hljs-number">78</span>]: tensor(<span class="hljs-number">10</span>, dtype=torch.int32)<br></code></pre></td></tr></table></figure>


</li>
<li><p>转置：<code>tensor.t()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">79</span>]: x.t()<br>Out[<span class="hljs-number">79</span>]:<br>tensor([[    <span class="hljs-number">1</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">5</span>],<br>        [    <span class="hljs-number">2</span>,     <span class="hljs-number">4</span>, 	  <span class="hljs-number">10</span>]], dtype=torch.int32)<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>tensor[1,3]</code>  获取tensor中第一行第三列的值</p>
</li>
<li><p><code>tensor[1,3]=100</code> 对tensor中第一行第三列的位置进行赋值100</p>
</li>
<li><p>tensor的切片</p>
</li>
</ol>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">101</span>]: x<br>Out[<span class="hljs-number">101</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br><br>In [<span class="hljs-number">102</span>]: x[:,<span class="hljs-number">1</span>]<br>Out[<span class="hljs-number">102</span>]: tensor([<span class="hljs-number">1.9439</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.4858</span>])<br></code></pre></td></tr></table></figure>

<p>​    </p>
<h2 id="4-tensor的数据类型"><a href="#4-tensor的数据类型" class="headerlink" title="4. tensor的数据类型"></a>4. tensor的数据类型</h2><p>tensor中的数据类型非常多，常见类型如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" srcset="/img/loading.gif" lazyload></p>
<p>上图中的Tensor types表示这种type的tensor是其实例</p>
<ol>
<li><p>获取tensor的数据类型:<code>tensor.dtype</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">80</span>]: x.dtype<br>Out[<span class="hljs-number">80</span>]: torch.int32<br></code></pre></td></tr></table></figure>
</li>
<li><p>创建数据的时候指定类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">88</span>]: torch.ones([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],dtype=torch.float32)<br>Out[<span class="hljs-number">88</span>]:<br>tensor([[<span class="hljs-number">9.1167e+18</span>, <span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">7.8796e+15</span>],<br>        [<span class="hljs-number">8.3097e-43</span>, <span class="hljs-number">0.0000e+00</span>, -<span class="hljs-number">0.0000e+00</span>]])<br></code></pre></td></tr></table></figure>


</li>
<li><p>类型的修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">17</span>]: a<br>Out[<span class="hljs-number">17</span>]: tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], dtype=torch.int32)<br><br>In [<span class="hljs-number">18</span>]: a.<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">float</span>)<br>Out[<span class="hljs-number">18</span>]: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>])<br><br>In [<span class="hljs-number">19</span>]: a.double()<br>Out[<span class="hljs-number">19</span>]: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>], dtype=torch.float64)<br></code></pre></td></tr></table></figure></li>
</ol>
<h2 id="5-tensor的其他操作"><a href="#5-tensor的其他操作" class="headerlink" title="5. tensor的其他操作"></a>5. tensor的其他操作</h2><ol>
<li><p>tensor和tensor相加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">94</span>]: x = x.new_ones(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, dtype=torch.<span class="hljs-built_in">float</span>)<br><br>In [<span class="hljs-number">95</span>]: y = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)<br><br>In [<span class="hljs-number">96</span>]: x+y<br>Out[<span class="hljs-number">96</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br>In [<span class="hljs-number">98</span>]: torch.add(x,y)<br>Out[<span class="hljs-number">98</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br>In [<span class="hljs-number">99</span>]: x.add(y)<br>Out[<span class="hljs-number">99</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br>In [<span class="hljs-number">100</span>]: x.add_(y)  <span class="hljs-comment">#带下划线的方法会对x进行就地修改</span><br>Out[<span class="hljs-number">100</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br><br>In [<span class="hljs-number">101</span>]: x <span class="hljs-comment">#x发生改变</span><br>Out[<span class="hljs-number">101</span>]:<br>tensor([[<span class="hljs-number">1.6437</span>, <span class="hljs-number">1.9439</span>, <span class="hljs-number">1.5393</span>],<br>        [<span class="hljs-number">1.3491</span>, <span class="hljs-number">1.9575</span>, <span class="hljs-number">1.0552</span>],<br>        [<span class="hljs-number">1.5106</span>, <span class="hljs-number">1.0123</span>, <span class="hljs-number">1.0961</span>],<br>        [<span class="hljs-number">1.4382</span>, <span class="hljs-number">1.5939</span>, <span class="hljs-number">1.5012</span>],<br>        [<span class="hljs-number">1.5267</span>, <span class="hljs-number">1.4858</span>, <span class="hljs-number">1.4007</span>]])<br></code></pre></td></tr></table></figure>

<p>注意：带下划线的方法（比如:<code>add_</code>)会对tensor进行就地修改</p>
</li>
<li><p>tensor和数字操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">97</span>]: x +<span class="hljs-number">10</span><br>Out[<span class="hljs-number">97</span>]:<br>tensor([[<span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>],<br>        [<span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>],<br>        [<span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>],<br>        [<span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>],<br>        [<span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">11.</span>]])<br></code></pre></td></tr></table></figure>
</li>
<li><p>CUDA中的tensor</p>
<p>CUDA（Compute Unified Device Architecture），是NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。</p>
<p><code>torch.cuda</code>这个模块增加了对CUDA tensor的支持，能够在cpu和gpu上使用相同的方法操作tensor</p>
<p>通过<code>.to</code>方法能够把一个tensor转移到另外一个设备(比如从CPU转到GPU)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>)          <span class="hljs-comment"># cuda device对象</span><br>    y = torch.ones_like(x, device=device)  <span class="hljs-comment"># 创建一个在cuda上的tensor</span><br>    x = x.to(device)                       <span class="hljs-comment"># 使用方法把x转为cuda 的tensor</span><br>    z = x + y<br>    <span class="hljs-built_in">print</span>(z)<br>    <span class="hljs-built_in">print</span>(z.to(<span class="hljs-string">&quot;cpu&quot;</span>, torch.double))       <span class="hljs-comment"># .to方法也能够同时设置类型</span><br>    <br>&gt;&gt;tensor([<span class="hljs-number">1.9806</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br>&gt;&gt;tensor([<span class="hljs-number">1.9806</span>], dtype=torch.float64)<br></code></pre></td></tr></table></figure></li>
</ol>
<p>通过前面的学习，可以发现torch的各种操作几乎和numpy一样</p>
<h1 id="梯度下降和反向传播"><a href="#梯度下降和反向传播" class="headerlink" title="梯度下降和反向传播"></a>梯度下降和反向传播</h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道什么是梯度下降</li>
<li>知道什么是反向传播</li>
</ol>
<h2 id="1-梯度是什么"><a href="#1-梯度是什么" class="headerlink" title="1. 梯度是什么?"></a>1. 梯度是什么?</h2><p>梯度：是一个向量，导数+变化最快的方向(学习的前进方向)</p>
<p>回顾机器学习</p>
<p>收集数据$x$ ，构建机器学习模型$f$，得到$f(x,w) &#x3D; Y_{predict}$</p>
<p>判断模型好坏的方法：<br>$$<br>\begin{align*}<br>loss &amp; &#x3D; (Y_{predict}-Y_{true})^2  &amp;(回归损失) \<br>loss &amp; &#x3D; Y_{true} \cdot log(Y_{predict}) &amp;(分类损失)<br>\end{align*}<br>$$</p>
<p>目标：通过调整(学习)参数$w$，尽可能的降低$loss$，那么我们该如何调整$w$呢？</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A61.png" srcset="/img/loading.gif" lazyload></p>
<p>随机选择一个起始点$w_0$,通过调整$w_0$，让loss函数取到最小值</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A62.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>$w$的更新方法</strong>：</p>
<ol>
<li>计算$w$的梯度（导数）</li>
</ol>
<p>$$<br>\begin{align*}<br>\nabla w &#x3D; \frac{f(w+0.000001)-f(w-0.000001)}{2*0.000001} </p>
<p>\end{align*}<br>$$</p>
<ol start="2">
<li>更新$w$<br>$$<br>w &#x3D; w - \alpha \nabla w<br>$$</li>
</ol>
<p>其中：</p>
<ol>
<li>$\nabla w &lt;0 $ ,意味着w将增大</li>
<li>$\nabla w &gt;0 $ ,意味着w将减小</li>
</ol>
<p>总结：梯度就是多元函数参数的变化趋势（参数学习的方向），只有一个自变量时称为<strong>导数</strong></p>
<h2 id="2-偏导的计算"><a href="#2-偏导的计算" class="headerlink" title="2. 偏导的计算"></a>2. 偏导的计算</h2><h3 id="2-1-常见的导数计算"><a href="#2-1-常见的导数计算" class="headerlink" title="2.1 常见的导数计算"></a>2.1 常见的导数计算</h3><ul>
<li><p>多项式求导数：$f(x) &#x3D; x^5$ ,$f^{‘}(x) &#x3D; 5x^{(5-1)}$</p>
</li>
<li><p>基本运算求导：$f(x) &#x3D; xy$ ，$f^{‘}(x) &#x3D; y$</p>
</li>
<li><p>指数求导：$f(x) &#x3D; 5e^x$ ，$f^{‘}(x) &#x3D; 5e^x$</p>
</li>
<li><p>对数求导：$f(x) &#x3D; 5lnx$ ，$f^{‘}(x) &#x3D; \frac{5}{x}$，ln 表示log以e为底的对数</p>
</li>
<li><p>导数的微分形式：<br>$$<br>\begin{align*}<br>&amp; f^{‘}(x) &#x3D; &amp; \frac{d f(x)}{dx} \<br>&amp; 牛顿         &amp;莱布尼兹<br>\end{align*}<br>$$</p>
</li>
</ul>
<p>那么：如何求$f(x) &#x3D; (1+e^{-x})^{-1}$ 的导数呢？那就可以使用</p>
<p>$f(x) &#x3D; (1+e^{-x})^{-1}$         &#x3D;&#x3D;&gt;   $f(a) &#x3D; a^{-1},a(b) &#x3D; (1+b),b(c) &#x3D; e^c,c(x) &#x3D; -x$</p>
<p>则有：<br>$$<br>\begin{align*}<br>\frac{d f(x)}{dx} &amp; &#x3D; \frac{df}{da} \times \frac{da}{db} \times \frac{db}{dc}\times \frac{dc}{dx} \<br>&amp;&#x3D;-a^{-2} \times 1\times e^c \times (-1) \<br>&amp;&#x3D; -(1+e^{-x})^{-2} \times e^{-x} \times (-1) \<br>&amp;&#x3D; e^{-x}(1+e^{-x})^{-2}<br>\end{align*}<br>$$</p>
<h3 id="2-2-多元函数求偏导"><a href="#2-2-多元函数求偏导" class="headerlink" title="2.2 多元函数求偏导"></a>2.2 多元函数求偏导</h3><p>一元函数，即有一个自变量。类似$f(x)$</p>
<p>多元函数，即有多个自变量。类似$f(x,y,z),三个自变量x,y,z$</p>
<p>多元函数求偏导过程中：<strong>对某一个自变量求导，其他自变量当做常量即可</strong></p>
<p>例1：<br>$$<br>\begin{align*}<br> &amp;f(x,y,z) &amp;&#x3D; &amp;ax+by+cz \<br>&amp;\frac{df(x,y,z)}{dx} &amp;&#x3D; &amp;a \<br>&amp;\frac{df(x,y,z)}{dy} &amp;&#x3D; &amp;b \<br>&amp;\frac{df(x,y,z)}{dz} &amp;&#x3D; &amp;c<br>\end{align*}<br>$$</p>
<p>例2：<br>$$<br>\begin{align*}<br> &amp;f(x,y) &amp;&#x3D; &amp;xy \<br>&amp;\frac{df(x,y)}{dx} &amp;&#x3D; &amp; y\<br>&amp;\frac{df(x,y)}{dy} &amp;&#x3D; &amp;x<br>\end{align*}<br>$$<br>例3：<br>$$<br>\begin{align*}<br> &amp;f(x,w) &amp;&#x3D; &amp;(y-xw)^2 \<br>&amp;\frac{df(x,w)}{dx} &amp;&#x3D; &amp; -2w(y-xw)\<br>&amp;\frac{df(x,w)}{dw} &amp;&#x3D; &amp; -2x(y-xw)<br>\end{align*}<br>$$<br><strong>练习：</strong></p>
<p>已知$J(a,b,c) &#x3D; 3(a+bc),令u&#x3D;a+v,v &#x3D; bc$,求a，b，c各自的偏导数。<br>$$<br>\begin{align*}<br> 令:&amp; J(a,b,c) &#x3D; 3u\<br> \frac{dJ}{da} &amp;&#x3D;\frac{dJ}{du} \times \frac{du}{da} &#x3D; 3\times1 \<br> \frac{dJ}{db} &amp;&#x3D;\frac{dJ}{du} \times \frac{du}{dv} \times \frac{dv}{db} &#x3D; 3\times1\times c \<br> \frac{dJ}{dc} &amp;&#x3D;\frac{dJ}{du} \times \frac{du}{dv} \times \frac{dv}{dc} &#x3D; 3\times1\times b \<br>\end{align*}<br>$$</p>
<h2 id="3-反向传播算法"><a href="#3-反向传播算法" class="headerlink" title="3. 反向传播算法"></a>3. 反向传播算法</h2><h3 id="3-1-计算图和反向传播"><a href="#3-1-计算图和反向传播" class="headerlink" title="3.1 计算图和反向传播"></a>3.1 计算图和反向传播</h3><p>计算图：通过图的方式来描述函数的图形</p>
<p>在上面的练习中，$J(a,b,c) &#x3D; 3(a+bc),令u&#x3D;a+v,v &#x3D; bc$,把它绘制成计算图可以表示为：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E5%9B%BE.png" srcset="/img/loading.gif" lazyload></p>
<p>绘制成为计算图之后，可以清楚的看到向前计算的过程</p>
<p>之后，对每个节点求偏导可有：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6.png" srcset="/img/loading.gif" lazyload></p>
<p>那么反向传播的过程就是一个上图的从右往左的过程，自变量$a,b,c$各自的偏导就是连线上的梯度的乘积：<br>$$<br>\begin{align*}<br>\frac{dJ}{da} &amp;&#x3D; 3 \times 1 \<br>\frac{dJ}{db} &amp;&#x3D; 3 \times 1 \times c \<br>\frac{dJ}{dc} &amp;&#x3D; 3 \times 1 \times b<br>\end{align*}<br>$$</p>
<h3 id="3-2-神经网络中的反向传播"><a href="#3-2-神经网络中的反向传播" class="headerlink" title="3.2 神经网络中的反向传播"></a>3.2 神经网络中的反向传播</h3><h4 id="3-2-1-神经网络的示意图"><a href="#3-2-1-神经网络的示意图" class="headerlink" title="3.2.1 神经网络的示意图"></a>3.2.1 神经网络的示意图</h4><p>$w1,w2,….wn$表示网络第n层权重</p>
<p>$w_n[i,j]$表示第n层第i个神经元，连接到第n+1层第j个神经元的权重。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97%E5%9B%BE.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="3-2-2-神经网络的计算图"><a href="#3-2-2-神经网络的计算图" class="headerlink" title="3.2.2 神经网络的计算图"></a>3.2.2 神经网络的计算图</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97%E5%9B%BE2.png" srcset="/img/loading.gif" lazyload></p>
<p>其中：</p>
<ol>
<li>$\nabla out$是根据损失函数对预测值进行求导得到的结果</li>
<li>f函数可以理解为激活函数</li>
</ol>
<p><strong>问题：</strong>那么此时$w_1[1,2]$的偏导该如何求解呢？</p>
<p>通过观察，发现从$out$ 到$w_1[1,2]$的来连接线有两条</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%97.png" srcset="/img/loading.gif" lazyload></p>
<p>结果如下：<br>$$<br>\frac{dout}{dW_1[1,2]} &#x3D; x1<em>f^{‘}(a2)</em>(W_2[2,1]*f^{‘}(b1)*W_3[1,1]*\nabla out +W_2[2,2]*f^{‘}(b2)*W_3[2,1]*\nabla out)<br>$$<br>公式分为两部分：</p>
<ol>
<li>括号外：左边红线部分</li>
<li>括号内<ol>
<li>加号左边：右边红线部分</li>
<li>加号右边：蓝线部分</li>
</ol>
</li>
</ol>
<p>但是这样做，当模型很大的时候，计算量非常大</p>
<p>所以反向传播的思想就是对其中的某一个参数单独求梯度，之后更新，如下图所示：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%972.png" srcset="/img/loading.gif" lazyload></p>
<p>计算过程如下<br>$$<br>\begin{align*}<br>&amp;\nabla W_3[1,1] &#x3D; f(b_1)*\nabla out  &amp; （计算W_3[1,1]梯度）\<br>&amp;\nabla W_3[2,1] &#x3D; f(b_2)*\nabla out  &amp; （计算W_3[2,1]梯度）\<br>\<br>&amp;\nabla b_1&#x3D; f^{‘}(b_1)*W_3[1,1]*\nabla out  &amp; （计算W_3[2,1]梯度）\<br>&amp;\nabla b_2&#x3D; f^{‘}(b_2)*W_3[2,1]*\nabla out  &amp; （计算W_3[2,1]梯度）\</p>
<p>\end{align*}<br>$$<br>更新参数之后，继续反向传播</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%973.png" srcset="/img/loading.gif" lazyload></p>
<p>计算过程如下：<br>$$<br>\begin{align*}<br>&amp;\nabla W_2[1,2] &#x3D; f(a_1)* \nabla b_2 \<br>&amp;\nabla a_2 &#x3D; f^{‘}(a_2)<em>(w_2[2,1]\nabla b_1 +W_2[2,2] \nabla b_2)<br>\end{align</em>}<br>$$<br>继续反向传播</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%81%8F%E5%AF%BC%E7%9A%84%E8%AE%A1%E7%AE%974.png" srcset="/img/loading.gif" lazyload></p>
<p>计算过程如下：<br>$$<br>\begin{align*}<br>&amp;▽W_1[1,2]&#x3D; x_1*▽a_2\<br>&amp;▽x_1&#x3D; (W_1[1,1]*▽a_1+w_1[1,2]*▽a_2)<em>x_1’<br>\end{align</em>}<br>$$</p>
<p><strong>通用的描述如下</strong><br>$$<br>\nabla w^{l}<em>{i,j} &#x3D; f(a^l_i)* \nabla a^{i+1}</em>{j}\<br>\nabla a^{l}<em>i &#x3D; f’(a^l_i)*(\sum</em>{j&#x3D;1}^{m}w_{i,j}*\nabla a_j^{l+1})<br>$$</p>
<h1 id="Pytorch完成线性回归"><a href="#Pytorch完成线性回归" class="headerlink" title="Pytorch完成线性回归"></a>Pytorch完成线性回归</h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><ol>
<li><p>知道<code>requires_grad</code>的作用</p>
</li>
<li><p>知道如何使用<code>backward</code></p>
</li>
<li><p>知道如何手动完成线性回归</p>
</li>
</ol>
<h2 id="1-向前计算"><a href="#1-向前计算" class="headerlink" title="1. 向前计算"></a>1. 向前计算</h2><p>对于pytorch中的一个tensor，如果设置它的属性 <code>.requires_grad</code>为<code>True</code>，那么它将会追踪对于该张量的所有操作。或者可以理解为，这个tensor是一个参数，后续会被计算梯度，更新该参数。</p>
<h3 id="1-1-计算过程"><a href="#1-1-计算过程" class="headerlink" title="1.1 计算过程"></a>1.1 计算过程</h3><p>假设有以下条件（1&#x2F;4表示求均值，xi中有4个数），使用torch完成其向前计算的过程<br>$$<br>\begin{align*}<br>&amp;o &#x3D; \frac{1}{4}\sum_iz_i \<br>&amp;z_i &#x3D; 3(x_i+2)^2\<br>其中:&amp;\<br>&amp;z_i|_{x_i&#x3D;1}&#x3D;27\<br>\end{align*}<br>$$<br>如果x为参数，需要对其进行梯度的计算和更新</p>
<p>那么，在最开始随机设置x的值的过程中，需要设置他的requires_grad属性为True，其<strong>默认值为False</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment">#初始化参数x并设置requires_grad=True用来追踪其计算历史</span><br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-comment">#tensor([[1., 1.],</span><br><span class="hljs-comment">#        [1., 1.]], requires_grad=True)</span><br><br>y = x+<span class="hljs-number">2</span><br><span class="hljs-built_in">print</span>(y)<br><span class="hljs-comment">#tensor([[3., 3.],</span><br><span class="hljs-comment">#        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</span><br><br>z = y*y*<span class="hljs-number">3</span>  <span class="hljs-comment">#平方x3</span><br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-comment">#tensor([[27., 27.],</span><br><span class="hljs-comment">#        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) </span><br><br>out = z.mean() <span class="hljs-comment">#求均值</span><br><span class="hljs-built_in">print</span>(out)<br><span class="hljs-comment">#tensor(27., grad_fn=&lt;MeanBackward0&gt;)</span><br><br></code></pre></td></tr></table></figure>

<p>从上述代码可以看出：</p>
<ol>
<li>x的requires_grad属性为True</li>
<li>之后的每次计算都会修改其<code>grad_fn</code>属性，用来记录做过的操作<ol>
<li>通过这个函数和grad_fn能够组成一个和前一小节类似的计算图</li>
</ol>
</li>
</ol>
<h3 id="1-2-requires-grad和grad-fn"><a href="#1-2-requires-grad和grad-fn" class="headerlink" title="1.2 requires_grad和grad_fn"></a>1.2 requires_grad和grad_fn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>a = ((a * <span class="hljs-number">3</span>) / (a - <span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(a.requires_grad)  <span class="hljs-comment">#False</span><br>a.requires_grad_(<span class="hljs-literal">True</span>)  <span class="hljs-comment">#就地修改</span><br><span class="hljs-built_in">print</span>(a.requires_grad)  <span class="hljs-comment">#True</span><br>b = (a * a).<span class="hljs-built_in">sum</span>()<br><span class="hljs-built_in">print</span>(b.grad_fn) <span class="hljs-comment"># &lt;SumBackward0 object at 0x4e2b14345d21&gt;</span><br><span class="hljs-keyword">with</span> torch.no_gard():<br>    c = (a * a).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment">#tensor(151.6830),此时c没有gard_fn</span><br>    <br><span class="hljs-built_in">print</span>(c.requires_grad) <span class="hljs-comment">#False</span><br></code></pre></td></tr></table></figure>

<p>注意：</p>
<p>为了防止跟踪历史记录（和使用内存），可以将代码块包装在<code>with torch.no_grad():</code>中。<strong>在评估模型时特别有用</strong>，因为模型可能具有<code>requires_grad = True</code>的可训练的参数，但是我们不需要在此过程中对他们进行梯度计算。</p>
<h2 id="2-梯度计算"><a href="#2-梯度计算" class="headerlink" title="2. 梯度计算"></a>2. 梯度计算</h2><p>对于1.1 中的out而言，我们可以使用<code>backward</code>方法来进行反向传播，计算梯度</p>
<p><code>out.backward()</code>,此时便能够求出导数$\frac{d out}{dx}$,调用<code>x.gard</code>能够获取导数值</p>
<p>得到</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">4.5000</span>, <span class="hljs-number">4.5000</span>],<br>        [<span class="hljs-number">4.5000</span>, <span class="hljs-number">4.5000</span>]])<br></code></pre></td></tr></table></figure>

<p> 因为：<br>$$<br>\frac{d(O)}{d(x_i)} &#x3D; \frac{3}{2}(x_i+2)<br>$$<br>在$x_i$等于1时其值为4.5</p>
<p>注意：在输出为一个标量的情况下，我们可以调用输出<code>tensor</code>的<code>backword()</code> 方法，但是在数据是一个向量的时候，调用<code>backward()</code>的时候还需要传入其他参数。</p>
<p>很多时候我们的损失函数都是一个标量，所以这里就不再介绍损失为向量的情况。</p>
<p><code>loss.backward()</code>就是根据损失函数，对参数（requires_grad&#x3D;True）的去计算他的梯度，并且把它累加保存到<code>x.gard</code>，此时还并未更新其梯度</p>
<p>注意点：</p>
<ol>
<li><p><code>tensor.data</code>:</p>
<ul>
<li><p>在tensor的require_grad&#x3D;False，tensor.data和tensor等价</p>
</li>
<li><p>require_grad&#x3D;True时，tensor.data仅仅是获取tensor中的数据</p>
</li>
</ul>
</li>
<li><p><code>tensor.numpy()</code>:</p>
<ul>
<li><code>require_grad=True</code>不能够直接转换，需要使用<code>tensor.detach().numpy()</code></li>
</ul>
</li>
</ol>
<h2 id="3-线性回归实现"><a href="#3-线性回归实现" class="headerlink" title="3. 线性回归实现"></a>3. 线性回归实现</h2><p>下面，我们使用一个自定义的数据，来使用torch实现一个简单的线性回归</p>
<p>假设我们的基础模型就是<code>y = wx+b</code>，其中w和b均为参数，我们使用<code>y = 3x+0.8</code>来构造数据x、y，所以最后通过模型应该能够得出w和b应该分别接近3和0.8</p>
<ol>
<li>准备数据</li>
<li>计算预测值</li>
<li>计算损失，把参数的梯度置为0，进行反向传播</li>
<li>更新参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-comment">#1. 准备数据 y = 3x+0.8，准备参数</span><br>x = torch.rand([<span class="hljs-number">50</span>])<br>y = <span class="hljs-number">3</span>*x + <span class="hljs-number">0.8</span><br><br>w = torch.rand(<span class="hljs-number">1</span>,requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.rand(<span class="hljs-number">1</span>,requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_fn</span>(<span class="hljs-params">y,y_predict</span>):<br>    loss = (y_predict-y).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [w,b]:<br>		<span class="hljs-comment">#每次反向传播前把梯度置为0</span><br>        <span class="hljs-keyword">if</span> i.grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            i.grad.data.zero_()<br>    <span class="hljs-comment"># [i.grad.data.zero_() for i in [w,b] if i.grad is not None]</span><br>    loss.backward()<br>    <span class="hljs-keyword">return</span> loss.data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">optimize</span>(<span class="hljs-params">learning_rate</span>):<br>    <span class="hljs-comment"># print(w.grad.data,w.data,b.data)</span><br>    w.data -= learning_rate* w.grad.data<br>    b.data -= learning_rate* b.grad.data<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3000</span>):<br>    <span class="hljs-comment">#2. 计算预测值</span><br>    y_predict = x*w + b<br>	<br>    <span class="hljs-comment">#3.计算损失，把参数的梯度置为0，进行反向传播 </span><br>    loss = loss_fn(y,y_predict)<br>    <br>    <span class="hljs-keyword">if</span> i%<span class="hljs-number">500</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(i,loss)<br>    <span class="hljs-comment">#4. 更新参数w和b</span><br>    optimize(<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># 绘制图形，观察训练结束的预测值和真实值</span><br>predict =  x*w + b  <span class="hljs-comment">#使用训练后的w和b计算预测值</span><br><br>plt.scatter(x.data.numpy(), y.data.numpy(),c = <span class="hljs-string">&quot;r&quot;</span>)<br>plt.plot(x.data.numpy(), predict.data.numpy())<br>plt.show()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;w&quot;</span>,w)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;b&quot;</span>,b)<br></code></pre></td></tr></table></figure>



<p>图形效果如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921.png" srcset="/img/loading.gif" lazyload></p>
<p>打印w和b，可有</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">w tensor([<span class="hljs-number">2.9280</span>], requires_grad=<span class="hljs-literal">True</span>)<br>b tensor([<span class="hljs-number">0.8372</span>], requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>可知，w和b已经非常接近原来的预设的3和0.8</p>
<h1 id="Pytorch完成基础的模型"><a href="#Pytorch完成基础的模型" class="headerlink" title="Pytorch完成基础的模型"></a>Pytorch完成基础的模型</h1><h2 id="目标-4"><a href="#目标-4" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道Pytorch中Module的使用方法</li>
<li>知道Pytorch中优化器类的使用方法</li>
<li>知道Pytorch中常见的损失函数的使用方法</li>
<li>知道如何在GPU上运行代码</li>
<li>能够说出常见的优化器及其原理</li>
</ol>
<h2 id="1-Pytorch完成模型常用API"><a href="#1-Pytorch完成模型常用API" class="headerlink" title="1. Pytorch完成模型常用API"></a>1. Pytorch完成模型常用API</h2><p>在前一部分，我们自己实现了通过torch的相关方法完成反向传播和参数更新，在pytorch中预设了一些更加灵活简单的对象，让我们来构造模型、定义损失，优化损失等</p>
<p>那么接下来，我们一起来了解一下其中常用的API</p>
<h3 id="1-1-nn-Module"><a href="#1-1-nn-Module" class="headerlink" title="1.1 nn.Module"></a>1.1 <code>nn.Module</code></h3><p><code>nn.Modul</code> 是<code>torch.nn</code>提供的一个类，是pytorch中我们<code>自定义网络</code>的一个基类，在这个类中定义了很多有用的方法，让我们在继承这个类定义网络的时候非常简单</p>
<p>当我们自定义网络的时候，有两个方法需要特别注意：</p>
<ol>
<li><code>__init__</code>需要调用<code>super</code>方法，继承父类的属性和方法</li>
<li><code>farward</code>方法必须实现，用来定义我们的网络的向前计算的过程</li>
</ol>
<p>用前面的<code>y = wx+b</code>的模型举例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lr</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Lr, self).__init__()  <span class="hljs-comment">#继承父类init的参数</span><br>        self.linear = nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.linear(x)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li><code>nn.Linear</code>为torch预定义好的线性模型，也被称为<strong>全链接层</strong>，传入的参数为输入的数量，输出的数量(in_features, out_features),是不算(batch_size的列数)</li>
<li><code>nn.Module</code>定义了<code>__call__</code>方法，实现的就是调用<code>forward</code>方法，即<code>Lr</code>的实例，能够直接被传入参数调用，实际上调用的是<code>forward</code>方法并传入参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 实例化模型</span><br>model = Lr()<br><span class="hljs-comment"># 传入数据，计算结果</span><br>predict = model(x)<br></code></pre></td></tr></table></figure>

<h3 id="1-2-优化器类"><a href="#1-2-优化器类" class="headerlink" title="1.2 优化器类"></a>1.2 优化器类</h3><p>优化器(<code>optimizer</code>)，可以理解为torch为我们封装的用来进行更新参数的方法，比如常见的随机梯度下降(<code>stochastic gradient descent,SGD</code>)</p>
<p>优化器类都是由<code>torch.optim</code>提供的，例如</p>
<ol>
<li><code>torch.optim.SGD(参数，学习率)</code></li>
<li><code>torch.optim.Adam(参数，学习率)</code></li>
</ol>
<p>注意：</p>
<ol>
<li>参数可以使用<code>model.parameters()</code>来获取，获取模型中所有<code>requires_grad=True</code>的参数</li>
<li>优化类的使用方法<ol>
<li>实例化</li>
<li>所有参数的梯度，将其值置为0</li>
<li>反向传播计算梯度</li>
<li>更新参数值</li>
</ol>
</li>
</ol>
<p>示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>) <span class="hljs-comment">#1. 实例化</span><br>optimizer.zero_grad() <span class="hljs-comment">#2. 梯度置为0</span><br>loss.backward() <span class="hljs-comment">#3. 计算梯度</span><br>optimizer.step()  <span class="hljs-comment">#4. 更新参数的值</span><br></code></pre></td></tr></table></figure>



<h3 id="1-3-损失函数"><a href="#1-3-损失函数" class="headerlink" title="1.3 损失函数"></a>1.3 损失函数</h3><p>前面的例子是一个回归问题，torch中也预测了很多损失函数</p>
<ol>
<li>均方误差:<code>nn.MSELoss()</code>,常用于回归问题</li>
<li>交叉熵损失：<code>nn.CrossEntropyLoss()</code>，常用于分类问题</li>
</ol>
<p>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">model = Lr() <span class="hljs-comment">#1. 实例化模型</span><br>criterion = nn.MSELoss() <span class="hljs-comment">#2. 实例化损失函数</span><br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>) <span class="hljs-comment">#3. 实例化优化器类</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    y_predict = model(x_true) <span class="hljs-comment">#4. 向前计算预测值</span><br>    loss = criterion(y_true,y_predict) <span class="hljs-comment">#5. 调用损失函数传入真实值和预测值，得到损失结果</span><br>    optimizer.zero_grad() <span class="hljs-comment">#5. 当前循环参数梯度置为0</span><br>    loss.backward() <span class="hljs-comment">#6. 计算梯度</span><br>    optimizer.step()  <span class="hljs-comment">#7. 更新参数的值</span><br></code></pre></td></tr></table></figure>

<h3 id="1-4-把线性回归完整代码"><a href="#1-4-把线性回归完整代码" class="headerlink" title="1.4 把线性回归完整代码"></a>1.4 把线性回归完整代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 1. 定义数据</span><br>x = torch.rand([<span class="hljs-number">50</span>,<span class="hljs-number">1</span>])<br>y = x*<span class="hljs-number">3</span> + <span class="hljs-number">0.8</span><br><br><span class="hljs-comment">#2 .定义模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lr</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Lr,self).__init__()<br>        self.linear = nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>		<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.linear(x)<br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># 2. 实例化模型，loss，和优化器</span><br>model = Lr()<br>criterion = nn.MSELoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br><span class="hljs-comment">#3. 训练模型</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30000</span>):<br>    out = model(x) <span class="hljs-comment">#3.1 获取预测值</span><br>    loss = criterion(y,out) <span class="hljs-comment">#3.2 计算损失</span><br>    optimizer.zero_grad()  <span class="hljs-comment">#3.3 梯度归零</span><br>    loss.backward() <span class="hljs-comment">#3.4 计算梯度</span><br>    optimizer.step()  <span class="hljs-comment"># 3.5 更新梯度</span><br>    <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % <span class="hljs-number">20</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch[&#123;&#125;/&#123;&#125;], loss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i,<span class="hljs-number">30000</span>,loss.data))<br><br><span class="hljs-comment">#4. 模型评估</span><br>model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment">#设置模型为评估模式，即预测模式</span><br>predict = model(x)<br>predict = predict.data.numpy()<br>plt.scatter(x.data.numpy(),y.data.numpy(),c=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.plot(x.data.numpy(),predict)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%922.png" srcset="/img/loading.gif" lazyload></p>
<p>注意：</p>
<p><code>model.eval()</code>表示设置模型为评估模式，即预测模式</p>
<p><code>model.train(mode=True)</code> 表示设置模型为训练模式</p>
<p>在当前的线性回归中，上述并无区别</p>
<p>但是在其他的一些模型中，<strong>训练的参数和预测的参数会不相同</strong>，到时候就需要具体告诉程序我们是在进行训练还是预测，比如模型中存在<strong>Dropout</strong>，<strong>BatchNorm</strong>的时候</p>
<h2 id="2-在GPU上运行代码"><a href="#2-在GPU上运行代码" class="headerlink" title="2. 在GPU上运行代码"></a>2. 在GPU上运行代码</h2><p>当模型太大，或者参数太多的情况下，为了加快训练速度，经常会使用GPU来进行训练</p>
<p>此时我们的代码需要稍作调整：</p>
<ol>
<li><p>判断GPU是否可用<code>torch.cuda.is_available()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>&gt;&gt;device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>)  <span class="hljs-comment">#使用gpu</span><br>&gt;&gt;device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cpu&#x27;</span>) <span class="hljs-comment">#使用cpu</span><br></code></pre></td></tr></table></figure>


</li>
<li><p>把模型参数和input数据转化为cuda的支持类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model.to(device)<br>x_true.to(device)<br></code></pre></td></tr></table></figure>


</li>
<li><p>在GPU上计算结果也为cuda的数据类型，需要转化为numpy或者torch的cpu的tensor类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">predict = predict.cpu().detach().numpy() <br></code></pre></td></tr></table></figure>

<p><code>detach()</code>的效果和data的相似，但是<code>detach()</code>是深拷贝，data是取值，是浅拷贝</p>
</li>
</ol>
<p>修改之后的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># 1. 定义数据</span><br>x = torch.rand([<span class="hljs-number">50</span>,<span class="hljs-number">1</span>])<br>y = x*<span class="hljs-number">3</span> + <span class="hljs-number">0.8</span><br><br><span class="hljs-comment">#2 .定义模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lr</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Lr,self).__init__()<br>        self.linear = nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.linear(x)<br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># 2. 实例化模型，loss，和优化器</span><br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>x,y = x.to(device),y.to(device)<br><br>model = Lr().to(device)<br>criterion = nn.MSELoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br><br><span class="hljs-comment">#3. 训练模型</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">300</span>):<br>    out = model(x)<br>    loss = criterion(y,out)<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br>    <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % <span class="hljs-number">20</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch[&#123;&#125;/&#123;&#125;], loss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i,<span class="hljs-number">30000</span>,loss.data))<br><br><span class="hljs-comment">#4. 模型评估</span><br>model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment">#</span><br>predict = model(x)<br>predict = predict.cpu().detach().numpy() <span class="hljs-comment">#转化为numpy数组</span><br>plt.scatter(x.cpu().data.numpy(),y.cpu().data.numpy(),c=<span class="hljs-string">&quot;r&quot;</span>)<br>plt.plot(x.cpu().data.numpy(),predict,)<br>plt.show()<br><br></code></pre></td></tr></table></figure>

<h2 id="3-常见的优化算法介绍"><a href="#3-常见的优化算法介绍" class="headerlink" title="3. 常见的优化算法介绍"></a>3. 常见的优化算法介绍</h2><h3 id="3-1-梯度下降算法（batch-gradient-descent-BGD）"><a href="#3-1-梯度下降算法（batch-gradient-descent-BGD）" class="headerlink" title="3.1 梯度下降算法（batch gradient descent BGD）"></a>3.1 梯度下降算法（batch gradient descent BGD）</h3><p>每次迭代都需要把所有样本都送入，这样的好处是每次迭代都顾及了全部的样本，做的是全局最优化,但是有可能达到局部最优。</p>
<h3 id="3-2-随机梯度下降法-Stochastic-gradient-descent-SGD"><a href="#3-2-随机梯度下降法-Stochastic-gradient-descent-SGD" class="headerlink" title="3.2 随机梯度下降法 (Stochastic gradient descent SGD)"></a>3.2 随机梯度下降法 (Stochastic gradient descent SGD)</h3><p>针对梯度下降算法训练速度过慢的缺点，提出了随机梯度下降算法，随机梯度下降算法算法是从样本中随机抽出一组，训练后按梯度更新一次，然后再抽取一组，再更新一次，在样本量及其大的情况下，可能不用训练完所有的样本就可以获得一个损失值在可接受范围之内的模型了。</p>
<p>torch中的api为：<code>torch.optim.SGD()</code></p>
<h3 id="3-3-小批量梯度下降-Mini-batch-gradient-descent-MBGD）"><a href="#3-3-小批量梯度下降-Mini-batch-gradient-descent-MBGD）" class="headerlink" title="3.3 小批量梯度下降 (Mini-batch gradient descent MBGD）"></a>3.3 小批量梯度下降 (Mini-batch gradient descent MBGD）</h3><p>SGD相对来说要快很多，但是也有存在问题，由于单个样本的训练可能会带来很多噪声，使得SGD并不是每次迭代都向着整体最优化方向，因此在刚开始训练时可能收敛得很快，但是训练一段时间后就会变得很慢。在此基础上又提出了小批量梯度下降法，它是每次从样本中随机抽取一小批进行训练，而不是一组，这样即保证了效果又保证的速度。</p>
<h3 id="3-4-动量法"><a href="#3-4-动量法" class="headerlink" title="3.4 动量法"></a>3.4 动量法</h3><p>mini-batch SGD算法虽然这种算法能够带来很好的训练速度，但是在到达最优点的时候并不能够总是真正到达最优点，而是在最优点附近徘徊。</p>
<p>另一个缺点就是mini-batch SGD需要我们挑选一个合适的学习率，当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。我们所希望的仅仅是网络在优化的时候网络的损失函数有一个很好的收敛速度同时又不至于摆动幅度太大。</p>
<p>所以Momentum优化器刚好可以解决我们所面临的问题，它主要是基于梯度的移动指数加权平均，对网络的梯度进行平滑处理的，让梯度的摆动幅度变得更小。<br>$$<br>\begin{align*}<br>&amp;gradent &#x3D; 0.8\nabla w + 0.2 history_gradent  &amp;，\nabla w 表示当前一次的梯度\<br>&amp;w &#x3D; w - \alpha* gradent &amp;，\alpha表示学习率<br>\end{align*}<br>$$</p>
<p>（注：t+1的的histroy_gradent 为第t次的gradent）</p>
<h3 id="3-5-AdaGrad"><a href="#3-5-AdaGrad" class="headerlink" title="3.5 AdaGrad"></a>3.5 AdaGrad</h3><p>AdaGrad算法就是将每一个参数的每一次迭代的梯度取平方累加后在开方，用全局学习率除以这个数，作为学习率的动态更新，从而达到<strong>自适应学习率</strong>的效果<br>$$<br>\begin{align*}<br>&amp;gradent &#x3D; history_gradent + (\nabla w)^2 \<br>&amp;w &#x3D; w - \frac{\alpha}{\sqrt{gradent}+\delta} \nabla w ,&amp;\delta为小常数，为了数值稳定大约设置为10^{-7}<br>\end{align*}<br>$$</p>
<h3 id="3-6-RMSProp"><a href="#3-6-RMSProp" class="headerlink" title="3.6 RMSProp"></a>3.6 RMSProp</h3><p>Momentum优化算法中，虽然初步解决了优化中摆动幅度大的问题,为了进一步优化损失函数在更新中存在摆动幅度过大的问题，并且进一步加快函数的收敛速度，RMSProp算法对参数的梯度使用了平方加权平均数。<br>$$<br>\begin{align*}<br>&amp; gradent &#x3D; 0.8<em>history_gradent + 0.2</em>(\nabla w)^2 \<br>&amp; w &#x3D; w - \frac{\alpha}{\sqrt{gradent}+\delta} \nabla w<br>\end{align*}<br>$$</p>
<h3 id="3-7-Adam"><a href="#3-7-Adam" class="headerlink" title="3.7 Adam"></a>3.7 Adam</h3><p>Adam（Adaptive Moment Estimation）算法是将Momentum算法和RMSProp算法结合起来使用的一种算法,能够达到防止梯度的摆幅多大，同时还能够加开收敛速度<br>$$<br>\begin{align*}<br>&amp; 1. 需要初始化梯度的累积量和平方累积量 \<br>&amp; v_w &#x3D; 0,s_w &#x3D; 0 \<br>&amp; 2. 第 t 轮训练中，我们首先可以计算得到Momentum和RMSProp的参数更新：\<br>&amp; v_w &#x3D; 0.8v  + 0.2 \nabla w \qquad,Momentum计算的梯度\<br>&amp; s_w &#x3D; 0.8<em>s + 0.2</em>(\nabla w)^2 \qquad,RMSProp计算的梯度\<br>&amp; 3. 对其中的值进行处理后，得到：\<br>&amp; w &#x3D; w - \frac{\alpha}{\sqrt{s_w}+\delta} v_w<br>\end{align*}<br>$$<br>torch中的api为：<code>torch.optim.Adam()</code></p>
<h3 id="3-8-效果演示："><a href="#3-8-效果演示：" class="headerlink" title="3.8 效果演示："></a>3.8 效果演示：</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96%E5%99%A8%E6%96%B9%E6%B3%95.gif" srcset="/img/loading.gif" lazyload></p>
<p>​	</p>
<h1 id="Pytorch中的数据加载"><a href="#Pytorch中的数据加载" class="headerlink" title="Pytorch中的数据加载"></a>Pytorch中的数据加载</h1><h2 id="目标-5"><a href="#目标-5" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道数据加载的目的</li>
<li>知道pytorch中Dataset的使用方法</li>
<li>知道pytorch中DataLoader的使用方法</li>
<li>知道pytorch中的自带数据集如何获取</li>
</ol>
<h2 id="1-模型中使用数据加载器的目的"><a href="#1-模型中使用数据加载器的目的" class="headerlink" title="1. 模型中使用数据加载器的目的"></a>1. 模型中使用数据加载器的目的</h2><p>在前面的线性回归模型中，我们使用的数据很少，所以直接把全部数据放到模型中去使用。</p>
<p>但是在深度学习中，数据量通常是都非常多，非常大的，如此大量的数据，不可能一次性的在模型中进行向前的计算和反向传播，经常我们会对整个数据进行随机的打乱顺序，把数据处理成一个个的batch，同时还会对数据进行预处理。</p>
<p>所以，接下来我们来学习pytorch中的数据加载的方法</p>
<h2 id="2-数据集类"><a href="#2-数据集类" class="headerlink" title="2. 数据集类"></a>2. 数据集类</h2><h3 id="2-1-Dataset基类介绍"><a href="#2-1-Dataset基类介绍" class="headerlink" title="2.1 Dataset基类介绍"></a>2.1 Dataset基类介绍</h3><p>在torch中提供了数据集的基类<code>torch.utils.data.Dataset</code>，继承这个基类，我们能够非常快速的实现对数据的加载。</p>
<p><code>torch.utils.data.Dataset</code>的源码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dataset</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;An abstract class representing a Dataset.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    All other datasets should subclass it. All subclasses should override</span><br><span class="hljs-string">    ``__len__``, that provides the size of the dataset, and ``__getitem__``,</span><br><span class="hljs-string">    supporting integer indexing in range from 0 to len(self) exclusive.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__add__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> ConcatDataset([self, other])<br></code></pre></td></tr></table></figure>

<p>可知：我们需要在自定义的数据集类中继承Dataset类，同时还需要实现两个方法：</p>
<ol>
<li><code>__len__</code>方法，能够实现通过全局的<code>len()</code>方法获取其中的元素个数</li>
<li><code>__getitem__</code>方法，能够通过传入索引的方式获取数据，例如通过<code>dataset[i]</code>获取其中的第<code>i</code>条数据</li>
</ol>
<h3 id="2-2-数据加载案例"><a href="#2-2-数据加载案例" class="headerlink" title="2.2 数据加载案例"></a>2.2 数据加载案例</h3><p>下面通过一个例子来看看如何使用Dataset来加载数据</p>
<p>数据来源：<code>http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection</code></p>
<p>数据介绍：SMS Spam Collection是用于骚扰短信识别的经典数据集，完全来自真实短信内容，包括4831条正常短信和747条骚扰短信。正常短信和骚扰短信保存在一个文本文件中。 每行完整记录一条短信内容，每行开头通过ham和spam标识正常短信和骚扰短信</p>
<p>数据实例：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/dataset%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B.png" srcset="/img/loading.gif" lazyload></p>
<p>实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data_path = <span class="hljs-string">r&quot;data\SMSSpamCollection&quot;</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CifarDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        lines = <span class="hljs-built_in">open</span>(data_path,<span class="hljs-string">&quot;r&quot;</span>)<br>        <span class="hljs-comment">#对数据进行处理，前4个为label，后面的为短信内容</span><br>        lines = [[i[:<span class="hljs-number">4</span>].strip(),i[<span class="hljs-number">4</span>:].strip()] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> lines]<br>        <span class="hljs-comment">#转化为dataFrame</span><br>        self.df = pd.DataFrame(lines,columns=[<span class="hljs-string">&quot;label&quot;</span>,<span class="hljs-string">&quot;sms&quot;</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        single_item = self.df.iloc[index,:]<br>        <span class="hljs-keyword">return</span> single_item.values[<span class="hljs-number">0</span>],single_item.values[<span class="hljs-number">1</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.df.shape[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<p>之后对Dataset进行实例化，可以跌倒获取其中的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">d = CifarDataset()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(d)):<br>    <span class="hljs-built_in">print</span>(i,d[i])<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">....<br><span class="hljs-number">5571</span> (<span class="hljs-string">&#x27;ham&#x27;</span>, <span class="hljs-string">&#x27;Pity, * was in mood for that. So...any other suggestions?&#x27;</span>)<br><span class="hljs-number">5572</span> (<span class="hljs-string">&#x27;ham&#x27;</span>, <span class="hljs-string">&quot;The guy did some bitching but I acted like i&#x27;d be interested in buying something else next week and he gave it to us for free&quot;</span>)<br><span class="hljs-number">5573</span> (<span class="hljs-string">&#x27;ham&#x27;</span>, <span class="hljs-string">&#x27;Rofl. Its true to its name&#x27;</span>)<br></code></pre></td></tr></table></figure>



<h2 id="3-迭代数据集"><a href="#3-迭代数据集" class="headerlink" title="3. 迭代数据集"></a>3. 迭代数据集</h2><p>使用上述的方法能够进行数据的读取，但是其中还有很多内容没有实现：</p>
<ul>
<li>批处理数据（Batching the data）</li>
<li>打乱数据（Shuffling the data）</li>
<li>使用多线程 <code>multiprocessing</code> 并行加载数据。</li>
</ul>
<p>在pytorch中<code>torch.utils.data.DataLoader</code>提供了上述的所用方法</p>
<p><code>DataLoader</code>的使用方法示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>dataset = CifarDataset()<br>data_loader = DataLoader(dataset=dataset,batch_size=<span class="hljs-number">10</span>,shuffle=<span class="hljs-literal">True</span>,num_workers=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment">#遍历，获取其中的每个batch的结果</span><br><span class="hljs-keyword">for</span> index, (label, context) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data_loader):<br>    <span class="hljs-built_in">print</span>(index,label,context)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;*&quot;</span>*<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure>

<p>其中参数含义：</p>
<ol>
<li>dataset：提前定义的dataset的实例</li>
<li>batch_size:传入数据的batch的大小，常用128,256等等</li>
<li>shuffle：bool类型，表示是否在每次获取数据的时候提前打乱数据</li>
<li><code>num_workers</code>:加载数据的线程数</li>
</ol>
<p>数据迭代器的返回结果如下：</p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-number">555</span> (&#x27;spam&#x27;, &#x27;ham&#x27;, &#x27;spam&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;spam&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;) (&#x27;URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call <span class="hljs-number">0905000309</span>1 from....&quot;, &#x27;swhrt how u dey,hope ur ok, tot about u <span class="hljs-number">2</span>day.love n miss.take care.&#x27;)<br>***********************************************************************************<br>556 (&#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;ham&#x27;, &#x27;spam&#x27;) (&#x27;He telling not to tell any one. If so treat for me hi hi hi&#x27;, &#x27;Did u got that persons story&#x27;, &quot;Don kn....<span class="hljs-number">1000</span> cash prize or a prize worth £<span class="hljs-number">5000</span>&#x27;)<br></code></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li><code>len(dataset) = 数据集的样本数</code></li>
<li><code>len(dataloader) = math.ceil(样本数/batch_size) 即向上取整</code></li>
</ol>
<h2 id="4-pytorch自带的数据集"><a href="#4-pytorch自带的数据集" class="headerlink" title="4 pytorch自带的数据集"></a>4 pytorch自带的数据集</h2><p>pytorch中自带的数据集由两个上层api提供，分别是<code>torchvision</code>和<code>torchtext</code></p>
<p>其中：</p>
<ol>
<li><code>torchvision</code>提供了对图片数据处理相关的api和数据<ul>
<li>数据位置：<code>torchvision.datasets</code>，例如：<code>torchvision.datasets.MNIST</code>(手写数字图片数据)</li>
</ul>
</li>
<li><code>torchtext</code>提供了对文本数据处理相关的API和数据<ul>
<li>数据位置：<code>torchtext.datasets</code>,例如：<code>torchtext.datasets.IMDB（电影</code>评论文本数据）</li>
</ul>
</li>
</ol>
<p>下面我们以Mnist手写数字为例，来看看pytorch如何加载其中自带的数据集</p>
<p>使用方法和之前一样：</p>
<ol>
<li>准备好Dataset实例</li>
<li>把dataset交给dataloder 打乱顺序，组成batch</li>
</ol>
<h3 id="4-1-torchversion-datasets"><a href="#4-1-torchversion-datasets" class="headerlink" title="4.1 torchversion.datasets"></a>4.1 torchversion.datasets</h3><p><code>torchversoin.datasets</code>中的数据集类（比如<code>torchvision.datasets.MNIST</code>）,都是继承自<code>Dataset</code></p>
<p>意味着：直接对<code>torchvision.datasets.MNIST</code>进行实例化就可以得到<code>Dataset</code>的实例</p>
<p>但是MNIST API中的参数需要注意一下：</p>
<p><code> torchvision.datasets.MNIST(root=&#39;/files/&#39;, train=True, download=True, transform=)</code></p>
<ol>
<li><code>root</code>参数表示数据存放的位置</li>
<li><code>train：</code>bool类型，表示是使用训练集的数据还是测试集的数据</li>
<li><code>download：</code>bool类型，表示是否需要下载数据到root目录</li>
<li><code>transform:</code>实现的对图片的处理函数</li>
</ol>
<h3 id="4-2-MNIST数据集的介绍"><a href="#4-2-MNIST数据集的介绍" class="headerlink" title="4.2 MNIST数据集的介绍"></a>4.2 MNIST数据集的介绍</h3><p>数据集的原始地址：<code>http://yann.lecun.com/exdb/mnist/</code></p>
<p>MNIST是由<code>Yann LeCun</code>等人提供的免费的图像识别的数据集，其中包括60000个训练样本和10000个测试样本，其中图拍了的尺寸已经进行的标准化的处理，都是黑白的图像，大小为<code>28X28</code></p>
<p>执行代码，下载数据，观察数据类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><br>dataset = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;./data&quot;</span>,train=<span class="hljs-literal">True</span>,download=<span class="hljs-literal">True</span>,transform=<span class="hljs-literal">None</span>)<br><br><span class="hljs-built_in">print</span>(dataset[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<p>下载的数据如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MNIST-dataset.png" srcset="/img/loading.gif" lazyload></p>
<p>代码输出结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz<br>Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz<br>Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz<br>Processing...<br>Done!<br>(&lt;PIL.Image.Image image mode=L size=28x28 at <span class="hljs-number">0x18D303B9C18</span>&gt;, tensor(<span class="hljs-number">5</span>))<br></code></pre></td></tr></table></figure>



<p>可以其中数据集返回了两条数据，可以猜测为图片的数据和目标值</p>
<p>返回值的第0个为Image类型，可以调用show() 方法打开，发现为手写数字5</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><br>dataset = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;./data&quot;</span>,train=<span class="hljs-literal">True</span>,download=<span class="hljs-literal">True</span>,transform=<span class="hljs-literal">None</span>)<br><br><span class="hljs-built_in">print</span>(dataset[<span class="hljs-number">0</span>])<br><br>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br>img.show() <span class="hljs-comment">#打开图片</span><br></code></pre></td></tr></table></figure>

<p>图片如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/MNIST-dataset-5.png" srcset="/img/loading.gif" lazyload></p>
<p>由上可知：返回值为<code>(图片，目标值)</code>,这个结果也可以通过观察源码得到</p>
<h1 id="使用Pytorch实现手写数字识别"><a href="#使用Pytorch实现手写数字识别" class="headerlink" title="使用Pytorch实现手写数字识别"></a>使用Pytorch实现手写数字识别</h1><h2 id="目标-6"><a href="#目标-6" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道如何使用Pytorch完成神经网络的构建</li>
<li>知道Pytorch中激活函数的使用方法</li>
<li>知道Pytorch中<code>torchvision.transforms</code>中常见图形处理函数的使用</li>
<li>知道如何训练模型和如何评估模型</li>
</ol>
<h2 id="1-思路和流程分析"><a href="#1-思路和流程分析" class="headerlink" title="1. 思路和流程分析"></a>1. 思路和流程分析</h2><p>流程：</p>
<ol>
<li>准备数据，这些需要准备DataLoader</li>
<li>构建模型，这里可以使用torch构造一个深层的神经网络</li>
<li>模型的训练</li>
<li>模型的保存，保存模型，后续持续使用</li>
<li>模型的评估，使用测试集，观察模型的好坏</li>
</ol>
<h2 id="2-准备训练集和测试集"><a href="#2-准备训练集和测试集" class="headerlink" title="2. 准备训练集和测试集"></a>2. 准备训练集和测试集</h2><p>准备数据集的方法前面已经讲过，但是通过前面的内容可知，调用MNIST返回的结果中图形数据是一个Image对象,需要对其进行处理</p>
<p>为了进行数据的处理，接下来学习<code>torchvision.transfroms</code>的方法</p>
<h3 id="2-1-torchvision-transforms的图形数据处理方法"><a href="#2-1-torchvision-transforms的图形数据处理方法" class="headerlink" title="2.1 torchvision.transforms的图形数据处理方法"></a>2.1 <code>torchvision.transforms</code>的图形数据处理方法</h3><h4 id="2-1-1-torchvision-transforms-ToTensor"><a href="#2-1-1-torchvision-transforms-ToTensor" class="headerlink" title="2.1.1 torchvision.transforms.ToTensor"></a>2.1.1 <code>torchvision.transforms.ToTensor</code></h4><p>把一个取值范围是<code>[0,255]</code>的<code>PIL.Image</code>或者<code>shape</code>为<code>(H,W,C)</code>的<code>numpy.ndarray</code>，转换成形状为<code>[C,H,W]</code></p>
<p>其中<code>(H,W,C)</code>意思为<code>(高，宽，通道数)</code>，黑白图片的通道数只有1，其中每个像素点的取值为[0,255],彩色图片的通道数为(R,G,B),每个通道的每个像素点的取值为[0,255]，三个通道的颜色相互叠加，形成了各种颜色</p>
<p>示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>data = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, size=<span class="hljs-number">12</span>)<br>img = data.reshape(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(img.shape)<br>img_tensor = transforms.ToTensor()(img) <span class="hljs-comment"># 转换成tensor</span><br><span class="hljs-built_in">print</span>(img_tensor)<br><span class="hljs-built_in">print</span>(img_tensor.shape)<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">shape:(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>img_tensor:tensor([[[<span class="hljs-number">215</span>, <span class="hljs-number">171</span>],<br>                 [ <span class="hljs-number">34</span>,  <span class="hljs-number">12</span>]],<br><br>                [[<span class="hljs-number">229</span>,  <span class="hljs-number">87</span>],<br>                 [ <span class="hljs-number">15</span>, <span class="hljs-number">237</span>]],<br><br>                [[ <span class="hljs-number">10</span>,  <span class="hljs-number">55</span>],<br>                 [ <span class="hljs-number">72</span>, <span class="hljs-number">204</span>]]], dtype=torch.int32)<br>new shape:torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<br><br></code></pre></td></tr></table></figure>

<p>注意：</p>
<p><code>transforms.ToTensor</code>对象中有<code>__call__</code>方法，所以可以对其示例能够传入数据获取结果</p>
<h4 id="2-1-2-torchvision-transforms-Normalize-mean-std"><a href="#2-1-2-torchvision-transforms-Normalize-mean-std" class="headerlink" title="2.1.2 torchvision.transforms.Normalize(mean, std)"></a>2.1.2 <code>torchvision.transforms.Normalize(mean, std)</code></h4><p>给定均值：mean，shape和图片的通道数相同(指的是每个通道的均值)，方差：std，和图片的通道数相同(指的是每个通道的方差)，将会把<code>Tensor</code>规范化处理。</p>
<p>即：<code>Normalized_image=(image-mean)/std</code>。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torchvision<br><br>data = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, size=<span class="hljs-number">12</span>)<br>img = data.reshape(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br>img = transforms.ToTensor()(img) <span class="hljs-comment"># 转换成tensor</span><br><span class="hljs-built_in">print</span>(img)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;*&quot;</span>*<span class="hljs-number">100</span>)<br><br>norm_img = transforms.Normalize((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))(img) <span class="hljs-comment">#进行规范化处理</span><br><br><span class="hljs-built_in">print</span>(norm_img)<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs lua">tensor(<span class="hljs-string">[[[177, 223],</span><br><span class="hljs-string">         [ 71, 182]]</span>,<br><br>        <span class="hljs-string">[[153, 120],</span><br><span class="hljs-string">         [173,  33]]</span>,<br><br>        <span class="hljs-string">[[162, 233],</span><br><span class="hljs-string">         [194,  73]]</span>], dtype=torch.int32)<br>***************************************************************************************<br>tensor(<span class="hljs-string">[[[167, 213],</span><br><span class="hljs-string">         [ 61, 172]]</span>,<br><br>        <span class="hljs-string">[[143, 110],</span><br><span class="hljs-string">         [163,  23]]</span>,<br><br>        <span class="hljs-string">[[152, 223],</span><br><span class="hljs-string">         [184,  63]]</span>], dtype=torch.int32)<br></code></pre></td></tr></table></figure>

<p>注意：在sklearn中，默认上式中的std和mean为数据每列的std和mean，sklearn会在标准化之前算出每一列的std和mean。</p>
<p>但是在api：Normalize中并没有帮我们计算，所以我们需要手动计算</p>
<ol>
<li><p>当mean为全部数据的均值，std为全部数据的std的时候，才是进行了标准化。</p>
</li>
<li><p>如果mean(x)不是全部数据的mean的时候，std(y)也不是的时候，Normalize后的数据分布满足下面的关系<br>$$<br>\begin{align*}<br>&amp;new_mean &#x3D; \frac{mean-x}{y}&amp;， mean为原数据的均值，x为传入的均值x \<br>&amp;new_std &#x3D; \frac{std}{y} &amp;，y为传入的标准差y\<br>\end{align*}<br>$$</p>
</li>
</ol>
<h4 id="2-1-3-torchvision-transforms-Compose-transforms"><a href="#2-1-3-torchvision-transforms-Compose-transforms" class="headerlink" title="2.1.3 torchvision.transforms.Compose(transforms)"></a>2.1.3 <code>torchvision.transforms.Compose(transforms)</code></h4><p>将多个<code>transform</code>组合起来使用。</p>
<p>例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">transforms.Compose([<br>     torchvision.transforms.ToTensor(), <span class="hljs-comment">#先转化为Tensor</span><br>     torchvision.transforms.Normalize(mean,std) <span class="hljs-comment">#在进行正则化</span><br> ])<br></code></pre></td></tr></table></figure>



<h3 id="2-2-准备MNIST数据集的Dataset和DataLoader"><a href="#2-2-准备MNIST数据集的Dataset和DataLoader" class="headerlink" title="2.2 准备MNIST数据集的Dataset和DataLoader"></a>2.2 准备MNIST数据集的Dataset和DataLoader</h3><p>准备训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment">#准备数据集，其中0.1307，0.3081为MNIST数据的均值和标准差，这样操作能够对其进行标准化</span><br><span class="hljs-comment">#因为MNIST只有一个通道（黑白图片）,所以元组中只有一个值</span><br>dataset = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;/data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                             transform=torchvision.transforms.Compose([<br>                               torchvision.transforms.ToTensor(),<br>                               torchvision.transforms.Normalize(<br>                                 (<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                             ]))<br><span class="hljs-comment">#准备数据迭代器                          </span><br>train_dataloader = torch.utils.data.DataLoader(dataset,batch_size=<span class="hljs-number">64</span>,shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>准备测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment">#准备数据集，其中0.1307，0.3081为MNIST数据的均值和标准差，这样操作能够对其进行标准化</span><br><span class="hljs-comment">#因为MNIST只有一个通道（黑白图片）,所以元组中只有一个值</span><br>dataset = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;/data&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>,<br>                             transform=torchvision.transforms.Compose([<br>                               torchvision.transforms.ToTensor(),<br>                               torchvision.transforms.Normalize(<br>                                 (<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                             ]))<br><span class="hljs-comment">#准备数据迭代器                          </span><br>train_dataloader = torch.utils.data.DataLoader(dataset,batch_size=<span class="hljs-number">64</span>,shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-构建模型"><a href="#3-构建模型" class="headerlink" title="3. 构建模型"></a>3. 构建模型</h2><p>补充：<strong>全连接层</strong>：当前一层的神经元和前一层的神经元相互链接，其核心操作就是$y &#x3D; wx$，即矩阵的乘法，实现对前一层的数据的变换</p>
<p>模型的构建使用了一个三层的神经网络，其中包括两个全连接层和一个输出层，第一个全连接层会经过激活函数的处理，将处理后的结果交给下一个全连接层，进行变换后输出结果</p>
<p>那么在这个模型中有两个地方需要注意：</p>
<ol>
<li>激活函数如何使用</li>
<li>每一层数据的形状</li>
<li>模型的损失函数</li>
</ol>
<h3 id="3-1-激活函数的使用"><a href="#3-1-激活函数的使用" class="headerlink" title="3.1 激活函数的使用"></a>3.1 激活函数的使用</h3><p>前面介绍了激活函数的作用，常用的激活函数为Relu激活函数，他的使用非常简单</p>
<p>Relu激活函数由<code>import torch.nn.functional as F</code>提供，<code>F.relu(x)</code>即可对x进行处理</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">30</span>]: b<br>Out[<span class="hljs-number">30</span>]: tensor([-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>])<br><br>In [<span class="hljs-number">31</span>]: <span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>In [<span class="hljs-number">32</span>]: F.relu(b)<br>Out[<span class="hljs-number">32</span>]: tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure>



<h3 id="3-2-模型中数据的形状（【添加形状变化图形】）"><a href="#3-2-模型中数据的形状（【添加形状变化图形】）" class="headerlink" title="3.2  模型中数据的形状（【添加形状变化图形】）"></a>3.2  模型中数据的形状（【添加形状变化图形】）</h3><ol>
<li>原始输入数据为的形状:<code>[batch_size,1,28,28]</code></li>
<li>进行形状的修改：<code>[batch_size,28*28]</code> ,(全连接层是在进行矩阵的乘法操作)</li>
<li>第一个全连接层的输出形状：<code>[batch_size,28]</code>，这里的28是个人设定的，你也可以设置为别的</li>
<li>激活函数不会修改数据的形状</li>
<li>第二个全连接层的输出形状：<code>[batch_size,10]</code>,因为手写数字有10个类别</li>
</ol>
<p>构建模型的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MnistNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MnistNet,self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>*<span class="hljs-number">1</span>,<span class="hljs-number">28</span>)  <span class="hljs-comment">#定义Linear的输入和输出的形状</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">28</span>,<span class="hljs-number">10</span>)  <span class="hljs-comment">#定义Linear的输入和输出的形状</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>*<span class="hljs-number">28</span>*<span class="hljs-number">1</span>)  <span class="hljs-comment">#对数据形状变形，-1表示该位置根据后面的形状自动调整</span><br>        x = self.fc1(x) <span class="hljs-comment">#[batch_size,28]</span><br>        x = F.relu(x)  <span class="hljs-comment">#[batch_size,28]</span><br>        x = self.fc2(x) <span class="hljs-comment">#[batch_size,10]</span><br>  <br></code></pre></td></tr></table></figure>

<p>可以发现：pytorch在构建模型的时候<code>形状上</code>并不会考虑<code>batch_size</code></p>
<h3 id="3-3-模型的损失函数"><a href="#3-3-模型的损失函数" class="headerlink" title="3.3 模型的损失函数"></a>3.3 模型的损失函数</h3><p>首先，我们需要明确，当前我们手写字体识别的问题是一个多分类的问题，所谓多分类对比的是之前学习的2分类</p>
<p>回顾之前的课程，我们在逻辑回归中，我们使用sigmoid进行计算对数似然损失，来定义我们的2分类的损失。</p>
<ul>
<li><p>在2分类中我们有正类和负类，正类的概率为$P(x) &#x3D;  \frac{1}{1+e^{-x}} &#x3D; \frac{e^x}{1+e^x}$,那么负类的概率为$1-P(x)$</p>
</li>
<li><p>将这个结果进行计算对数似然损失$-\sum y log(P(x))$就可以得到最终的损失</p>
</li>
</ul>
<p>那么在多分类的过程中我们应该怎么做呢？</p>
<ul>
<li><p>多分类和2分类中唯一的区别是我们不能够再使用sigmoid函数来计算当前样本属于某个类别的概率，而应该使用softmax函数。</p>
</li>
<li><p>softmax和sigmoid的区别在于我们需要去计算样本属于每个类别的概率，需要计算多次，而sigmoid只需要计算一次</p>
</li>
</ul>
<p>softmax的公式如下：<br>$$<br>\sigma(z)<em>j &#x3D; \frac{e^{z_j}}{\sum^K</em>{k&#x3D;1}e^{z_K}}  ,j&#x3D;1 \cdots k<br>$$</p>
<p>例如下图：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/softmax.png" srcset="/img/loading.gif" lazyload></p>
<p>假如softmax之前的输出结果是<code>2.3, 4.1, 5.6</code>,那么经过softmax之后的结果是多少呢？<br>$$<br>Y1 &#x3D; \frac{e^{2.3}}{e^{2.3}+e^{4.1}+e^{5.6}} \<br>Y2 &#x3D; \frac{e^{4.1}}{e^{2.3}+e^{4.1}+e^{5.6}} \<br>Y3 &#x3D; \frac{e^{5.6}}{e^{2.3}+e^{4.1}+e^{5.6}} \<br>$$</p>
<p>对于这个softmax输出的结果，是在[0,1]区间，我们可以把它当做概率</p>
<p>和前面2分类的损失一样，多分类的损失只需要再把这个结果进行对数似然损失的计算即可</p>
<p>即：<br>$$<br>\begin{align*}<br>&amp; J &#x3D; -\sum Y log(P) &amp;, 其中 P &#x3D; \frac{e^{z_j}}{\sum^K_{k&#x3D;1}e^{z_K}} ,Y表示真实值<br>\end{align*}<br>$$<br>最后，会计算每个样本的损失，即上式的平均值</p>
<p>我们把softmax概率传入对数似然损失得到的损失函数称为<strong>交叉熵损失</strong></p>
<p>在pytorch中有两种方法实现交叉熵损失</p>
<ol>
<li>&#96;&#96;&#96;<br>criterion &#x3D; nn.CrossEntropyLoss()<br>loss &#x3D; criterion(input,target)<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><br><span class="hljs-number">2.</span> ```<br>   #<span class="hljs-number">1.</span> 对输出值计算softmax和取对数<br>   output = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">F</span>.</span></span>log<span class="hljs-constructor">_softmax(<span class="hljs-params">x</span>,<span class="hljs-params">dim</span>=-1)</span><br>   #<span class="hljs-number">2.</span> 使用torch中带权损失<br>   loss = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">F</span>.</span></span>nll<span class="hljs-constructor">_loss(<span class="hljs-params">output</span>,<span class="hljs-params">target</span>)</span><br></code></pre></td></tr></table></figure></li>
</ol>
<p>带权损失定义为：$l_n &#x3D; -\sum w_{i} x_{i}$，其实就是把$log(P)$作为$x_i$,把真实值Y作为权重</p>
<h2 id="4-模型的训练"><a href="#4-模型的训练" class="headerlink" title="4. 模型的训练"></a>4. 模型的训练</h2><p>训练的流程：</p>
<ol>
<li>实例化模型，设置模型为训练模式</li>
<li>实例化优化器类，实例化损失函数</li>
<li>获取，遍历dataloader</li>
<li>梯度置为0</li>
<li>进行向前计算</li>
<li>计算损失</li>
<li>反向传播</li>
<li>更新参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">mnist_net = MnistNet()<br>optimizer = optim.Adam(mnist_net.parameters(),lr= <span class="hljs-number">0.001</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    mode = <span class="hljs-literal">True</span><br>    mnist_net.train(mode=mode) <span class="hljs-comment">#模型设置为训练模型</span><br>    <br>    train_dataloader = get_dataloader(train=mode) <span class="hljs-comment">#获取训练数据集</span><br>    <span class="hljs-keyword">for</span> idx,(data,target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        optimizer.zero_grad() <span class="hljs-comment">#梯度置为0</span><br>        output = mnist_net(data) <span class="hljs-comment">#进行向前计算</span><br>        loss = F.nll_loss(output,target) <span class="hljs-comment">#带权损失</span><br>        loss.backward()  <span class="hljs-comment">#进行反向传播，计算梯度</span><br>        optimizer.step() <span class="hljs-comment">#参数更新</span><br>        <span class="hljs-keyword">if</span> idx % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, idx * <span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                       <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item()))<br></code></pre></td></tr></table></figure>



<h2 id="5-模型的保存和加载"><a href="#5-模型的保存和加载" class="headerlink" title="5. 模型的保存和加载"></a>5. 模型的保存和加载</h2><h3 id="5-1-模型的保存"><a href="#5-1-模型的保存" class="headerlink" title="5.1 模型的保存"></a>5.1 模型的保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(mnist_net.state_dict(),<span class="hljs-string">&quot;model/mnist_net.pt&quot;</span>) <span class="hljs-comment">#保存模型参数</span><br>torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;results/mnist_optimizer.pt&#x27;</span>) <span class="hljs-comment">#保存优化器参数</span><br></code></pre></td></tr></table></figure>



<h3 id="5-2-模型的加载"><a href="#5-2-模型的加载" class="headerlink" title="5.2 模型的加载"></a>5.2 模型的加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">mnist_net.load_state_dict(torch.load(<span class="hljs-string">&quot;model/mnist_net.pt&quot;</span>))<br>optimizer.load_state_dict(torch.load(<span class="hljs-string">&quot;results/mnist_optimizer.pt&quot;</span>))<br></code></pre></td></tr></table></figure>

<h2 id="6-模型的评估"><a href="#6-模型的评估" class="headerlink" title="6. 模型的评估"></a>6. 模型的评估</h2><p>评估的过程和训练的过程相似，但是：</p>
<ol>
<li>不需要计算梯度</li>
<li>需要收集损失和准确率，用来计算平均损失和平均准确率</li>
<li>损失的计算和训练时候损失的计算方法相同</li>
<li>准确率的计算：<ul>
<li>模型的输出为[batch_size,10]的形状</li>
<li>其中最大值的位置就是其预测的目标值（预测值进行过sotfmax后为概率，sotfmax中分母都是相同的，分子越大，概率越大）</li>
<li>最大值的位置获取的方法可以使用<code>torch.max</code>,返回最大值和最大值的位置</li>
<li>返回最大值的位置后，和真实值（<code>[batch_size]</code>）进行对比，相同表示预测成功</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    mnist_net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment">#设置模型为评估模式</span><br>    test_dataloader = get_dataloader(train=<span class="hljs-literal">False</span>) <span class="hljs-comment">#获取评估数据集</span><br>    <span class="hljs-keyword">with</span> torch.no_grad(): <span class="hljs-comment">#不计算其梯度</span><br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_dataloader:<br>            output = mnist_net(data)<br>            test_loss += F.nll_loss(output, target, reduction=<span class="hljs-string">&#x27;sum&#x27;</span>).item()<br>            pred = output.data.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>] <span class="hljs-comment">#获取最大值的位置,[batch_size,1]</span><br>            correct += pred.eq(target.data.view_as(pred)).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment">#预测准备样本数累加</span><br>    test_loss /= <span class="hljs-built_in">len</span>(test_dataloader.dataset) <span class="hljs-comment">#计算平均损失</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&#x27;</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_dataloader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_dataloader.dataset)))<br></code></pre></td></tr></table></figure>



<h2 id="7-完整的代码如下："><a href="#7-完整的代码如下：" class="headerlink" title="7. 完整的代码如下："></a>7. 完整的代码如下：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torchvision<br><br>train_batch_size = <span class="hljs-number">64</span><br>test_batch_size = <span class="hljs-number">1000</span><br>img_size = <span class="hljs-number">28</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader</span>(<span class="hljs-params">train=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(train,<span class="hljs-built_in">bool</span>),<span class="hljs-string">&quot;train 必须是bool类型&quot;</span><br><br>    <span class="hljs-comment">#准备数据集，其中0.1307，0.3081为MNIST数据的均值和标准差，这样操作能够对其进行标准化</span><br>    <span class="hljs-comment">#因为MNIST只有一个通道（黑白图片）,所以元组中只有一个值</span><br>    dataset = torchvision.datasets.MNIST(<span class="hljs-string">&#x27;/data&#x27;</span>, train=train, download=<span class="hljs-literal">True</span>,<br>                                         transform=torchvision.transforms.Compose([<br>                                         torchvision.transforms.ToTensor(),<br>                                         torchvision.transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,)),]))<br>    <span class="hljs-comment">#准备数据迭代器</span><br>    batch_size = train_batch_size <span class="hljs-keyword">if</span> train <span class="hljs-keyword">else</span> test_batch_size<br>    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> dataloader<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MnistNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MnistNet,self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>*<span class="hljs-number">1</span>,<span class="hljs-number">28</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">28</span>,<span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>*<span class="hljs-number">28</span>*<span class="hljs-number">1</span>)<br>        x = self.fc1(x) <span class="hljs-comment">#[batch_size,28]</span><br>        x = F.relu(x)  <span class="hljs-comment">#[batch_size,28]</span><br>        x = self.fc2(x) <span class="hljs-comment">#[batch_size,10]</span><br>        <span class="hljs-comment"># return x</span><br>        <span class="hljs-keyword">return</span> F.log_softmax(x,dim=-<span class="hljs-number">1</span>)<br><br>mnist_net = MnistNet()<br>optimizer = optim.Adam(mnist_net.parameters(),lr= <span class="hljs-number">0.001</span>)<br><span class="hljs-comment"># criterion = nn.NLLLoss()</span><br><span class="hljs-comment"># criterion = nn.CrossEntropyLoss()</span><br>train_loss_list = []<br>train_count_list = []<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    mode = <span class="hljs-literal">True</span><br>    mnist_net.train(mode=mode)<br>    train_dataloader = get_dataloader(train=mode)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(train_dataloader.dataset))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(train_dataloader))<br>    <span class="hljs-keyword">for</span> idx,(data,target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        optimizer.zero_grad()<br>        output = mnist_net(data)<br>        loss = F.nll_loss(output,target) <span class="hljs-comment">#对数似然损失</span><br>        loss.backward()<br>        optimizer.step()<br>        <span class="hljs-keyword">if</span> idx % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, idx * <span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                       <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item()))<br><br>            train_loss_list.append(loss.item())<br>            train_count_list.append(idx*train_batch_size+(epoch-<span class="hljs-number">1</span>)*<span class="hljs-built_in">len</span>(train_dataloader))<br>            torch.save(mnist_net.state_dict(),<span class="hljs-string">&quot;model/mnist_net.pkl&quot;</span>)<br>            torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;results/mnist_optimizer.pkl&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    mnist_net.<span class="hljs-built_in">eval</span>()<br>    test_dataloader = get_dataloader(train=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_dataloader:<br>            output = mnist_net(data)<br>            test_loss += F.nll_loss(output, target, reduction=<span class="hljs-string">&#x27;sum&#x27;</span>).item()<br>            pred = output.data.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>] <span class="hljs-comment">#获取最大值的位置,[batch_size,1]</span><br>            correct += pred.eq(target.data.view_as(pred)).<span class="hljs-built_in">sum</span>()<br>    test_loss /= <span class="hljs-built_in">len</span>(test_dataloader.dataset)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&#x27;</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_dataloader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_dataloader.dataset)))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    test()  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>): <span class="hljs-comment">#模型训练5轮</span><br>        train(i)<br>        test()<br></code></pre></td></tr></table></figure>

<h1 id="循环神经网络和自然语言处理介绍"><a href="#循环神经网络和自然语言处理介绍" class="headerlink" title="循环神经网络和自然语言处理介绍"></a>循环神经网络和自然语言处理介绍</h1><h2 id="目标-7"><a href="#目标-7" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道<code>token</code>和<code>tokenization</code></li>
<li>知道<code>N-gram</code>的概念和作用</li>
<li>知道文本向量化表示的方法</li>
</ol>
<h2 id="1-文本的tokenization"><a href="#1-文本的tokenization" class="headerlink" title="1. 文本的tokenization"></a>1. 文本的<code>tokenization</code></h2><h3 id="1-1-概念和工具的介绍"><a href="#1-1-概念和工具的介绍" class="headerlink" title="1.1 概念和工具的介绍"></a>1.1 概念和工具的介绍</h3><p><code>tokenization</code>就是通常所说的分词，分出的每一个词语我们把它称为<code>token</code>。</p>
<p>常见的分词工具很多，比如：</p>
<ul>
<li><code>jieba分词：https://github.com/fxsjy/jieba</code></li>
<li>清华大学的分词工具THULAC：<code>https://github.com/thunlp/THULAC-Python</code></li>
</ul>
<h3 id="1-2-中英文分词的方法"><a href="#1-2-中英文分词的方法" class="headerlink" title="1.2 中英文分词的方法"></a>1.2 中英文分词的方法</h3><ul>
<li>把句子转化为词语<ul>
<li>比如：<code>我爱深度学习</code> 可以分为<code>[我，爱， 深度学习]</code></li>
</ul>
</li>
<li>把句子转化为单个字<ul>
<li>比如：<code>我爱深度学习</code>的token是<code>[我，爱，深，度，学，习]</code></li>
</ul>
</li>
</ul>
<h2 id="2-N-garm表示方法"><a href="#2-N-garm表示方法" class="headerlink" title="2. N-garm表示方法"></a>2. <code>N-garm</code>表示方法</h2><p>前面我们说，句子可以用但个字，词来表示，但是有的时候，我们可以用2个、3个或者多个词来表示。</p>
<p><code>N-gram</code>一组一组的词语，其中的<code>N</code>表示能够被一起使用的词的数量</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">59</span>]: text = <span class="hljs-string">&quot;深度学习（英语：deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。&quot;</span><br><br>In [<span class="hljs-number">60</span>]: cuted = jieba.lcut(text)<br><br>In [<span class="hljs-number">61</span>]: [cuted[i:i+<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(cuted)-<span class="hljs-number">1</span>)] <span class="hljs-comment">#N-gram 中n=2时</span><br>Out[<span class="hljs-number">61</span>]:[[<span class="hljs-string">&#x27;深度&#x27;</span>, <span class="hljs-string">&#x27;学习&#x27;</span>],<br> [<span class="hljs-string">&#x27;学习&#x27;</span>, <span class="hljs-string">&#x27;（&#x27;</span>],<br> [<span class="hljs-string">&#x27;（&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>],<br> [<span class="hljs-string">&#x27;英语&#x27;</span>, <span class="hljs-string">&#x27;：&#x27;</span>],<br> [<span class="hljs-string">&#x27;：&#x27;</span>, <span class="hljs-string">&#x27;deep&#x27;</span>],<br> [<span class="hljs-string">&#x27;deep&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>],<br> [<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-string">&#x27;learning&#x27;</span>],<br> [<span class="hljs-string">&#x27;learning&#x27;</span>, <span class="hljs-string">&#x27;）&#x27;</span>],<br> [<span class="hljs-string">&#x27;）&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>],<br> [<span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;机器&#x27;</span>],<br> [<span class="hljs-string">&#x27;机器&#x27;</span>, <span class="hljs-string">&#x27;学习&#x27;</span>],<br> [<span class="hljs-string">&#x27;学习&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>],<br> [<span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;分支&#x27;</span>],<br> [<span class="hljs-string">&#x27;分支&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>],<br> [<span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;是&#x27;</span>],<br> [<span class="hljs-string">&#x27;是&#x27;</span>, <span class="hljs-string">&#x27;一种&#x27;</span>],<br> [<span class="hljs-string">&#x27;一种&#x27;</span>, <span class="hljs-string">&#x27;以&#x27;</span>],<br> [<span class="hljs-string">&#x27;以&#x27;</span>, <span class="hljs-string">&#x27;人工神经网络&#x27;</span>],<br> [<span class="hljs-string">&#x27;人工神经网络&#x27;</span>, <span class="hljs-string">&#x27;为&#x27;</span>],<br> [<span class="hljs-string">&#x27;为&#x27;</span>, <span class="hljs-string">&#x27;架构&#x27;</span>],<br> [<span class="hljs-string">&#x27;架构&#x27;</span>, <span class="hljs-string">&#x27;，&#x27;</span>],<br> [<span class="hljs-string">&#x27;，&#x27;</span>, <span class="hljs-string">&#x27;对&#x27;</span>],<br> [<span class="hljs-string">&#x27;对&#x27;</span>, <span class="hljs-string">&#x27;数据&#x27;</span>],<br> [<span class="hljs-string">&#x27;数据&#x27;</span>, <span class="hljs-string">&#x27;进行&#x27;</span>],<br> [<span class="hljs-string">&#x27;进行&#x27;</span>, <span class="hljs-string">&#x27;表征&#x27;</span>],<br> [<span class="hljs-string">&#x27;表征&#x27;</span>, <span class="hljs-string">&#x27;学习&#x27;</span>],<br> [<span class="hljs-string">&#x27;学习&#x27;</span>, <span class="hljs-string">&#x27;的&#x27;</span>],<br> [<span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-string">&#x27;算法&#x27;</span>],<br> [<span class="hljs-string">&#x27;算法&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]]<br></code></pre></td></tr></table></figure>

<p>在传统的机器学习中，使用N-gram方法往往能够取得非常好的效果，但是在深度学习比如RNN中会自带N-gram的效果。</p>
<h2 id="3-向量化"><a href="#3-向量化" class="headerlink" title="3. 向量化"></a>3. 向量化</h2><p>因为文本不能够直接被模型计算，所以需要将其转化为向量</p>
<p>把文本转化为向量有两种方法：</p>
<ol>
<li>转化为one-hot编码</li>
<li>转化为word embedding</li>
</ol>
<h3 id="3-1-one-hot-编码"><a href="#3-1-one-hot-编码" class="headerlink" title="3.1 one-hot 编码"></a>3.1 one-hot 编码</h3><p>在one-hot编码中，每一个token使用一个长度为N的向量表示，N表示词典的数量</p>
<p>即：把待处理的文档进行分词或者是N-gram处理，然后进行去重得到词典，假设我们有一个文档：<code>深度学习</code>，那么进行one-hot处理后的结果如下：</p>
<table>
<thead>
<tr>
<th>token</th>
<th>one-hot encoding</th>
</tr>
</thead>
<tbody><tr>
<td>深</td>
<td>1000</td>
</tr>
<tr>
<td>度</td>
<td>0100</td>
</tr>
<tr>
<td>学</td>
<td>0010</td>
</tr>
<tr>
<td>习</td>
<td>0001</td>
</tr>
</tbody></table>
<h3 id="3-2-word-embedding"><a href="#3-2-word-embedding" class="headerlink" title="3.2 word embedding"></a>3.2 word embedding</h3><p>word embedding是深度学习中表示文本常用的一种方法。和one-hot编码不同，word embedding使用了浮点型的稠密矩阵来表示token。根据词典的大小，我们的向量通常使用不同的维度，例如100,256,300等。其中向量中的每一个值是一个参数，其初始值是随机生成的，之后会在训练的过程中进行学习而获得。</p>
<p>如果我们文本中有20000个词语，如果使用one-hot编码，那么我们会有20000*20000的矩阵，其中大多数的位置都为0，但是如果我们使用word embedding来表示的话，只需要20000* 维度，比如20000*300</p>
<p>形象的表示就是：</p>
<table>
<thead>
<tr>
<th>token</th>
<th>num</th>
<th>vector</th>
</tr>
</thead>
<tbody><tr>
<td>词1</td>
<td>0</td>
<td><code>[w11,w12,w13...w1N]</code> ,其中N表示维度（dimension）</td>
</tr>
<tr>
<td>词2</td>
<td>1</td>
<td><code>[w21,w22,w23...w2N] </code></td>
</tr>
<tr>
<td>词3</td>
<td>2</td>
<td><code>[w31,w23,w33...w3N] </code></td>
</tr>
<tr>
<td>…</td>
<td>….</td>
<td>…</td>
</tr>
<tr>
<td>词m</td>
<td>m</td>
<td><code>[wm1,wm2,wm3...wmN]</code>,其中m表示词典的大小</td>
</tr>
</tbody></table>
<p>我们会把所有的文本转化为向量，把句子用向量来表示</p>
<p>但是在这中间，<strong>我们会先把token使用数字来表示，再把数字使用向量来表示。</strong></p>
<p>即：<code>token---&gt; num ----&gt;vector</code></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/word_embedding.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-3-word-embedding-API"><a href="#3-3-word-embedding-API" class="headerlink" title="3.3 word embedding API"></a>3.3 word embedding API</h3><p><code>torch.nn.Embedding(num_embeddings,embedding_dim)</code></p>
<p>参数介绍：</p>
<ol>
<li><code>num_embeddings</code>：词典的大小</li>
<li><code>embedding_dim</code>：embedding的维度</li>
</ol>
<p>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">embedding = nn.Embedding(vocab_size,<span class="hljs-number">300</span>) <span class="hljs-comment">#实例化</span><br>input_embeded = embedding(<span class="hljs-built_in">input</span>)         <span class="hljs-comment">#进行embedding的操作</span><br></code></pre></td></tr></table></figure>

<h3 id="3-4-数据的形状变化"><a href="#3-4-数据的形状变化" class="headerlink" title="3.4 数据的形状变化"></a>3.4 数据的形状变化</h3><p>思考：每个batch中的每个句子有10个词语，经过形状为[20，4]的Word emebedding之后，原来的句子会变成什么形状？</p>
<p>每个词语用长度为4的向量表示，所以，最终句子会变为<code>[batch_size,10,4]</code>的形状。</p>
<p>增加了一个维度，这个维度是embedding的dim</p>
<h1 id="文本情感分类"><a href="#文本情感分类" class="headerlink" title="文本情感分类"></a>文本情感分类</h1><h2 id="目标-8"><a href="#目标-8" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道文本处理的基本方法</li>
<li>能够使用数据实现情感分类的</li>
</ol>
<h2 id="1-案例介绍"><a href="#1-案例介绍" class="headerlink" title="1. 案例介绍"></a>1. 案例介绍</h2><p>为了对前面的word embedding这种常用的文本向量化的方法进行巩固，这里我们会完成一个文本情感分类的案例</p>
<p>现在我们有一个经典的数据集<code>IMDB</code>数据集，地址：<code>http://ai.stanford.edu/~amaas/data/sentiment/</code>，这是一份包含了5万条流行电影的评论数据，其中训练集25000条，测试集25000条。数据格式如下：</p>
<p>下图左边为名称，其中名称包含两部分，分别是序号和情感评分，（1-4为neg，5-10为pos），右边为评论内容</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A0%B7%E6%9C%AC%E5%90%8D%E7%A7%B0.png" srcset="/img/loading.gif" lazyload></p>
<p>根据上述的样本，需要使用pytorch完成模型，实现对评论情感进行预测</p>
<h2 id="2-思路分析"><a href="#2-思路分析" class="headerlink" title="2. 思路分析"></a>2. 思路分析</h2><p>首先可以把上述问题定义为分类问题，情感评分分为1-10，10个类别（也可以理解为回归问题，这里当做分类问题考虑）。那么根据之前的经验，我们的大致流程如下：</p>
<ol>
<li>准备数据集</li>
<li>构建模型</li>
<li>模型训练</li>
<li>模型评估</li>
</ol>
<p>知道思路之后，那么我们一步步来完成上述步骤</p>
<h2 id="3-准备数据集"><a href="#3-准备数据集" class="headerlink" title="3. 准备数据集"></a>3. 准备数据集</h2><p>准备数据集和之前的方法一样，实例化dataset，准备dataloader，最终我们的数据可以处理成如下格式：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB-data%E5%8A%A0%E8%BD%BD1.png" srcset="/img/loading.gif" lazyload></p>
<p>其中有两点需要注意：</p>
<ol>
<li>如何完成基础打Dataset的构建和Dataloader的准备</li>
<li>每个batch中文本的长度不一致的问题如何解决</li>
<li>每个batch中的文本如何转化为数字序列</li>
</ol>
<h3 id="3-1-基础Dataset的准备"><a href="#3-1-基础Dataset的准备" class="headerlink" title="3.1 基础Dataset的准备"></a>3.1 基础Dataset的准备</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader,Dataset<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> re<br><br>data_base_path = <span class="hljs-string">r&quot;data\aclImdb&quot;</span><br><br><span class="hljs-comment">#1. 定义tokenize的方法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># fileters = &#x27;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`&#123;|&#125;~\t\n&#x27;</span><br>    fileters = [<span class="hljs-string">&#x27;!&#x27;</span>,<span class="hljs-string">&#x27;&quot;&#x27;</span>,<span class="hljs-string">&#x27;#&#x27;</span>,<span class="hljs-string">&#x27;$&#x27;</span>,<span class="hljs-string">&#x27;%&#x27;</span>,<span class="hljs-string">&#x27;&amp;&#x27;</span>,<span class="hljs-string">&#x27;\(&#x27;</span>,<span class="hljs-string">&#x27;\)&#x27;</span>,<span class="hljs-string">&#x27;\*&#x27;</span>,<span class="hljs-string">&#x27;\+&#x27;</span>,<span class="hljs-string">&#x27;,&#x27;</span>,<span class="hljs-string">&#x27;-&#x27;</span>,<span class="hljs-string">&#x27;\.&#x27;</span>,<span class="hljs-string">&#x27;/&#x27;</span>,<span class="hljs-string">&#x27;:&#x27;</span>,<span class="hljs-string">&#x27;;&#x27;</span>,<span class="hljs-string">&#x27;&lt;&#x27;</span>,<span class="hljs-string">&#x27;=&#x27;</span>,<span class="hljs-string">&#x27;&gt;&#x27;</span>,<span class="hljs-string">&#x27;\?&#x27;</span>,<span class="hljs-string">&#x27;@&#x27;</span><br>        ,<span class="hljs-string">&#x27;\[&#x27;</span>,<span class="hljs-string">&#x27;\\&#x27;</span>,<span class="hljs-string">&#x27;\]&#x27;</span>,<span class="hljs-string">&#x27;^&#x27;</span>,<span class="hljs-string">&#x27;_&#x27;</span>,<span class="hljs-string">&#x27;`&#x27;</span>,<span class="hljs-string">&#x27;\&#123;&#x27;</span>,<span class="hljs-string">&#x27;\|&#x27;</span>,<span class="hljs-string">&#x27;\&#125;&#x27;</span>,<span class="hljs-string">&#x27;~&#x27;</span>,<span class="hljs-string">&#x27;\t&#x27;</span>,<span class="hljs-string">&#x27;\n&#x27;</span>,<span class="hljs-string">&#x27;\x97&#x27;</span>,<span class="hljs-string">&#x27;\x96&#x27;</span>,<span class="hljs-string">&#x27;”&#x27;</span>,<span class="hljs-string">&#x27;“&#x27;</span>,]<br>    text = re.sub(<span class="hljs-string">&quot;&lt;.*?&gt;&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,text,flags=re.S)<br>    text = re.sub(<span class="hljs-string">&quot;|&quot;</span>.join(fileters),<span class="hljs-string">&quot; &quot;</span>,text,flags=re.S)<br>    <span class="hljs-keyword">return</span> [i.strip() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> text.split()]<br><br><span class="hljs-comment">#2. 准备dataset</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ImdbDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,mode</span>):<br>        <span class="hljs-built_in">super</span>(ImdbDataset,self).__init__()<br>        <span class="hljs-keyword">if</span> mode==<span class="hljs-string">&quot;train&quot;</span>:<br>            text_path = [os.path.join(data_base_path,i)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;train/neg&quot;</span>,<span class="hljs-string">&quot;train/pos&quot;</span>]]<br>        <span class="hljs-keyword">else</span>:<br>            text_path =  [os.path.join(data_base_path,i)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;test/neg&quot;</span>,<span class="hljs-string">&quot;test/pos&quot;</span>]]<br><br>        self.total_file_path_list = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> text_path:<br>            self.total_file_path_list.extend([os.path.join(i,j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> os.listdir(i)])<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        cur_path = self.total_file_path_list[idx]<br><br>        cur_filename = os.path.basename(cur_path)<br>        label = <span class="hljs-built_in">int</span>(cur_filename.split(<span class="hljs-string">&quot;_&quot;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;.&quot;</span>)[<span class="hljs-number">0</span>]) -<span class="hljs-number">1</span> <span class="hljs-comment">#处理标题，获取label，转化为从[0-9]</span><br>        text = tokenize(<span class="hljs-built_in">open</span>(cur_path).read().strip()) <span class="hljs-comment">#直接按照空格进行分词</span><br>        <span class="hljs-keyword">return</span> label,text<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.total_file_path_list)<br>    <br> <span class="hljs-comment"># 2. 实例化，准备dataloader</span><br>dataset = ImdbDataset(mode=<span class="hljs-string">&quot;train&quot;</span>)<br>dataloader = DataLoader(dataset=dataset,batch_size=<span class="hljs-number">2</span>,shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment">#3. 观察数据输出结果</span><br><span class="hljs-keyword">for</span> idx,(label,text) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;idx：&quot;</span>,idx)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;table:&quot;</span>,label)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;text:&quot;</span>,text)<br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">idx： <span class="hljs-number">0</span><br>table: tensor([<span class="hljs-number">3</span>, <span class="hljs-number">1</span>])<br>text: [(<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;Want&#x27;</span>), (<span class="hljs-string">&#x27;thought&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>), (<span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;great&#x27;</span>), (<span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-string">&#x27;recipe&#x27;</span>), (<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>), (<span class="hljs-string">&#x27;great&#x27;</span>, <span class="hljs-string">&#x27;failure&#x27;</span>), (<span class="hljs-string">&#x27;idea&#x27;</span>, <span class="hljs-string">&#x27;Take&#x27;</span>), (<span class="hljs-string">&#x27;but&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>), (<span class="hljs-string">&#x27;boy&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>), (<span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>), (<span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&#x27;plot&#x27;</span>), (<span class="hljs-string">&#x27;poorly&#x27;</span>, <span class="hljs-string">&#x27;add&#x27;</span>), (<span class="hljs-string">&#x27;executed&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>), (<span class="hljs-string">&#x27;We&#x27;</span>, <span class="hljs-string">&#x27;some&#x27;</span>), (<span class="hljs-string">&#x27;do&#x27;</span>, <span class="hljs-string">&#x27;weak&#x27;</span>), (<span class="hljs-string">&#x27;get&#x27;</span>, <span class="hljs-string">&#x27;completely&#x27;</span>), (<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;undeveloped&#x27;</span>), (<span class="hljs-string">&#x27;broad&#x27;</span>, <span class="hljs-string">&#x27;characters&#x27;</span>), (<span class="hljs-string">&#x27;sense&#x27;</span>, <span class="hljs-string">&#x27;and&#x27;</span>), (<span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;than&#x27;</span>), (<span class="hljs-string">&#x27;how&#x27;</span>, <span class="hljs-string">&#x27;throw&#x27;</span>), (<span class="hljs-string">&#x27;complex&#x27;</span>, <span class="hljs-string">&#x27;in&#x27;</span>), (<span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), (<span class="hljs-string">&#x27;challenging&#x27;</span>, <span class="hljs-string">&#x27;worst&#x27;</span>), (<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;special&#x27;</span>), (<span class="hljs-string">&#x27;backstage&#x27;</span>, <span class="hljs-string">&#x27;effects&#x27;</span>), (<span class="hljs-string">&#x27;operations&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>), (<span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;horror&#x27;</span>), (<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;movie&#x27;</span>), (<span class="hljs-string">&#x27;show&#x27;</span>, <span class="hljs-string">&#x27;has&#x27;</span>), (<span class="hljs-string">&#x27;are&#x27;</span>, <span class="hljs-string">&#x27;known&#x27;</span>), (<span class="hljs-string">&#x27;but&#x27;</span>, <span class="hljs-string">&#x27;Let&#x27;</span>), (<span class="hljs-string">&#x27;virtually&#x27;</span>, <span class="hljs-string">&#x27;stew&#x27;</span>), (<span class="hljs-string">&#x27;no&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>), ...(<span class="hljs-string">&#x27;show&#x27;</span>, <span class="hljs-string">&#x27;somehow&#x27;</span>), (<span class="hljs-string">&#x27;rather&#x27;</span>, <span class="hljs-string">&#x27;destroy&#x27;</span>), (<span class="hljs-string">&#x27;than&#x27;</span>, <span class="hljs-string">&#x27;every&#x27;</span>), (<span class="hljs-string">&#x27;anything&#x27;</span>, <span class="hljs-string">&#x27;copy&#x27;</span>), (<span class="hljs-string">&#x27;worth&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>), (<span class="hljs-string">&#x27;watching&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>), (<span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;film&#x27;</span>), (<span class="hljs-string">&#x27;its&#x27;</span>, <span class="hljs-string">&#x27;so&#x27;</span>), (<span class="hljs-string">&#x27;own&#x27;</span>, <span class="hljs-string">&#x27;it&#x27;</span>), (<span class="hljs-string">&#x27;merit&#x27;</span>, <span class="hljs-string">&#x27;will&#x27;</span>)]<br></code></pre></td></tr></table></figure>

<p>明显，其中的text内容出现对应，和想象的不太相似，出现问题的原因在于<code>Dataloader</code>中的参数<code>collate_fn</code></p>
<p><code>collate_fn</code>的默认值为torch自定义的<code>default_collate</code>,<code>collate_fn</code>的作用就是对每个batch进行处理，而默认的<code>default_collate</code>处理出错。</p>
<p>解决问题的思路：</p>
<p>手段1：考虑先把数据转化为数字序列，观察其结果是否符合要求，之前使用DataLoader并未出现类似错误</p>
<p>手段2：考虑自定义一个<code>collate_fn</code>，观察结果</p>
<p>这里使用方式2，自定义一个<code>collate_fn</code>,然后观察结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):<br>	<span class="hljs-comment">#batch是list，其中是一个一个元组，每个元组是dataset中__getitem__的结果</span><br>    batch = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(*batch))<br>    labes = torch.tensor(batch[<span class="hljs-number">0</span>],dtype=torch.int32)<br>    texts = batch[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">del</span> batch<br>    <span class="hljs-keyword">return</span> labes,texts<br>dataloader = DataLoader(dataset=dataset,batch_size=<span class="hljs-number">2</span>,shuffle=<span class="hljs-literal">True</span>,collate_fn=collate_fn)<br><br><span class="hljs-comment">#此时输出正常</span><br><span class="hljs-keyword">for</span> idx,(label,text) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;idx：&quot;</span>,idx)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;table:&quot;</span>,label)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;text:&quot;</span>,text)<br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure>



<h3 id="3-2-文本序列化"><a href="#3-2-文本序列化" class="headerlink" title="3.2 文本序列化"></a>3.2 文本序列化</h3><blockquote>
<p>再介绍word embedding的时候，我们说过，不会直接把文本转化为向量，而是先转化为数字，再把数字转化为向量，那么这个过程该如何实现呢？</p>
</blockquote>
<p>这里我们可以考虑把文本中的每个<strong>词语和其对应的数字，使用字典保存</strong>，同时实现方法<strong>把句子通过字典映射为包含数字的列表</strong>。</p>
<p>实现文本序列化之前，考虑以下几点:</p>
<ol>
<li>如何使用字典把词语和数字进行对应</li>
<li>不同的词语出现的次数不尽相同，是否需要对高频或者低频词语进行过滤，以及总的词语数量是否需要进行限制</li>
<li>得到词典之后，如何把句子转化为数字序列，如何把数字序列转化为句子</li>
<li>不同句子长度不相同，每个batch的句子如何构造成相同的长度（可以对短句子进行填充，填充特殊字符）</li>
<li>对于新出现的词语在词典中没有出现怎么办（可以使用特殊字符代理）</li>
</ol>
<p>思路分析：</p>
<ol>
<li>对所有句子进行分词</li>
<li>词语存入字典，根据次数对词语进行过滤，并统计次数</li>
<li>实现文本转数字序列的方法</li>
<li>实现数字序列转文本方法</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Word2Sequence</span>():<br>    UNK_TAG = <span class="hljs-string">&quot;UNK&quot;</span><br>    PAD_TAG = <span class="hljs-string">&quot;PAD&quot;</span><br><br>    UNK = <span class="hljs-number">0</span><br>    PAD = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.<span class="hljs-built_in">dict</span> = &#123;<br>            self.UNK_TAG :self.UNK,<br>            self.PAD_TAG :self.PAD<br>        &#125;<br>        self.fited = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_index</span>(<span class="hljs-params">self,word</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;word -&gt; index&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited == <span class="hljs-literal">True</span>,<span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br>        <span class="hljs-keyword">return</span> self.<span class="hljs-built_in">dict</span>.get(word,self.UNK)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_word</span>(<span class="hljs-params">self,index</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;index -&gt; word&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited , <span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br>        <span class="hljs-keyword">if</span> index <span class="hljs-keyword">in</span> self.inversed_dict:<br>            <span class="hljs-keyword">return</span> self.inversed_dict[index]<br>        <span class="hljs-keyword">return</span> self.UNK_TAG<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self(self.<span class="hljs-built_in">dict</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, sentences, min_count=<span class="hljs-number">1</span>, max_count=<span class="hljs-literal">None</span>, max_feature=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param sentences:[[word1,word2,word3],[word1,word3,wordn..],...]</span><br><span class="hljs-string">        :param min_count: 最小出现的次数</span><br><span class="hljs-string">        :param max_count: 最大出现的次数</span><br><span class="hljs-string">        :param max_feature: 总词语的最大数量</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        count = &#123;&#125;<br>        <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences:<br>            <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> sentence:<br>                <span class="hljs-keyword">if</span> a <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> count:<br>                    count[a] = <span class="hljs-number">0</span><br>                count[a] += <span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># 比最小的数量大和比最大的数量小的需要</span><br>        <span class="hljs-keyword">if</span> min_count <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            count = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> count.items() <span class="hljs-keyword">if</span> v &gt;= min_count&#125;<br>        <span class="hljs-keyword">if</span> max_count <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            count = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> count.items() <span class="hljs-keyword">if</span> v &lt;= max_count&#125;<br><br>        <span class="hljs-comment"># 限制最大的数量</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(max_feature, <span class="hljs-built_in">int</span>):<br>            count = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(count.items()), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">if</span> max_feature <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(count) &gt; max_feature:<br>                count = count[-<span class="hljs-built_in">int</span>(max_feature):]<br>            <span class="hljs-keyword">for</span> w, _ <span class="hljs-keyword">in</span> count:<br>                self.<span class="hljs-built_in">dict</span>[w] = <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(count.keys()):<br>                self.<span class="hljs-built_in">dict</span>[w] = <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br><br>        self.fited = <span class="hljs-literal">True</span><br>        <span class="hljs-comment"># 准备一个index-&gt;word的字典</span><br>        self.inversed_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.<span class="hljs-built_in">dict</span>.values(), self.<span class="hljs-built_in">dict</span>.keys()))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self, sentence,max_len=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        实现吧句子转化为数组（向量）</span><br><span class="hljs-string">        :param sentence:</span><br><span class="hljs-string">        :param max_len:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited, <span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br>        <span class="hljs-keyword">if</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            r = [self.PAD]*max_len<br>        <span class="hljs-keyword">else</span>:<br>            r = [self.PAD]*<span class="hljs-built_in">len</span>(sentence)<br>        <span class="hljs-keyword">if</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(sentence)&gt;max_len:<br>            sentence=sentence[:max_len]<br>        <span class="hljs-keyword">for</span> index,word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sentence):<br>            r[index] = self.to_index(word)<br>        <span class="hljs-keyword">return</span> np.array(r,dtype=np.int64)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inverse_transform</span>(<span class="hljs-params">self,indices</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        实现从数组 转化为文字</span><br><span class="hljs-string">        :param indices: [1,2,3....]</span><br><span class="hljs-string">        :return:[word1,word2.....]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        sentence = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices:<br>            word = self.to_word(i)<br>            sentence.append(word)<br>        <span class="hljs-keyword">return</span> sentence<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    w2s = Word2Sequence()<br>    w2s.fit([<br>        [<span class="hljs-string">&quot;你&quot;</span>, <span class="hljs-string">&quot;好&quot;</span>, <span class="hljs-string">&quot;么&quot;</span>],<br>        [<span class="hljs-string">&quot;你&quot;</span>, <span class="hljs-string">&quot;好&quot;</span>, <span class="hljs-string">&quot;哦&quot;</span>]])<br><br>    <span class="hljs-built_in">print</span>(w2s.<span class="hljs-built_in">dict</span>)<br>    <span class="hljs-built_in">print</span>(w2s.fited)<br>    <span class="hljs-built_in">print</span>(w2s.transform([<span class="hljs-string">&quot;你&quot;</span>,<span class="hljs-string">&quot;好&quot;</span>,<span class="hljs-string">&quot;嘛&quot;</span>]))<br>    <span class="hljs-built_in">print</span>(w2s.transform([<span class="hljs-string">&quot;你好嘛&quot;</span>],max_len=<span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>

<p>完成了<code>wordsequence</code>之后，接下来就是保存现有样本中的数据字典，方便后续的使用。</p>
<p>实现对IMDB数据的处理和保存</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#1. 对IMDB的数据记性fit操作</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fit_save_word_sequence</span>():<br>    <span class="hljs-keyword">from</span> wordSequence <span class="hljs-keyword">import</span> Word2Sequence<br><br>    ws = Word2Sequence()<br>    train_path = [os.path.join(data_base_path,i)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;train/neg&quot;</span>,<span class="hljs-string">&quot;train/pos&quot;</span>]]<br>    total_file_path_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> train_path:<br>        total_file_path_list.extend([os.path.join(i, j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> os.listdir(i)])<br>    <span class="hljs-keyword">for</span> cur_path <span class="hljs-keyword">in</span> tqdm(total_file_path_list,<span class="hljs-built_in">ascii</span>=<span class="hljs-literal">True</span>,desc=<span class="hljs-string">&quot;fitting&quot;</span>):<br>        ws.fit(tokenize(<span class="hljs-built_in">open</span>(cur_path).read().strip()))<br>    ws.build_vocab()<br>    <span class="hljs-comment"># 对wordSequesnce进行保存</span><br>    pickle.dump(ws,<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./model/ws.pkl&quot;</span>,<span class="hljs-string">&quot;wb&quot;</span>))<br><br><span class="hljs-comment">#2. 在dataset中使用wordsequence</span><br>ws = pickle.load(<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./model/ws.pkl&quot;</span>,<span class="hljs-string">&quot;rb&quot;</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):<br>    MAX_LEN = <span class="hljs-number">500</span> <br>    <span class="hljs-comment">#MAX_LEN = max([len(i) for i in texts]) #取当前batch的最大值作为batch的最大长度</span><br><br>    batch = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(*batch))<br>    labes = torch.tensor(batch[<span class="hljs-number">0</span>],dtype=torch.<span class="hljs-built_in">int</span>)<br><br>    texts = batch[<span class="hljs-number">1</span>]<br>    <span class="hljs-comment">#获取每个文本的长度</span><br>    lengths = [<span class="hljs-built_in">len</span>(i) <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(i)&lt;MAX_LEN <span class="hljs-keyword">else</span> MAX_LEN <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> texts]<br>    texts = torch.tensor([ws.transform(i, MAX_LEN) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> texts])<br>    <span class="hljs-keyword">del</span> batch<br>    <span class="hljs-keyword">return</span> labes,texts,lengths<br><br><span class="hljs-comment">#3. 获取输出</span><br>dataset = ImdbDataset(ws,mode=<span class="hljs-string">&quot;train&quot;</span>)<br>    dataloader = DataLoader(dataset=dataset,batch_size=<span class="hljs-number">20</span>,shuffle=<span class="hljs-literal">True</span>,collate_fn=collate_fn)<br>    <span class="hljs-keyword">for</span> idx,(label,text,length) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;idx：&quot;</span>,idx)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;table:&quot;</span>,label)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;text:&quot;</span>,text)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;length:&quot;</span>,length)<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure>

<p>输出如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">idx： <span class="hljs-number">0</span><br>table: tensor([ <span class="hljs-number">7</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">1</span>, <span class="hljs-number">10</span>,  <span class="hljs-number">7</span>, <span class="hljs-number">10</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">7</span>, <span class="hljs-number">10</span>,<br>         <span class="hljs-number">1</span>,  <span class="hljs-number">4</span>], dtype=torch.int32)<br>text: tensor([[ <span class="hljs-number">50983</span>,  <span class="hljs-number">77480</span>,  <span class="hljs-number">82366</span>,  ...,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">54702</span>,  <span class="hljs-number">57262</span>, <span class="hljs-number">102035</span>,  ...,  <span class="hljs-number">80474</span>,  <span class="hljs-number">56457</span>,  <span class="hljs-number">63180</span>],<br>        [ <span class="hljs-number">26991</span>,  <span class="hljs-number">57693</span>,  <span class="hljs-number">88450</span>,  ...,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>],<br>        ...,<br>        [ <span class="hljs-number">51138</span>,  <span class="hljs-number">73263</span>,  <span class="hljs-number">80428</span>,  ...,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>],<br>        [  <span class="hljs-number">7022</span>,  <span class="hljs-number">78114</span>,  <span class="hljs-number">83498</span>,  ...,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>],<br>        [  <span class="hljs-number">5353</span>, <span class="hljs-number">101803</span>,  <span class="hljs-number">99148</span>,  ...,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">1</span>]])<br>length: [<span class="hljs-number">296</span>, <span class="hljs-number">500</span>, <span class="hljs-number">221</span>, <span class="hljs-number">132</span>, <span class="hljs-number">74</span>, <span class="hljs-number">407</span>, <span class="hljs-number">500</span>, <span class="hljs-number">130</span>, <span class="hljs-number">54</span>, <span class="hljs-number">217</span>, <span class="hljs-number">80</span>, <span class="hljs-number">322</span>, <span class="hljs-number">72</span>, <span class="hljs-number">156</span>, <span class="hljs-number">94</span>, <span class="hljs-number">270</span>, <span class="hljs-number">317</span>, <span class="hljs-number">117</span>, <span class="hljs-number">200</span>, <span class="hljs-number">379</span>]<br><br></code></pre></td></tr></table></figure>

<blockquote>
<p>思考：前面我们自定义了MAX_LEN作为句子的最大长度，如果我们需要把每个batch中的最长的句子长度作为当前batch的最大长度，该如何实现？</p>
</blockquote>
<h2 id="4-构建模型"><a href="#4-构建模型" class="headerlink" title="4. 构建模型"></a>4. 构建模型</h2><p>这里我们只练习使用word embedding，所以模型只有一层，即：</p>
<ol>
<li>数据经过word embedding</li>
<li>数据通过全连接层返回结果，计算<code>log_softmax</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">from</span> build_dataset <span class="hljs-keyword">import</span> get_dataloader,ws,MAX_LEN<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">IMDBModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,max_len</span>):<br>        <span class="hljs-built_in">super</span>(IMDBModel,self).__init__()<br>        self.embedding = nn.Embedding(<span class="hljs-built_in">len</span>(ws),<span class="hljs-number">300</span>,padding_idx=ws.PAD) <span class="hljs-comment">#[N,300]</span><br>        self.fc = nn.Linear(max_len*<span class="hljs-number">300</span>,<span class="hljs-number">10</span>)  <span class="hljs-comment">#[max_len*300,10]</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        embed = self.embedding(x) <span class="hljs-comment">#[batch_size,max_len,300]</span><br>        embed = embed.view(x.size(<span class="hljs-number">0</span>),-<span class="hljs-number">1</span>)<br>        out = self.fc(embed)<br>        <span class="hljs-keyword">return</span> F.log_softmax(out,dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>



<h2 id="5-模型的训练和评估"><a href="#5-模型的训练和评估" class="headerlink" title="5. 模型的训练和评估"></a>5. 模型的训练和评估</h2><p>训练流程和之前相同</p>
<ol>
<li>实例化模型，损失函数，优化器</li>
<li>遍历dataset_loader，梯度置为0，进行向前计算</li>
<li>计算损失，反向传播优化损失，更新参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python">train_batch_size = <span class="hljs-number">128</span><br>test_batch_size = <span class="hljs-number">1000</span><br>imdb_model = IMDBModel(MAX_LEN)<br>optimizer = optim.Adam(imdb_model.parameters())<br>criterion = nn.CrossEntropyLoss()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    mode = <span class="hljs-literal">True</span><br>    imdb_model.train(mode)<br>    train_dataloader =get_dataloader(mode,train_batch_size)<br>    <span class="hljs-keyword">for</span> idx,(target,<span class="hljs-built_in">input</span>,input_lenght) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        optimizer.zero_grad()<br>        output = imdb_model(<span class="hljs-built_in">input</span>)<br>        loss = F.nll_loss(output,target) <span class="hljs-comment">#traget需要是[0,9]，不能是[1-10]</span><br>        loss.backward()<br>        optimizer.step()<br>        <span class="hljs-keyword">if</span> idx %<span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, idx * <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                       <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item()))<br><br>            torch.save(imdb_model.state_dict(), <span class="hljs-string">&quot;model/mnist_net.pkl&quot;</span>)<br>            torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;model/mnist_optimizer.pkl&#x27;</span>)<br>            <br> <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    mode = <span class="hljs-literal">False</span><br>    imdb_model.<span class="hljs-built_in">eval</span>()<br>    test_dataloader = get_dataloader(mode, test_batch_size)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> target, <span class="hljs-built_in">input</span>, input_lenght <span class="hljs-keyword">in</span> test_dataloader:<br>            output = imdb_model(<span class="hljs-built_in">input</span>)<br>            test_loss  += F.nll_loss(output, target,reduction=<span class="hljs-string">&quot;sum&quot;</span>)<br>            pred = torch.<span class="hljs-built_in">max</span>(output,dim=-<span class="hljs-number">1</span>,keepdim=<span class="hljs-literal">False</span>)[-<span class="hljs-number">1</span>]<br>            correct = pred.eq(target.data).<span class="hljs-built_in">sum</span>()<br>        test_loss = test_loss/<span class="hljs-built_in">len</span>(test_dataloader.dataset)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&#x27;</span>.<span class="hljs-built_in">format</span>(<br>            test_loss, correct, <span class="hljs-built_in">len</span>(test_dataloader.dataset),<br>            <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_dataloader.dataset)))<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    test()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        train(i)<br>        test()<br><br></code></pre></td></tr></table></figure>

<p>这里我们仅仅使用了一层全连接层，其分类效果不会很好，这里重点是理解常见的模型流程和word embedding的使用方法</p>
<h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><h2 id="目标-9"><a href="#目标-9" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够说出循环神经网络的概念和作用</li>
<li>能够说出循环神经网络的类型和应用场景</li>
<li>能够说出LSTM的作用和原理</li>
<li>能够说出GRU的作用和原理</li>
</ol>
<h2 id="1-循环神经网络的介绍"><a href="#1-循环神经网络的介绍" class="headerlink" title="1. 循环神经网络的介绍"></a>1. 循环神经网络的介绍</h2><blockquote>
<p>为什么有了神经网络还需要有循环神经网络？</p>
</blockquote>
<p>在普通的神经网络中，信息的传递是单向的，这种限制虽然使得网络变得更容易学习，但在一定程度上也减弱了神经网络模型的能力。特别是在很多现实任务中，网络的输出不仅和当前时刻的输入相关，也和其过去一段时间的输出相关。此外，普通网络难以处理时序数据，比如视频、语音、文本等，时序数据的长度一般是不固定的，而前馈神经网络要求输入和输出的维数都是固定的，不能任意改变。因此，当处理这一类和时序相关的问题时，就需要一种能力更强的模型。</p>
<p>循环神经网络（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其它神经元的信息，也可以接受自身的信息，形成具有环路的网络结构。换句话说：神经元的输出可以在下一个时间步直接作用到自身（</p>
<p>入）</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%9B%BE.png" srcset="/img/loading.gif" lazyload></p>
<p>通过简化图，我们看到RNN比传统的神经网络多了一个循环圈，这个循环表示的就是在下一个时间步（<strong>Time Step</strong>）上会返回作为输入的一部分，我们把RNN在时间点上展开，得到的图形如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%B1%95%E5%BC%80.png" srcset="/img/loading.gif" lazyload></p>
<p>或者是：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E7%9A%84RNN%E5%B1%95%E5%BC%80%E5%9B%BE.png" srcset="/img/loading.gif" lazyload></p>
<p>在不同的时间步，RNN的输入都将与之前的时间状态有关，$t_n$时刻网络的输出结果是该时刻的输入和所有历史共同作用的结果，这就达到了对时间序列建模的目的。</p>
<p>RNN的不同表示和功能可以通过下图看出：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN%E5%8A%9F%E8%83%BD.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>图1：固定长度的输入和输出 (e.g. 图像分类)</li>
<li>图2：序列输出 (e.g.图像转文字)</li>
<li>图3：数列输入 (e.g. 文本分类)</li>
<li>图4：异步的序列输入和输出(e.g.文本翻译).</li>
<li>图5：同步的序列输入和输出 (e.g. 根据视频的每一帧来对视频进行分类)</li>
</ul>
<h2 id="2-LSTM和GRU"><a href="#2-LSTM和GRU" class="headerlink" title="2. LSTM和GRU"></a>2. LSTM和GRU</h2><h3 id="2-1-LSTM的基础介绍"><a href="#2-1-LSTM的基础介绍" class="headerlink" title="2.1 LSTM的基础介绍"></a>2.1 LSTM的基础介绍</h3><p>假如现在有这样一个需求，根据现有文本预测下一个词语，比如<code>天上的云朵漂浮在__</code>，通过间隔不远的位置就可以预测出来词语是<code>天上</code>，但是对于其他一些句子，可能需要被预测的词语在前100个词语之前，那么此时由于间隔非常大，随着间隔的增加可能会导致真实的预测值对结果的影响变的非常小，而无法非常好的进行预测（RNN中的长期依赖问题（long-Term Dependencies））</p>
<p>那么为了解决这个问题需要<strong>LSTM</strong>（<strong>Long Short-Term Memory网络</strong>）</p>
<p>LSTM是一种RNN特殊的类型，可以学习长期依赖信息。在很多问题上，LSTM都取得相当巨大的成功，并得到了广泛的应用。</p>
<p>一个LSMT的单元就是下图中的一个绿色方框中的内容：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM1.jpg" srcset="/img/loading.gif" lazyload></p>
<p>其中$\sigma$表示sigmod函数，其他符号的含义：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM2.jpg" srcset="/img/loading.gif" lazyload></p>
<h3 id="2-2-LSTM的核心"><a href="#2-2-LSTM的核心" class="headerlink" title="2.2 LSTM的核心"></a>2.2 LSTM的核心</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM3.png" srcset="/img/loading.gif" lazyload></p>
<p>LSTM的核心在于单元（细胞）中的状态，也就是上图中最上面的那根线。</p>
<p>但是如果只有上面那一条线，那么没有办法实现信息的增加或者删除，所以在LSTM是通过一个叫做<code>门</code>的结构实现，门可以选择让信息通过或者不通过。</p>
<p>这个门主要是通过sigmoid和点乘（<code>pointwise multiplication</code>）实现的</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM4.png" srcset="/img/loading.gif" lazyload></p>
<p>我们都知道，$sigmoid$的取值范围是在(0,1)之间，如果接近0表示不让任何信息通过，如果接近1表示所有的信息都会通过</p>
<h3 id="2-3-逐步理解LSTM"><a href="#2-3-逐步理解LSTM" class="headerlink" title="2.3 逐步理解LSTM"></a>2.3 逐步理解LSTM</h3><h4 id="2-3-1-遗忘门"><a href="#2-3-1-遗忘门" class="headerlink" title="2.3.1 遗忘门"></a>2.3.1 遗忘门</h4><p>遗忘门通过sigmoid函数来决定哪些信息会被遗忘</p>
<p>在下图就是$h_{t-1}和x_t$进行合并（concat）之后乘上权重和偏置，通过sigmoid函数，输出0-1之间的一个值，这个值会和前一次的细胞状态($C_{t-1}$)进行点乘，从而决定遗忘或者保留</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%98%93%E7%8E%8B%E9%97%A8.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="2-3-2-输入门"><a href="#2-3-2-输入门" class="headerlink" title="2.3.2 输入门"></a>2.3.2 输入门</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BE%93%E5%85%A5%E9%97%A8.png" srcset="/img/loading.gif" lazyload></p>
<p>下一步就是决定哪些新的信息会被保留，这个过程有两步：</p>
<ol>
<li>一个被称为<code>输入门</code>的sigmoid 层决定哪些信息会被更新</li>
<li><code>tanh</code>会创造一个新的候选向量$\widetilde{C}_{t}$，后续可能会被添加到细胞状态中</li>
</ol>
<p>例如：</p>
<p><code>我昨天吃了苹果，今天我想吃菠萝</code>，在这个句子中，通过遗忘门可以遗忘<code>苹果</code>,同时更新新的主语为<code>菠萝</code></p>
<p>现在就可以更新旧的细胞状态$C_{t-1}$为新的$C_{ t }$ 了。</p>
<p>更新的构成很简单就是：</p>
<ol>
<li>旧的细胞状态和遗忘门的结果相乘</li>
<li>然后加上 输入门和tanh相乘的结果</li>
</ol>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM-update.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="2-3-3-输出门"><a href="#2-3-3-输出门" class="headerlink" title="2.3.3 输出门"></a>2.3.3 输出门</h4><p>最后，我们需要决定什么信息会被输出，也是一样这个输出经过变换之后会通过sigmoid函数的结果来决定那些细胞状态会被输出。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BE%93%E5%87%BA%E9%97%A8.png" srcset="/img/loading.gif" lazyload></p>
<p>步骤如下：</p>
<ol>
<li>前一次的输出和当前时间步的输入的组合结果通过sigmoid函数进行处理得到$O_t$</li>
<li>更新后的细胞状态$C_t$会经过tanh层的处理，把数据转化到(-1,1)的区间</li>
<li>tanh处理后的结果和$O_t$进行相乘，把结果输出同时传到下一个LSTM的单元</li>
</ol>
<h3 id="2-4-GRU，LSTM的变形"><a href="#2-4-GRU，LSTM的变形" class="headerlink" title="2.4 GRU，LSTM的变形"></a>2.4 GRU，LSTM的变形</h3><p>GRU(Gated Recurrent Unit),是一种LSTM的变形版本， 它将遗忘和输入门组合成一个“更新门”。它还合并了单元状态和隐藏状态，并进行了一些其他更改，由于他的模型比标准LSTM模型简单，所以越来越受欢迎。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GRU.png" srcset="/img/loading.gif" lazyload></p>
<p>LSTM内容参考地址：<a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
<h2 id="3-双向LSTM"><a href="#3-双向LSTM" class="headerlink" title="3. 双向LSTM"></a>3. 双向LSTM</h2><p>单向的 RNN，是根据前面的信息推出后面的，但有时候只看前面的词是不够的， 可能需要预测的词语和后面的内容也相关，那么此时需要一种机制，能够让模型不仅能够从前往后的具有记忆，还需要从后往前需要记忆。此时双向LSTM就可以帮助我们解决这个问题</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bidir_lstm.png" srcset="/img/loading.gif" lazyload></p>
<p>由于是双向LSTM，所以每个方向的LSTM都会有一个输出，最终的输出会有2部分，所以往往需要concat的操作</p>
<h1 id="循环神经网络实现文本情感分类"><a href="#循环神经网络实现文本情感分类" class="headerlink" title="循环神经网络实现文本情感分类"></a>循环神经网络实现文本情感分类</h1><h2 id="目标-10"><a href="#目标-10" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道LSTM和GRU的使用方法及输入输出的格式</li>
<li>能够应用LSTM和GRU实现文本情感分类</li>
</ol>
<h2 id="1-Pytorch中LSTM和GRU模块使用"><a href="#1-Pytorch中LSTM和GRU模块使用" class="headerlink" title="1. Pytorch中LSTM和GRU模块使用"></a>1. Pytorch中LSTM和GRU模块使用</h2><h3 id="1-1-LSTM介绍"><a href="#1-1-LSTM介绍" class="headerlink" title="1.1 LSTM介绍"></a>1.1 LSTM介绍</h3><p>LSTM和GRU都是由<code>torch.nn</code>提供</p>
<p>通过观察文档，可知LSMT的参数，</p>
<p><code>torch.nn.LSTM(input_size,hidden_size,num_layers,batch_first,dropout,bidirectional)</code></p>
<ol>
<li><code>input_size </code>：输入数据的形状，即embedding_dim</li>
<li><code>hidden_size</code>：隐藏层神经元的数量，即每一层有多少个LSTM单元</li>
<li><code>num_layer</code> ：即RNN的中LSTM单元的层数</li>
<li><code>batch_first</code>：默认值为False，输入的数据需要<code>[seq_len,batch,feature]</code>,如果为True，则为<code>[batch,seq_len,feature]</code></li>
<li><code>dropout</code>:dropout的比例，默认值为0。dropout是一种训练过程中让部分参数随机失活的一种方式，能够提高训练速度，同时能够解决过拟合的问题。这里是在LSTM的最后一层，对每个输出进行dropout</li>
<li><code>bidirectional</code>：是否使用双向LSTM,默认是False</li>
</ol>
<p>实例化LSTM对象之后,<strong>不仅需要传入数据，还需要前一次的h_0(前一次的隐藏状态)和c_0（前一次memory）</strong></p>
<p>即：<code>lstm(input,(h_0,c_0))</code></p>
<p>LSTM的默认输出为<code>output, (h_n, c_n)</code></p>
<ol>
<li><code>output</code>：<code>(seq_len, batch, num_directions * hidden_size)</code>—&gt;batch_first&#x3D;False</li>
<li><code>h_n</code>:<code>(num_layers * num_directions, batch, hidden_size)</code></li>
<li><code>c_n</code>: <code>(num_layers * num_directions, batch, hidden_size)</code></li>
</ol>
<h2 id="1-2-LSTM使用示例"><a href="#1-2-LSTM使用示例" class="headerlink" title="1.2 LSTM使用示例"></a>1.2 LSTM使用示例</h2><p>假设数据输入为 input ,形状是<code>[10,20]</code>，假设embedding的形状是<code>[100,30]</code></p>
<p>则LSTM使用示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size =<span class="hljs-number">10</span><br>seq_len = <span class="hljs-number">20</span><br>embedding_dim = <span class="hljs-number">30</span><br>word_vocab = <span class="hljs-number">100</span><br>hidden_size = <span class="hljs-number">18</span><br>num_layer = <span class="hljs-number">2</span><br><br><span class="hljs-comment">#准备输入数据</span><br><span class="hljs-built_in">input</span> = torch.randint(low=<span class="hljs-number">0</span>,high=<span class="hljs-number">100</span>,size=(batch_size,seq_len))<br><span class="hljs-comment">#准备embedding</span><br>embedding  = torch.nn.Embedding(word_vocab,embedding_dim)<br>lstm = torch.nn.LSTM(embedding_dim,hidden_size,num_layer)<br><br><span class="hljs-comment">#进行mebed操作</span><br>embed = embedding(<span class="hljs-built_in">input</span>) <span class="hljs-comment">#[10,20,30]</span><br><br><span class="hljs-comment">#转化数据为batch_first=False</span><br>embed = embed.permute(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>) <span class="hljs-comment">#[20,10,30]</span><br><br><span class="hljs-comment">#初始化状态， 如果不初始化，torch默认初始值为全0</span><br>h_0 = torch.rand(num_layer,batch_size,hidden_size)<br>c_0 = torch.rand(num_layer,batch_size,hidden_size)<br>output,(h_1,c_1) = lstm(embed,(h_0,c_0))<br><span class="hljs-comment">#output [20,10,1*18]</span><br><span class="hljs-comment">#h_1 [2,10,18]</span><br><span class="hljs-comment">#c_1 [2,10,18]</span><br></code></pre></td></tr></table></figure>

<p>输出如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">122</span>]: output.size()<br>Out[<span class="hljs-number">122</span>]: torch.Size([<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br><br>In [<span class="hljs-number">123</span>]: h_1.size()<br>Out[<span class="hljs-number">123</span>]: torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br><br>In [<span class="hljs-number">124</span>]: c_1.size()<br>Out[<span class="hljs-number">124</span>]: torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br></code></pre></td></tr></table></figure>

<p>通过前面的学习，我们知道，最后一次的h_1应该和output的最后一个time step的输出是一样的</p>
<p>通过下面的代码，我们来验证一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">179</span>]: a = output[-<span class="hljs-number">1</span>,:,:]<br><br>In [<span class="hljs-number">180</span>]: a.size()<br>Out[<span class="hljs-number">180</span>]: torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br><br>In [<span class="hljs-number">183</span>]: b.size()<br>Out[<span class="hljs-number">183</span>]: torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br>In [<span class="hljs-number">184</span>]: a == b<br>Out[<span class="hljs-number">184</span>]:<br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>       dtype=torch.uint8)<br></code></pre></td></tr></table></figure>

<h3 id="1-3-GRU的使用示例"><a href="#1-3-GRU的使用示例" class="headerlink" title="1.3 GRU的使用示例"></a>1.3 GRU的使用示例</h3><p>GRU模块<code>torch.nn.GRU</code>，和LSTM的参数相同，含义相同，具体可参考文档</p>
<p>但是输入只剩下<code>gru(input,h_0)</code>，输出为<code>output, h_n</code></p>
<p>其形状为：</p>
<ol>
<li><code>output</code>:<code>(seq_len, batch, num_directions * hidden_size)</code></li>
<li><code>h_n</code>:<code>(num_layers * num_directions, batch, hidden_size)</code></li>
</ol>
<p>大家可以使用上述代码，观察GRU的输出形式</p>
<h3 id="1-4-双向LSTM"><a href="#1-4-双向LSTM" class="headerlink" title="1.4 双向LSTM"></a>1.4 双向LSTM</h3><p>如果需要使用双向LSTM，则在实例化LSTM的过程中，需要把LSTM中的bidriectional设置为True，同时h_0和c_0使用num_layer*2</p>
<p>观察效果，输出为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size =<span class="hljs-number">10</span> <span class="hljs-comment">#句子的数量</span><br>seq_len = <span class="hljs-number">20</span>  <span class="hljs-comment">#每个句子的长度</span><br>embedding_dim = <span class="hljs-number">30</span>  <span class="hljs-comment">#每个词语使用多长的向量表示</span><br>word_vocab = <span class="hljs-number">100</span>  <span class="hljs-comment">#词典中词语的总数</span><br>hidden_size = <span class="hljs-number">18</span>  <span class="hljs-comment">#隐层中lstm的个数</span><br>num_layer = <span class="hljs-number">2</span>  <span class="hljs-comment">#多少个隐藏层</span><br><br><span class="hljs-built_in">input</span> = torch.randint(low=<span class="hljs-number">0</span>,high=<span class="hljs-number">100</span>,size=(batch_size,seq_len))<br>embedding  = torch.nn.Embedding(word_vocab,embedding_dim)<br>lstm = torch.nn.LSTM(embedding_dim,hidden_size,num_layer,bidirectional=<span class="hljs-literal">True</span>)<br><br>embed = embedding(<span class="hljs-built_in">input</span>) <span class="hljs-comment">#[10,20,30]</span><br><br><span class="hljs-comment">#转化数据为batch_first=False</span><br>embed = embed.permute(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>) <span class="hljs-comment">#[20,10,30]</span><br>h_0 = torch.rand(num_layer*<span class="hljs-number">2</span>,batch_size,hidden_size)<br>c_0 = torch.rand(num_layer*<span class="hljs-number">2</span>,batch_size,hidden_size)<br>output,(h_1,c_1) = lstm(embed,(h_0,c_0))<br><br>In [<span class="hljs-number">135</span>]: output.size()<br>Out[<span class="hljs-number">135</span>]: torch.Size([<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">36</span>])<br><br>In [<span class="hljs-number">136</span>]: h_1.size()<br>Out[<span class="hljs-number">136</span>]: torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br><br>In [<span class="hljs-number">137</span>]: c_1.size()<br>Out[<span class="hljs-number">137</span>]: torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">10</span>, <span class="hljs-number">18</span>])<br></code></pre></td></tr></table></figure>

<p>在单向LSTM中，最后一个time step的输出的前hidden_size个和最后一层隐藏状态h_1的输出相同，那么双向LSTM呢？</p>
<p>双向LSTM中：</p>
<p><strong>output：按照正反计算的结果顺序在第2个维度进行拼接，正向第一个拼接反向的最后一个输出</strong></p>
<p><strong>hidden state:按照得到的结果在第0个维度进行拼接，正向第一个之后接着是反向第一个</strong></p>
<ol>
<li><p>前向的LSTM中，最后一个time step的输出的前hidden_size个和最后一层向前传播h_1的输出相同</p>
<ul>
<li><p>示例：</p>
</li>
<li><p>&#96;&#96;&#96;python<br>#-1是前向LSTM的最后一个，前18是前hidden_size个<br>In [188]: a &#x3D; output[-1,:,:18]  #前项LSTM中最后一个time step的output</p>
<p>In [189]: b &#x3D; h_1[-2,:,:]  #倒数第二个为前向</p>
<p>In [190]: a.size()<br>Out[190]: torch.Size([10, 18])</p>
<p>In [191]: b.size()<br>Out[191]: torch.Size([10, 18])</p>
<p>In [192]: a &#x3D;&#x3D; b<br>Out[192]:<br>tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],<br>    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],<br>   dtype&#x3D;torch.uint8)</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><br>     <br><br><span class="hljs-number">2</span>. 后向LSTM中，最后一个<span class="hljs-selector-tag">time</span> step的输出的后hidden_size个和最后一层后向传播的h_1的输出相同<br><br>   - 示例<br><br>   - ```python<br>     #<span class="hljs-number">0</span> 是反向LSTM的最后一个，后<span class="hljs-number">18</span>是后hidden_size个<br>     In <span class="hljs-selector-attr">[196]</span>: c = output<span class="hljs-selector-attr">[0,:,18:]</span>  #后向LSTM中的最后一个输出<br>     <br>     In <span class="hljs-selector-attr">[197]</span>: d = h_1<span class="hljs-selector-attr">[-1,:,:]</span> #后向LSTM中的最后一个隐藏层状态<br>     <br>     In <span class="hljs-selector-attr">[198]</span>: c == d<br>     Out<span class="hljs-selector-attr">[198]</span>:<br>     <span class="hljs-built_in">tensor</span>(<span class="hljs-selector-attr">[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>,<br>             <span class="hljs-selector-attr">[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>],<br>            dtype=torch.uint8)<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="1-4-LSTM和GRU的使用注意点"><a href="#1-4-LSTM和GRU的使用注意点" class="headerlink" title="1.4 LSTM和GRU的使用注意点"></a>1.4 LSTM和GRU的使用注意点</h3><ol>
<li>第一次调用之前，需要初始化隐藏状态，如果不初始化，默认创建全为0的隐藏状态</li>
<li>往往会使用LSTM or GRU 的输出的最后一维的结果，来代表LSTM、GRU对文本处理的结果，其形状为<code>[batch,  num_directions*hidden_size]</code>。<ol>
<li>并不是所有模型都会使用最后一维的结果</li>
<li>如果实例化LSTM的过程中，batch_first&#x3D;False,则<code>output[-1] or output[-1,:,:]</code>可以获取最后一维</li>
<li>如果实例化LSTM的过程中，batch_first&#x3D;True,则<code>output[:,-1,:]</code>可以获取最后一维</li>
</ol>
</li>
<li>如果结果是<code>(seq_len, batch_size, num_directions * hidden_size)</code>,需要把它转化为<code>(batch_size,seq_len, num_directions * hidden_size)</code>的形状，不能够不是view等变形的方法，需要使用<code>output.permute(1,0,2)</code>，即交换0和1轴，实现上述效果</li>
<li>使用双向LSTM的时候，往往会分别使用每个方向最后一次的output，作为当前数据经过双向LSTM的结果<ul>
<li>即：<code>torch.cat([h_1[-2,:,:],h_1[-1,:,:]],dim=-1)</code></li>
<li>最后的表示的size是<code>[batch_size,hidden_size*2]</code></li>
</ul>
</li>
<li>上述内容在GRU中同理</li>
</ol>
<h2 id="2-使用LSTM完成文本情感分类"><a href="#2-使用LSTM完成文本情感分类" class="headerlink" title="2. 使用LSTM完成文本情感分类"></a>2. 使用LSTM完成文本情感分类</h2><p>在前面，我们使用了word embedding去实现了toy级别的文本情感分类，那么现在我们在这个模型中添加上LSTM层，观察分类效果。</p>
<p>为了达到更好的效果，对之前的模型做如下修改</p>
<ol>
<li>MAX_LEN &#x3D; 200</li>
<li>构建dataset的过程，把数据转化为2分类的问题，pos为1，neg为0，否则25000个样本完成10个类别的划分数据量是不够的</li>
<li>在实例化LSTM的时候，使用dropout&#x3D;0.5，在model.eval()的过程中，dropout自动会为0</li>
</ol>
<h3 id="2-1-修改模型"><a href="#2-1-修改模型" class="headerlink" title="2.1 修改模型"></a>2.1 修改模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">IMDBLstmmodel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(IMDBLstmmodel,self).__init__()<br>        self.hidden_size = <span class="hljs-number">64</span><br>        self.embedding_dim = <span class="hljs-number">200</span><br>        self.num_layer = <span class="hljs-number">2</span><br>        self.bidriectional = <span class="hljs-literal">True</span><br>        self.bi_num = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> self.bidriectional <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        self.dropout = <span class="hljs-number">0.5</span><br>        <span class="hljs-comment">#以上部分为超参数，可以自行修改</span><br><br>        self.embedding = nn.Embedding(<span class="hljs-built_in">len</span>(ws),self.embedding_dim,padding_idx=ws.PAD) <span class="hljs-comment">#[N,300]</span><br>        self.lstm = nn.LSTM(self.embedding_dim,self.hidden_size,self.num_layer,bidirectional=<span class="hljs-literal">True</span>,dropout=self.dropout)<br>        <span class="hljs-comment">#使用两个全连接层，中间使用relu激活函数</span><br>        self.fc = nn.Linear(self.hidden_size*self.bi_num,<span class="hljs-number">20</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">20</span>,<span class="hljs-number">2</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.embedding(x)<br>        x = x.permute(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>) <span class="hljs-comment">#进行轴交换</span><br>        h_0,c_0 = self.init_hidden_state(x.size(<span class="hljs-number">1</span>))<br>        _,(h_n,c_n) = self.lstm(x,(h_0,c_0))<br><br>        <span class="hljs-comment">#只要最后一个lstm单元处理的结果，这里多去的hidden state</span><br>        out = torch.cat([h_n[-<span class="hljs-number">2</span>, :, :], h_n[-<span class="hljs-number">1</span>, :, :]], dim=-<span class="hljs-number">1</span>)<br>        out = self.fc(out)<br>        out = F.relu(out)<br>        out = self.fc2(out)<br>        <span class="hljs-keyword">return</span> F.log_softmax(out,dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_hidden_state</span>(<span class="hljs-params">self,batch_size</span>):<br>        h_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to(device)<br>        c_0 = torch.rand(self.num_layer * self.bi_num, batch_size, self.hidden_size).to(device)<br>        <span class="hljs-keyword">return</span> h_0,c_0<br></code></pre></td></tr></table></figure>



<h3 id="2-2-完成训练和测试代码"><a href="#2-2-完成训练和测试代码" class="headerlink" title="2.2 完成训练和测试代码"></a>2.2 完成训练和测试代码</h3><p>为了提高程序的运行速度，可以考虑把模型放在gup上运行，那么此时需要处理一下几点：</p>
<ol>
<li><code>device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</code></li>
<li><code>model.to(device)</code></li>
<li>除了上述修改外，涉及计算的所有tensor都需要转化为CUDA的tensor<ol>
<li>初始化的<code>h_0,c_0</code></li>
<li>训练集和测试集的<code>input,traget</code></li>
</ol>
</li>
<li>在最后可以通过<code>tensor.cpu()</code>转化为torch的普通tensor</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python">train_batch_size = <span class="hljs-number">64</span><br>test_batch_size = <span class="hljs-number">5000</span><br><span class="hljs-comment"># imdb_model = IMDBModel(MAX_LEN) #基础model</span><br>imdb_model = IMDBLstmmodel().to(device) <span class="hljs-comment">#在gpu上运行，提高运行速度</span><br><span class="hljs-comment"># imdb_model.load_state_dict(torch.load(&quot;model/mnist_net.pkl&quot;))</span><br>optimizer = optim.Adam(imdb_model.parameters())<br>criterion = nn.CrossEntropyLoss()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    mode = <span class="hljs-literal">True</span><br>    imdb_model.train(mode)<br>    train_dataloader =get_dataloader(mode,train_batch_size)<br>    <span class="hljs-keyword">for</span> idx,(target,<span class="hljs-built_in">input</span>,input_lenght) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        target = target.to(device)<br>        <span class="hljs-built_in">input</span> = <span class="hljs-built_in">input</span>.to(device)<br>        optimizer.zero_grad()<br>        output = imdb_model(<span class="hljs-built_in">input</span>)<br>        loss = F.nll_loss(output,target) <span class="hljs-comment">#traget需要是[0,9]，不能是[1-10]</span><br>        loss.backward()<br>        optimizer.step()<br>        <span class="hljs-keyword">if</span> idx %<span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            pred = torch.<span class="hljs-built_in">max</span>(output, dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">False</span>)[-<span class="hljs-number">1</span>]<br>            acc = pred.eq(target.data).cpu().numpy().mean()*<span class="hljs-number">100.</span><br><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;\t ACC: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, idx * <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                       <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item(),acc))<br><br>            torch.save(imdb_model.state_dict(), <span class="hljs-string">&quot;model/mnist_net.pkl&quot;</span>)<br>            torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;model/mnist_optimizer.pkl&#x27;</span>)<br>            <br> <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    mode = <span class="hljs-literal">False</span><br>    imdb_model.<span class="hljs-built_in">eval</span>()<br>    test_dataloader = get_dataloader(mode, test_batch_size)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> idx,(target, <span class="hljs-built_in">input</span>, input_lenght) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_dataloader):<br>            target = target.to(device)<br>            <span class="hljs-built_in">input</span> = <span class="hljs-built_in">input</span>.to(device)<br>            output = imdb_model(<span class="hljs-built_in">input</span>)<br>            test_loss  = F.nll_loss(output, target,reduction=<span class="hljs-string">&quot;mean&quot;</span>)<br>            pred = torch.<span class="hljs-built_in">max</span>(output,dim=-<span class="hljs-number">1</span>,keepdim=<span class="hljs-literal">False</span>)[-<span class="hljs-number">1</span>]<br>            correct = pred.eq(target.data).<span class="hljs-built_in">sum</span>()<br>            acc = <span class="hljs-number">100.</span> * pred.eq(target.data).cpu().numpy().mean()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;idx: &#123;&#125; Test set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&#x27;</span>.<span class="hljs-built_in">format</span>(idx,test_loss, correct, target.size(<span class="hljs-number">0</span>),acc))<br>            <br> <span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    test()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(i)<br>        test()<br><br></code></pre></td></tr></table></figure>

<h3 id="2-3-模型训练的最终输出"><a href="#2-3-模型训练的最终输出" class="headerlink" title="2.3 模型训练的最终输出"></a>2.3 模型训练的最终输出</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">...</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">20480</span><span class="hljs-string">/25000</span> <span class="hljs-string">(82%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.017165</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">100.000000</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">21120</span><span class="hljs-string">/25000</span> <span class="hljs-string">(84%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.021572</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">98.437500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">21760</span><span class="hljs-string">/25000</span> <span class="hljs-string">(87%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.058546</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">98.437500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">22400</span><span class="hljs-string">/25000</span> <span class="hljs-string">(90%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.045248</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">98.437500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">23040</span><span class="hljs-string">/25000</span> <span class="hljs-string">(92%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.027622</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">98.437500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">23680</span><span class="hljs-string">/25000</span> <span class="hljs-string">(95%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.097722</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">95.312500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">24320</span><span class="hljs-string">/25000</span> <span class="hljs-string">(97%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.026713</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">98.437500</span><br><span class="hljs-attr">Train Epoch:</span> <span class="hljs-number">9</span> [<span class="hljs-number">15600</span><span class="hljs-string">/25000</span> <span class="hljs-string">(100%)</span>]	<span class="hljs-attr">Loss:</span> <span class="hljs-number">0.006082</span>	 <span class="hljs-attr">ACC:</span> <span class="hljs-number">100.000000</span><br><span class="hljs-attr">idx: 0 Test set: Avg. loss:</span> <span class="hljs-number">0.8794</span><span class="hljs-string">,</span> <span class="hljs-attr">Accuracy:</span> <span class="hljs-number">4053</span><span class="hljs-string">/5000</span> <span class="hljs-string">(81.06%)</span><br><span class="hljs-attr">idx: 1 Test set: Avg. loss:</span> <span class="hljs-number">0.8791</span><span class="hljs-string">,</span> <span class="hljs-attr">Accuracy:</span> <span class="hljs-number">4018</span><span class="hljs-string">/5000</span> <span class="hljs-string">(80.36%)</span><br><span class="hljs-attr">idx: 2 Test set: Avg. loss:</span> <span class="hljs-number">0.8250</span><span class="hljs-string">,</span> <span class="hljs-attr">Accuracy:</span> <span class="hljs-number">4087</span><span class="hljs-string">/5000</span> <span class="hljs-string">(81.74%)</span><br><span class="hljs-attr">idx: 3 Test set: Avg. loss:</span> <span class="hljs-number">0.8380</span><span class="hljs-string">,</span> <span class="hljs-attr">Accuracy:</span> <span class="hljs-number">4074</span><span class="hljs-string">/5000</span> <span class="hljs-string">(81.48%)</span><br><span class="hljs-attr">idx: 4 Test set: Avg. loss:</span> <span class="hljs-number">0.8696</span><span class="hljs-string">,</span> <span class="hljs-attr">Accuracy:</span> <span class="hljs-number">4027</span><span class="hljs-string">/5000</span> <span class="hljs-string">(80.54%)</span><br></code></pre></td></tr></table></figure>

<p>可以看到模型的测试准确率稳定在81%左右。</p>
<p>大家可以把上述代码改为GRU，或者多层LSTM继续尝试，观察效果</p>
<h1 id="Pytorch中的序列化容器"><a href="#Pytorch中的序列化容器" class="headerlink" title="Pytorch中的序列化容器"></a>Pytorch中的序列化容器</h1><h2 id="目标-11"><a href="#目标-11" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道梯度消失和梯度爆炸的原理和解决方法</li>
<li>能够使用<code>nn.Sequential</code>完成模型的搭建</li>
<li>知道<code>nn.BatchNorm1d</code>的使用方法</li>
<li>知道<code>nn.Dropout</code>的使用方法</li>
</ol>
<h2 id="1-梯度消失和梯度爆炸"><a href="#1-梯度消失和梯度爆炸" class="headerlink" title="1. 梯度消失和梯度爆炸"></a>1. 梯度消失和梯度爆炸</h2><p>在使用pytorch中的序列化 容器之前，我们先来了解一下常见的梯度消失和梯度爆炸的问题</p>
<h3 id="1-1-梯度消失"><a href="#1-1-梯度消失" class="headerlink" title="1.1 梯度消失"></a>1.1 梯度消失</h3><p>假设我们有四层极简神经网络：每层只有一个神经元</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1.png" srcset="/img/loading.gif" lazyload></p>
<p>$获取w1的梯度有：▽w1 &#x3D; x1<em>f(a1)’</em>w2<em>f(b1)’</em>w3*▽out$</p>
<p>假设我们使用sigmoid激活函数，即f为sigmoid函数，sigmoid的导数如下图</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/sigmoid%E5%AF%BC%E6%95%B0.png" srcset="/img/loading.gif" lazyload></p>
<p>假设每层都取得sigmoid导函数的最大值1&#x2F;4，那么在反向传播时，$X1&#x3D;0.5,w1&#x3D;w2&#x3D;w3&#x3D;0.5$</p>
<p>$\nabla w1&lt; \frac{1}{2} * \frac{1}{4}* \frac{1}{2}* \frac{1}{4}*\frac{1}{2}*\nabla out &#x3D; \frac{1}{2^7} \nabla out$ </p>
<p>当权重初始过小或使用<code>易饱和神经元(sigmoid,tanh，) sigmoid在y=0,1处梯度接近0，而无法更新参数</code>，时神经网络在反向传播时也会呈现指数倍缩小，产生“消失”现象。</p>
<h3 id="1-2-梯度爆炸"><a href="#1-2-梯度爆炸" class="headerlink" title="1.2 梯度爆炸"></a>1.2 梯度爆炸</h3><p>假设$X2&#x3D;2,w1&#x3D;w2&#x3D;w3&#x3D;2$</p>
<p>$\nabla w1 &#x3D; f’{a}<em>2</em>f‘{a}*x2\nabla out &#x3D; 2^3f’(a)^2 \nabla out $</p>
<p> 当权重初始过大时，梯度神经网络在反向传播时也会呈现指数倍放大，产生“爆炸”现象。</p>
<h3 id="1-3-解决梯度消失或者梯度爆炸的经验"><a href="#1-3-解决梯度消失或者梯度爆炸的经验" class="headerlink" title="1.3 解决梯度消失或者梯度爆炸的经验"></a>1.3 解决梯度消失或者梯度爆炸的经验</h3><ol>
<li><p><strong>替换易训练神经元</strong></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9B%BF%E6%8D%A2%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png" srcset="/img/loading.gif" lazyload></p>
</li>
<li><p><strong>改进梯度优化算法：</strong>使用adam等算法</p>
</li>
<li><p><strong>使用batch normalization</strong></p>
</li>
</ol>
<h2 id="2-nn-Sequential"><a href="#2-nn-Sequential" class="headerlink" title="2. nn.Sequential"></a>2. <code>nn.Sequential</code></h2><p><code>nn.Sequential</code>是一个有序的容器，其中传入的是构造器类(各种用来处理input的类)，最终input会被Sequential中的构造器类依次执行</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">layer = nn.Sequential(<br>            nn.Linear(input_dim, n_hidden_1), <br>            nn.ReLU(<span class="hljs-literal">True</span>)， <span class="hljs-comment">#inplace=False 是否对输入进行就地修改，默认为False</span><br>            nn.Linear(n_hidden_1, n_hidden_2)，<br>            nn.ReLU(<span class="hljs-literal">True</span>)，<br>            nn.Linear(n_hidden_2, output_dim) <span class="hljs-comment"># 最后一层不需要添加激活函数</span><br>             )<br></code></pre></td></tr></table></figure>

<p>在上述就够中，可以直接调用layer(x)，得到输出</p>
<p>x的被执行顺序就是Sequential中定义的顺序：</p>
<ol>
<li>被隐层1执行，形状变为[batch_size,n_hidden_1]</li>
<li>被relu执行，形状不变</li>
<li>被隐层2执行，形状变为[batch_size,n_hidden_2]</li>
<li>被relu执行，形状不变</li>
<li>被最后一层执行，形状变为[batch_size,output_dim]</li>
</ol>
<h2 id="3-nn-BatchNorm1d"><a href="#3-nn-BatchNorm1d" class="headerlink" title="3. nn.BatchNorm1d"></a>3. <code>nn.BatchNorm1d</code></h2><p><code>batch normalization</code>  翻译成中文就是批规范化，即在每个batch训练的过程中，对参数进行归一化的处理，从而达到加快训练速度的效果。</p>
<p>以sigmoid激活函数为例，他在反向传播的过程中，在值为0,1的时候，梯度接近0，导致参数被更新的幅度很小，训练速度慢。但是如果对数据进行归一化之后，就会尽可能的把数据拉倒[0-1]的范围，从而让参数更新的幅度变大，提高训练的速度。</p>
<p>batchNorm一般会放到激活函数之后，即对输入进行激活处理之后再进入batchNorm</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">layer = nn.Sequential(<br>            nn.Linear(input_dim, n_hidden_1),<br>    		<br>            nn.ReLU(<span class="hljs-literal">True</span>)， <br>    		nn.BatchNorm1d(n_hidden_1)<br>    <br>            nn.Linear(n_hidden_1, n_hidden_2)，<br>            nn.ReLU(<span class="hljs-literal">True</span>)，<br>    		nn.BatchNorm1d(n_hidden_2)<br><br>            nn.Linear(n_hidden_2, output_dim) <br>             )<br></code></pre></td></tr></table></figure>

<h2 id="4-nn-Dropout"><a href="#4-nn-Dropout" class="headerlink" title="4. nn.Dropout"></a>4. <code>nn.Dropout</code></h2><p>dropout在前面已经介绍过，可以理解为对参数的随机失活</p>
<ol>
<li>增加模型的稳健性</li>
<li>可以解决过拟合的问题（增加模型的泛化能力）</li>
<li>可以理解为训练后的模型是多个模型的组合之后的结果，类似随机森林。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">layer = nn.Sequential(<br>            nn.Linear(input_dim, n_hidden_1),<br>            nn.ReLU(<span class="hljs-literal">True</span>)， <br>    		nn.BatchNorm1d(n_hidden_1)<br>    		nn.Dropout(<span class="hljs-number">0.3</span>) <span class="hljs-comment">#0.3 为dropout的比例，默认值为0.5</span><br>    <br>            nn.Linear(n_hidden_1, n_hidden_2)，<br>            nn.ReLU(<span class="hljs-literal">True</span>)，<br>    		nn.BatchNorm1d(n_hidden_2)<br>    		nn.Dropout(<span class="hljs-number">0.3</span>)<br>    <br>            nn.Linear(n_hidden_2, output_dim) <br>             )<br></code></pre></td></tr></table></figure>

<h1 id="走进聊天机器人"><a href="#走进聊天机器人" class="headerlink" title="走进聊天机器人"></a>走进聊天机器人</h1><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ol>
<li>知道常见的bot的分类</li>
<li>知道企业中常见的流程和方法</li>
</ol>
<h2 id="1-目前企业中的常见的聊天机器人"><a href="#1-目前企业中的常见的聊天机器人" class="headerlink" title="1. 目前企业中的常见的聊天机器人"></a>1. 目前企业中的常见的聊天机器人</h2><ol>
<li>QA BOT（问答机器人）：回答问题<ol>
<li>代表 ：智能客服、</li>
<li>比如：提问和回答</li>
</ol>
</li>
<li>TASK BOT (任务机器人)：帮助人们做事情<ol>
<li>代表：siri</li>
<li>比如：设置明天早上9点的闹钟</li>
</ol>
</li>
<li>CHAT BOT(聊天机器人)：通用、开放聊天<ol>
<li>代表：微软小冰</li>
</ol>
</li>
</ol>
<h3 id="2-常见的聊天机器人怎么实现的"><a href="#2-常见的聊天机器人怎么实现的" class="headerlink" title="2. 常见的聊天机器人怎么实现的"></a>2. 常见的聊天机器人怎么实现的</h3><h5 id="2-1-问答机器人的常见实现手段"><a href="#2-1-问答机器人的常见实现手段" class="headerlink" title="2.1 问答机器人的常见实现手段"></a>2.1 问答机器人的常见实现手段</h5><ol>
<li><p>信息检索、搜索 （简单，效果一般，对数据问答对的要求高）</p>
<p>关键词：tfidf、SVM、朴素贝叶斯、RNN、CNN</p>
</li>
<li><p>知识图谱（相对复杂，效果好，很多论文）</p>
<p>在图形数据库中存储知识和知识间的关系、把问答转化为查询语句、能够实现推理</p>
</li>
</ol>
<h5 id="2-2-任务机器人的常见实现思路"><a href="#2-2-任务机器人的常见实现思路" class="headerlink" title="2.2 任务机器人的常见实现思路"></a>2.2 任务机器人的常见实现思路</h5><ol>
<li>语音转文字</li>
<li>意图识别、领域识别、文本分类</li>
<li>槽位填充：比如买机票的机器人 使用命令体识别填充 <code>从&#123;位置&#125;到&#123;位置&#125;的票</code>2个位置的</li>
<li>回话管理、回话策略</li>
<li>自然语言生成</li>
<li>文本转语音</li>
</ol>
<h5 id="2-3-闲聊机器人的常见实现思路"><a href="#2-3-闲聊机器人的常见实现思路" class="headerlink" title="2.3 闲聊机器人的常见实现思路"></a>2.3 闲聊机器人的常见实现思路</h5><ol>
<li>信息检索（简单、能够回答的话术有限）</li>
<li>seq2seq 和变种（答案覆盖率高，但是不能保证答案的通顺等）</li>
</ol>
<h2 id="3-企业中的聊天机器人是如何实现的"><a href="#3-企业中的聊天机器人是如何实现的" class="headerlink" title="3. 企业中的聊天机器人是如何实现的"></a>3. 企业中的聊天机器人是如何实现的</h2><h3 id="3-1-阿里小蜜-电商智能助理是如何实现的"><a href="#3-1-阿里小蜜-电商智能助理是如何实现的" class="headerlink" title="3.1 阿里小蜜-电商智能助理是如何实现的"></a>3.1 阿里小蜜-电商智能助理是如何实现的</h3><p>参考地址：<code>https://juejin.im/entry/59e96f946fb9a04510499c7f</code></p>
<h5 id="3-1-1-主要交互过程"><a href="#3-1-1-主要交互过程" class="headerlink" title="3.1.1 主要交互过程"></a>3.1.1 主要交互过程</h5><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>从图可以看出：</p>
<ol>
<li>输入：语音转化为文本，进行理解之后根据上下文得到语义的表示</li>
<li>输出：根据语义的表是和生成方法得到文本，再把文本转化为语音输出</li>
</ol>
<h5 id="3-1-2-技术架构"><a href="#3-1-2-技术架构" class="headerlink" title="3.1.2 技术架构"></a>3.1.2 技术架构</h5><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E6%9E%B6%E6%9E%84.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看出其流程为：</p>
<ol>
<li>判断用户意图</li>
<li>如果意图为面向目标：可能是问答型或者是任务型</li>
<li>如果非面向目标：可能是语聊型</li>
</ol>
<h5 id="3-1-3-检索模型流程（小蜜还用了其他的模型，这里以此为例）"><a href="#3-1-3-检索模型流程（小蜜还用了其他的模型，这里以此为例）" class="headerlink" title="3.1.3 检索模型流程（小蜜还用了其他的模型，这里以此为例）"></a>3.1.3 检索模型流程（小蜜还用了其他的模型，这里以此为例）</h5><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E8%9C%9C%E7%9A%84%E6%A3%80%E7%B4%A2%E6%B5%81%E7%A8%8B.png" srcset="/img/loading.gif" lazyload></p>
<p>通过上图可知，小蜜的检索式回答的流程大致为：</p>
<ol>
<li>对问题进行处理</li>
<li>根据问题进行召回，使用了提前准备的结构化的语料和训练的模型</li>
<li>对召回的结果进行组长和日志记录</li>
<li>对召回的结果进行相似度计算，情感分析和属性识别</li>
<li>返回组装的结果</li>
</ol>
<h3 id="3-2-58同城智能客服帮帮如何实现的"><a href="#3-2-58同城智能客服帮帮如何实现的" class="headerlink" title="3.2 58同城智能客服帮帮如何实现的"></a>3.2 58同城智能客服帮帮如何实现的</h3><p>参考地址：<code>http://www.6aiq.com/article/1536149308075?p=1&amp;m=0</code></p>
<h4 id="3-2-1-58客服体系"><a href="#3-2-1-58客服体系" class="headerlink" title="3.2.1 58客服体系"></a>3.2.1 58客服体系</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q.jpeg" srcset="/img/loading.gif" lazyload></p>
<p>58的客服主要用户为公司端和个人端，智能客服主要实现自动回答，如果回答不好会转到人工客服，其中自动回答需要覆盖的问题包括：业务咨询、投诉建议等</p>
<h4 id="3-2-2-58智能客服整体架构"><a href="#3-2-2-58智能客服整体架构" class="headerlink" title="3.2.2 58智能客服整体架构"></a>3.2.2 58智能客服整体架构</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798501.jpeg" srcset="/img/loading.gif" lazyload></p>
<p>整体来看，58的客服架构分为三个部分</p>
<ol>
<li>基础服务，实现基础的NLP的功能和意图识别</li>
<li>应用对话部分实现不同意图的模型，同时包括编辑运营等内容</li>
<li>提供对外的接口</li>
</ol>
<h4 id="3-2-3-业务咨询服务流程"><a href="#3-2-3-业务咨询服务流程" class="headerlink" title="3.2.3 业务咨询服务流程"></a>3.2.3 业务咨询服务流程</h4><h5 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h5><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798502.jpeg" srcset="/img/loading.gif" lazyload></p>
<p>KB-bot的流程大致为：</p>
<ol>
<li>对问题进行基础处理</li>
<li>对答案通过tfidf等方法进行召回</li>
<li>对答案通过规则、深度神经网络等方法进行重排序</li>
<li>返回答案排序列表</li>
</ol>
<h5 id="使用融合的模型"><a href="#使用融合的模型" class="headerlink" title="使用融合的模型"></a>使用融合的模型</h5><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798503.jpeg" srcset="/img/loading.gif" lazyload></p>
<p>在问答模型的深度网络模型中使用了多套模型进行融合来获取结果</p>
<ol>
<li>在模型层应用了 FastText、TextCNN 和 Bi-LSTM 等模型</li>
<li>在特征层尝试使用了单字、词、词性、词语属性等多种特征</li>
</ol>
<p>通过以上两个模型来组合获取相似的问题，返回相似问题ID对应的答案</p>
<h4 id="3-2-4-58的闲聊机器人"><a href="#3-2-4-58的闲聊机器人" class="headerlink" title="3.2.4 58的闲聊机器人"></a>3.2.4 58的闲聊机器人</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798504.jpeg" srcset="/img/loading.gif" lazyload></p>
<p>58同城的闲聊机器人使用三种方法包括：</p>
<ol>
<li>基于模板匹配的方法</li>
<li>基于搜索的方式获取（上上图）</li>
<li>使用seq2seq的神经网络来实现</li>
</ol>
<h4 id="3-2-5-解决不了转人工服务"><a href="#3-2-5-解决不了转人工服务" class="headerlink" title="3.2.5 解决不了转人工服务"></a>3.2.5 解决不了转人工服务</h4><p>​	智能客服解决不了的可以使用人工客服来实现</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/q-16812675798505.jpeg" srcset="/img/loading.gif" lazyload></p>
<h1 id="需求分析和流程介绍"><a href="#需求分析和流程介绍" class="headerlink" title="需求分析和流程介绍"></a>需求分析和流程介绍</h1><h2 id="目标-12"><a href="#目标-12" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够说出实现聊天机器人的需求</li>
<li>能够说出实现聊天机器人的流程</li>
</ol>
<h2 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h2><p>在黑马头条的小智同学板块实现聊天机器人，能够起到<code>智能客服</code>的效果，能够为使用app的用户解决基础的问题，而不用额外的人力。</p>
<p>但是由于语料的限制，所以这里使用了编程相关的问题，能够回答类似：<code>python是什么</code>，<code>python有什么优势</code>等问题</p>
<h2 id="2-效果演示"><a href="#2-效果演示" class="headerlink" title="2. 效果演示"></a>2. 效果演示</h2><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/app%E6%88%AA%E5%9B%BE.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="3-实现流程"><a href="#3-实现流程" class="headerlink" title="3. 实现流程"></a>3. 实现流程</h2><h4 id="3-1-整体架构"><a href="#3-1-整体架构" class="headerlink" title="3.1 整体架构"></a>3.1 整体架构</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png" srcset="/img/loading.gif" lazyload></p>
<p>整个流程的描述如下：</p>
<ol>
<li>接受用户的问题之后，对问题进行基础的处理</li>
<li>对处理后的问题进行分类，判断其意图</li>
<li>如果用户希望闲聊，那么调用闲聊模型返回结果</li>
<li>如果用户希望咨询问题，那么调用问答模型返回结果</li>
</ol>
<h4 id="3-2-闲聊模型"><a href="#3-2-闲聊模型" class="headerlink" title="3.2 闲聊模型"></a>3.2 闲聊模型</h4><p>闲聊模型使用了seq2seq模型实现</p>
<p>包含：</p>
<ol>
<li>对数据的embedding</li>
<li>编码层</li>
<li>attention机制的处理</li>
<li>解码层</li>
</ol>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chabot.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="3-4-问答模型"><a href="#3-4-问答模型" class="headerlink" title="3.4 问答模型"></a>3.4 问答模型</h4><p>问答模型使用了召回和排序的机制来实现，保证获取的速度的同时保证了准确率</p>
<ol>
<li>问题分析：对问题进行基础的处理，包括分词，词性的获取，词向量的获取</li>
<li>问题的召回：通过机器学习的方法进行海选，海选出大致满足要求的相似问题的前K个</li>
<li>问题的排序：通过深度学习的模型对问题计算准确率，进行排序</li>
<li>设置阈值，返回结果</li>
</ol>
<p><img src="/..%5Cimages%5C2.1%5CQAbot.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="目标-13"><a href="#目标-13" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够使用anaconda创建虚拟环境</li>
<li>能够安装fasttext</li>
<li>能够安装pysparnn</li>
</ol>
<h2 id="1-Anaconda环境准备"><a href="#1-Anaconda环境准备" class="headerlink" title="1. Anaconda环境准备"></a>1. Anaconda环境准备</h2><ol>
<li><p>下载地址：<code>https://mirror.tuna.tsinghua.edu.cn/help/anaconda/</code></p>
</li>
<li><p>下载对应电脑版本软件，安装</p>
<ol>
<li>windows ：双击exe文件</li>
<li>unix：给sh文件添加可执行权限，执行sh文件</li>
</ol>
</li>
<li><p>添加到环境变量</p>
<ol>
<li>windows安装过程中勾选</li>
<li>unix：<code>export PATH=&quot;/root/miniconda3/bin:$PATH&quot;</code></li>
</ol>
</li>
<li><p>创建虚拟环境</p>
<ol>
<li><code>conda create -n 名字 python=3.6(版本)</code></li>
<li>查看所有虚拟环境： <code>conda env list</code></li>
</ol>
</li>
<li><p>切换到虚拟环境</p>
<ol>
<li><code>conda activate 名字</code></li>
</ol>
</li>
<li><p>退出虚拟环境</p>
<ol>
<li><code>conda deactivate 名字</code></li>
</ol>
</li>
</ol>
<h2 id="2-fasttext安装"><a href="#2-fasttext安装" class="headerlink" title="2. fasttext安装"></a>2. fasttext安装</h2><p>文档地址：<code>https://fasttext.cc/docs/en/support.html</code></p>
<p>github地址：<code>&lt;https://github.com/facebookresearch/fastText</code></p>
<p>安装步骤：</p>
<ol>
<li>下载 <code>git clone https://github.com/facebookresearch/fastText.git</code></li>
<li>cd <code>cd fastText</code></li>
<li>安装 <code>python setup.py install</code></li>
</ol>
<h2 id="3-pysparnn安装"><a href="#3-pysparnn安装" class="headerlink" title="3. pysparnn安装"></a>3. pysparnn安装</h2><p>文档地址：<code>https://github.com/facebookresearch/pysparnn</code></p>
<p>安装步骤：</p>
<ol>
<li>下载：<code>git clone https://github.com/facebookresearch/pysparnn.git</code></li>
<li>安装：<code>python setupy.py install</code></li>
</ol>
<h1 id="语料准备"><a href="#语料准备" class="headerlink" title="语料准备"></a>语料准备</h1><h2 id="目标-14"><a href="#目标-14" class="headerlink" title="目标"></a>目标</h2><ol>
<li>准备分词词典</li>
<li>准备停用词</li>
<li>准备问答对</li>
<li>爬虫采集相似问题</li>
</ol>
<h2 id="1-分词词典"><a href="#1-分词词典" class="headerlink" title="1. 分词词典"></a>1. 分词词典</h2><p>最终词典的格式：</p>
<blockquote>
<p>词语   词性(不要和jieba默认的词性重复)</p>
</blockquote>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%85%B8.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="1-1-词典来源"><a href="#1-1-词典来源" class="headerlink" title="1.1 词典来源"></a>1.1 词典来源</h4><ol>
<li><p>各种输入法的词典</p>
<p>例如：<code>https://pinyin.sogou.com/dict/cate/index/97?rf=dictindex</code></p>
<p>例如：<code>https://shurufa.baidu.com/dict_list?cid=211</code></p>
</li>
<li><p>手动收集，根据目前的需求，我们可以手动收集如下词典</p>
<ol>
<li>机构名称，例如：<code>传智</code>，<code>传智播客</code>,<code>黑马程序员</code></li>
<li>课程名词，例如：<code>python</code>,<code>人工智能+python</code>，<code>c++</code>等</li>
</ol>
</li>
</ol>
<h4 id="1-2-词典处理"><a href="#1-2-词典处理" class="headerlink" title="1.2 词典处理"></a>1.2 词典处理</h4><p>输入法的词典都是特殊格式，需要使用特殊的工具才能够把它转化为文本格式</p>
<p>工具名称：<code>深蓝词库转换.exe</code></p>
<p>下载地址：<code>https://github.com/studyzy/imewlconverter</code></p>
<h4 id="1-3-对多个词典文件内容进行合并"><a href="#1-3-对多个词典文件内容进行合并" class="headerlink" title="1.3 对多个词典文件内容进行合并"></a>1.3 对多个词典文件内容进行合并</h4><p>下载使用不同平台的多个词典之后,把所有的txt文件合并到一起供之后使用</p>
<h2 id="2-准备停用词"><a href="#2-准备停用词" class="headerlink" title="2. 准备停用词"></a>2. 准备停用词</h2><h4 id="2-1-什么是停用词？"><a href="#2-1-什么是停用词？" class="headerlink" title="2.1 什么是停用词？"></a>2.1 什么是停用词？</h4><p>对句子进行分词之后，句子中不重要的词</p>
<h4 id="2-2-停用词的准备"><a href="#2-2-停用词的准备" class="headerlink" title="2.2 停用词的准备"></a>2.2 停用词的准备</h4><p>常用停用词下载地址：<code>https://github.com/goto456/stopwords</code></p>
<h4 id="2-3-手动筛选和合并"><a href="#2-3-手动筛选和合并" class="headerlink" title="2.3 手动筛选和合并"></a>2.3 手动筛选和合并</h4><p>对于停用词的具体内容，不同场景下可能需要保留和去除的词语不一样</p>
<p>比如：词语<code>哪个</code>，很多场景可以删除，但是在判断语义的时候则不行</p>
<h2 id="3-问答对的准备"><a href="#3-问答对的准备" class="headerlink" title="3. 问答对的准备"></a>3. 问答对的准备</h2><h4 id="3-1-现有问答对的样式"><a href="#3-1-现有问答对的样式" class="headerlink" title="3.1 现有问答对的样式"></a>3.1 现有问答对的样式</h4><p>问答对有两部分，一部分是咨询老师整理的问答对，一部分是excel中的问答对，</p>
<p>最终我们需要把问答对分别整理到两个txt文档中，如下图（左边是问题，右边是答案）：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E9%97%AE%E7%AD%94%E5%AF%B9.png" srcset="/img/loading.gif" lazyload></p>
<p>Excel中的问答对如下图：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/excel%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="3-2-excel中问答对的处理"><a href="#3-2-excel中问答对的处理" class="headerlink" title="3.2 excel中问答对的处理"></a>3.2 excel中问答对的处理</h4><p>Excel中的问答对直接使用pandas就能够处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">python_qa_path = <span class="hljs-string">&quot;./data/Python短问答-11月汇总.xlsx&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_duanwenda</span>():<br>    <span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>    ret = pd.read_excel(python_qa_path)<br>    column_list = ret.columns<br>    <span class="hljs-keyword">assert</span> <span class="hljs-string">&#x27;问题&#x27;</span> <span class="hljs-keyword">in</span> column_list <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;答案&quot;</span> <span class="hljs-keyword">in</span> column_list,<span class="hljs-string">&quot;excel 中必须包含问题和答案&quot;</span><br>    <span class="hljs-keyword">for</span> q,a <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(ret[<span class="hljs-string">&quot;问题&quot;</span>],ret[<span class="hljs-string">&quot;答案&quot;</span>]):<br>        q = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,q)<br>        q = q.strip()<br>        <span class="hljs-built_in">print</span>(q,a)<br></code></pre></td></tr></table></figure>

<h2 id="4-相似问答对的采集"><a href="#4-相似问答对的采集" class="headerlink" title="4. 相似问答对的采集"></a>4. 相似问答对的采集</h2><h4 id="4-1-采集相似问答对的目的"><a href="#4-1-采集相似问答对的目的" class="headerlink" title="4.1 采集相似问答对的目的"></a>4.1 采集相似问答对的目的</h4><p>后续在判断问题相似度的时候，需要有语料用来进行模型的训练，输入两个句子，输出相似度，这个语料不好获取，所以决定从百度知道入手，采集百度知道上面的相似问题，如下图所示：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%99%BE%E5%BA%A6%E7%9B%B8%E4%BC%BC%E9%97%AE%E9%A2%98%E6%90%9C%E7%B4%A2.png" srcset="/img/loading.gif" lazyload></p>
<p>上面采集的数据会存在部分噪声，部分问题搜索到的结果语义上并不是太相似</p>
<h4 id="4-2-手动构造数据"><a href="#4-2-手动构造数据" class="headerlink" title="4.2 手动构造数据"></a>4.2 手动构造数据</h4><p>根据前面的问答对的内容，把问题大致分为了若干类型，对不同类型的问题设计模板，然后构造问题，问题模块如下：</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs autoit">templete = [<br><span class="hljs-meta">#概念</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;什么是&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;是什么&quot;</span>,<span class="hljs-string">&quot;给我介绍一下&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;可以干什么&quot;</span>,<span class="hljs-string">&quot;能简单说下什么是&#123;kc&#125;吗&quot;</span>,<span class="hljs-string">&quot;我想了解&#123;kc&#125;&quot;</span>],<br><br><span class="hljs-meta">#课程优势</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;课程有什么特点&quot;</span>,<span class="hljs-string">&quot;&#123;jgmc&#125;的&#123;kc&#125;课程有什么特点&quot;</span>,<span class="hljs-string">&quot;&#123;jgmc&#125;的&#123;kc&#125;课程有什么优势&quot;</span>,<span class="hljs-string">&quot;为什么我要来&#123;jgmc&#125;学习&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;jgmc&#125;的&#123;kc&#125;课程有什么优势&quot;</span>,<span class="hljs-string">&quot;为什么要到&#123;jgmc&#125;学习&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;jgmc&#125;的&#123;kc&#125;跟其他机构有什么区别？&quot;</span>,<span class="hljs-string">&quot;为什么选择&#123;jgmc&#125;来学习&#123;kc&#125;？&quot;</span>],<br><br><span class="hljs-meta">#语言优势</span><br><span class="hljs-meta">#[<span class="hljs-string">&quot;&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;什么是&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;是什么&quot;</span>,<span class="hljs-string">&quot;给我介绍一下&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;可以干什么&quot;</span>,<span class="hljs-string">&quot;能简单说下什么是&#123;kc&#125;吗&quot;</span>], </span><br><span class="hljs-meta">#特点</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;有什么特点&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有什么优势&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有什么亮点&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有那些亮点&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有那些优势&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有那些特点&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的亮点是什么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的优势是什么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的特点是什么&quot;</span>],<br><span class="hljs-meta">#发展前景</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;的发展怎么样？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的前景怎么样？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的发展前景如何？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的未来怎样&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的前景好么&quot;</span> ],<br><span class="hljs-meta">#就业</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;好就业么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;就业机会多么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的岗位多吗&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;工作好找吗&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的市场需求怎么样&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的就业环境怎么样&quot;</span>],<br><span class="hljs-meta">#就业方向</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;学完以后能具体从事哪方面工作?&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的就业岗位有哪些？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程学完应聘哪方面工作？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;可以从事哪方面工作？&quot;</span>,],<br><span class="hljs-meta">#用途</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;学完可以做什么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;能干什么&quot;</span>,<span class="hljs-string">&quot;学&#123;kc&#125;能干什么&quot;</span>,<span class="hljs-string">&quot;能举例说下&#123;kc&#125;能做什么吗？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;毕业了能干什么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;主要应用在什么领域&quot;</span>],<br><span class="hljs-meta">#就业薪资</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;学完工资多少&quot;</span>,<span class="hljs-string">&quot;学完&#123;kc&#125;能拿多少钱&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的就业薪资多少&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;就业的平均是工资多少&quot;</span>],<br><span class="hljs-meta">#学习难度</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;简单么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;容易么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程容易么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;上手快么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程难么&quot;</span>],<br><span class="hljs-meta">#校区</span><br>[<span class="hljs-string">&quot;在那些城市开设了&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;哪里可以学习&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;可以去那些城市&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;在哪里开班了&quot;</span>],<br><span class="hljs-meta">#学费</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;学费&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;多少钱&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的学费多少&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;是怎么收费的？&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;要花多少钱&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;是怎么收费的&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程的价格&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程的价格是多少&quot;</span>],<br><span class="hljs-meta">#适合人群</span><br>[<span class="hljs-string">&quot;什么人可以学&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;哪些人可以学&#123;kc&#125;&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;有什么要求&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;需要那些条件&quot;</span>,<span class="hljs-string">&quot;没有基础可以学&#123;kc&#125;吗&quot;</span>,<span class="hljs-string">&quot;学历低可以学习&#123;kc&#125;吗？&quot;</span>,<span class="hljs-string">&quot;成绩不好可以学习&#123;kc&#125;吗？&quot;</span>,<span class="hljs-string">&quot;什么样的人适合学习&#123;kc&#125;?&quot;</span>],<br><span class="hljs-meta">#学习时间</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;需要学多久&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;需要多久才能就业&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;需要学习多长时间&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的学时是多少&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的课时是多少&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课时&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课时长度&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;的课程周期？&quot;</span>,<span class="hljs-string">&quot;0基础学&#123;kc&#125;多久能才就业&quot;</span>],<br><span class="hljs-meta">#学习内容</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;学什么&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;学习那些内容&quot;</span>,<span class="hljs-string">&quot;我们在&#123;kc&#125;中学习那些内容&quot;</span>,<span class="hljs-string">&quot;在&#123;kc&#125;中大致都学习什么内容&quot;</span>],<br><span class="hljs-meta">#项目内容</span><br>[<span class="hljs-string">&quot;&#123;kc&#125;的项目有哪些&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;有哪些项目&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;上课都有哪些实战&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;做什么项目？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;项目有多少个？&quot;</span>,<span class="hljs-string">&quot;&#123;kc&#125;课程中有项目吗？&quot;</span>],<br><span class="hljs-meta">#学习某课程的好处</span><br>[<span class="hljs-string">&quot;为什么要学习&#123;kc&#125;？&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;有哪些好处？&quot;</span>,<span class="hljs-string">&quot;学习&#123;kc&#125;的理由？&quot;</span>,<span class="hljs-string">&quot;为什么我要来学习&#123;kc&#125;&quot;</span>],<br><span class="hljs-meta">#上课时间</span><br>[<span class="hljs-string">&quot;上课时间&quot;</span>,<span class="hljs-string">&quot;你们那边每天的上课时间是怎样的呢？&quot;</span>],<br><span class="hljs-meta">#英语要求</span><br>[<span class="hljs-string">&quot;学习&#123;kc&#125;对英语有要求么&quot;</span>,<span class="hljs-string">&quot;来&#123;jgmc&#125;学习对英语有要求吗？&quot;</span>]<br>]<br></code></pre></td></tr></table></figure>

<p>其中大括号的内容<code>kc</code>表示课程，<code>jgmc</code>表示机构名称</p>
<p>接下来，需要完成两件事</p>
<ol>
<li>最终我们会把前面准备好的课程字典和机构名称字典中的词语放入大括号中</li>
<li>把kc相同的内容构造成相似问题</li>
</ol>
<h1 id="文本分词"><a href="#文本分词" class="headerlink" title="文本分词"></a>文本分词</h1><h2 id="目标-15"><a href="#目标-15" class="headerlink" title="目标"></a>目标</h2><ol>
<li>完成停用词的准备</li>
<li>完成分词方法的封装</li>
</ol>
<h2 id="1-准备词典和停用词"><a href="#1-准备词典和停用词" class="headerlink" title="1. 准备词典和停用词"></a>1. 准备词典和停用词</h2><h3 id="1-1-准备词典"><a href="#1-1-准备词典" class="headerlink" title="1.1 准备词典"></a>1.1 准备词典</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%8D%E5%85%B8-168126759923612.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="1-2-准备停用词"><a href="#1-2-准备停用词" class="headerlink" title="1.2 准备停用词"></a>1.2 准备停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">stopwords = <span class="hljs-built_in">set</span>([i.strip() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(config.stopwords_path).readlines()])<br></code></pre></td></tr></table></figure>



<h2 id="2-准备按照单个字切分句子的方法"><a href="#2-准备按照单个字切分句子的方法" class="headerlink" title="2. 准备按照单个字切分句子的方法"></a>2. 准备按照单个字切分句子的方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_cut_by_word</span>(<span class="hljs-params">sentence</span>):<br>    <span class="hljs-comment"># 对中文按照字进行处理，对英文不分为字母</span><br>    sentence = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,sentence)<br>    sentence = sentence.strip()<br>    result = []<br>    temp = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence:<br>        <span class="hljs-keyword">if</span> word.lower() <span class="hljs-keyword">in</span> letters:<br>            temp += word.lower()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>: <span class="hljs-comment">#不是字母</span><br>                result.append(temp)<br>                temp = <span class="hljs-string">&quot;&quot;</span><br>            <span class="hljs-keyword">if</span> word.strip() <span class="hljs-keyword">in</span> filters: <span class="hljs-comment">#标点符号</span><br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-comment">#是单个字</span><br>                result.append(word)<br>    <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>: <span class="hljs-comment">#最后的temp中包含字母</span><br>        result.append(temp)<br>    <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure>





<h2 id="3-完成分词方法的封装"><a href="#3-完成分词方法的封装" class="headerlink" title="3. 完成分词方法的封装"></a>3. 完成分词方法的封装</h2><p>lib 下创建<code>cut_sentence.py</code>文件，完成分词方法的构建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">import</span> jieba.posseg <span class="hljs-keyword">as</span> psg<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> string<br><br><span class="hljs-comment">#关闭jieba log输出</span><br>jieba.setLogLevel(logging.INFO)<br><span class="hljs-comment">#加载词典</span><br>jieba.load_userdict(config.keywords_path)<br><span class="hljs-comment">#单字分割，英文部分</span><br>letters = string.ascii_lowercase<br><span class="hljs-comment">#单字分割 去除的标点</span><br>filters= [<span class="hljs-string">&quot;,&quot;</span>,<span class="hljs-string">&quot;-&quot;</span>,<span class="hljs-string">&quot;.&quot;</span>,<span class="hljs-string">&quot; &quot;</span>]<br><span class="hljs-comment">#停用词</span><br>stopwords = <span class="hljs-built_in">set</span>([i.strip() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(config.stopwords_path).readlines()])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cut</span>(<span class="hljs-params">sentence,by_word=<span class="hljs-literal">False</span>,use_stopwords=<span class="hljs-literal">False</span>,with_sg=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">assert</span> by_word!=<span class="hljs-literal">True</span> <span class="hljs-keyword">or</span> with_sg!=<span class="hljs-literal">True</span>,<span class="hljs-string">&quot;根据word切分时候无法返回词性&quot;</span><br>    <span class="hljs-keyword">if</span> by_word:<br>        <span class="hljs-keyword">return</span> _cut_by_word(sentence)<br>    <span class="hljs-keyword">else</span>:<br>        ret = psg.lcut(sentence)<br>        <span class="hljs-keyword">if</span> use_stopwords:<br>            ret = [(i.word,i.flag) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ret <span class="hljs-keyword">if</span> i.word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords]<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> with_sg:<br>            ret = [i.word <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ret]<br>        <span class="hljs-keyword">return</span> ret<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_cut_by_word</span>(<span class="hljs-params">sentence</span>):<br>    <span class="hljs-comment"># 对中文按照字进行处理，对英文不分为字母</span><br>    sentence = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,sentence)<br>    sentence = sentence.strip()<br>    result = []<br>    temp = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence:<br>        <span class="hljs-keyword">if</span> word.lower() <span class="hljs-keyword">in</span> letters:<br>            temp += word.lower()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>: <span class="hljs-comment">#不是字母</span><br>                result.append(temp)<br>                temp = <span class="hljs-string">&quot;&quot;</span><br>            <span class="hljs-keyword">if</span> word.strip() <span class="hljs-keyword">in</span> filters: <span class="hljs-comment">#标点符号</span><br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-comment">#是单个字</span><br>                result.append(word)<br>    <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>: <span class="hljs-comment">#最后的temp中包含字母</span><br>        result.append(temp)<br>    <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure>

<h1 id="动手练习"><a href="#动手练习" class="headerlink" title="动手练习"></a>动手练习</h1><h2 id="目标-16"><a href="#目标-16" class="headerlink" title="目标"></a>目标</h2><ol>
<li>动手准备好词典</li>
<li>动手准备问答对</li>
<li>动手构造问答对</li>
<li>对问题进行分词，单独存储</li>
</ol>
<h1 id="分类的目的和分类的方法"><a href="#分类的目的和分类的方法" class="headerlink" title="分类的目的和分类的方法"></a>分类的目的和分类的方法</h1><h2 id="目标-17"><a href="#目标-17" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够说出项目中进行文本的目的</li>
<li>能够说出意图识别的方法</li>
<li>能够说出常见的分类的方法</li>
</ol>
<h2 id="1-文本分类的目的"><a href="#1-文本分类的目的" class="headerlink" title="1. 文本分类的目的"></a>1. 文本分类的目的</h2><p>回顾之前的流程，我们可以发现文本分类的目的就是为了进行<strong>意图识别</strong></p>
<p>在当前我们的项目的下，我们只有两种意图需要被识别出来，所以对应的是<strong>2分类</strong>的问题</p>
<p>可以想象，如果我们的聊天机器人有多个功能，那么我们需要分类的类别就有多个，这样就是一个<strong>多分类</strong>的问题。例如，如果希望聊天机器人能够播报当前的时间，那么我们就需要准备关于询问时间的语料，同时其目标值就是一个新的类别。在训练后，通过这个新的模型，判断出用户询问的是当前的时间这个类别，那么就返回当前的时间。</p>
<p>同理，如果还希望聊天机器人能够播报未来某一天的天气，那么这个机器人就还需要增加一个新的进行分类的意图，重新进行训练</p>
<h2 id="2-机器学习中常见的分类方法"><a href="#2-机器学习中常见的分类方法" class="headerlink" title="2. 机器学习中常见的分类方法"></a>2. 机器学习中常见的分类方法</h2><p>在前面的机器学习的课程中我们学习了<strong>朴素贝叶斯</strong>，<strong>决策树</strong>等方法都能够帮助我们进行文本的分类，那么我们具体该怎么做呢？</p>
<h3 id="2-1-步骤"><a href="#2-1-步骤" class="headerlink" title="2.1 步骤"></a>2.1 步骤</h3><ol>
<li>特征工程：对文本进行处理，转化为能够被计算的向量来表示。我们可以考虑使用所有词语的出现次数，也可以考虑使用tfidf这种方法来处理</li>
<li>对模型进行训练</li>
<li>对模型进行评估</li>
</ol>
<h3 id="2-2-优化"><a href="#2-2-优化" class="headerlink" title="2.2 优化"></a>2.2 优化</h3><p>使用机器学习的方法进行文本分类的时候，为了让结果更好，我们经常从两个角度出发</p>
<ol>
<li>特征工程的过程中处理的更加细致，比如文本中类似<strong>你，我，他</strong>这种词语可以把它剔除；某些词语出现的次数太少，可能并不具有代表意义；某些词语出现的次数太多，可能导致影响的程度过大等等都是我们可以考虑的地方</li>
<li>使用不同的算法进行训练，获取不同算法的结果，选择最好的，或者是使用集成学习方法</li>
</ol>
<h2 id="3-深度学习实现文本分类"><a href="#3-深度学习实现文本分类" class="headerlink" title="3. 深度学习实现文本分类"></a>3. 深度学习实现文本分类</h2><p>前面我们简单回顾了使用机器学习如何来进行文本分类，那么使用深度学习该如何实现呢？</p>
<p>在深度学习中我们常见的操作就是：</p>
<ol>
<li>对文本进行embedding的操作，转化为向量</li>
<li>之后再通过多层的神经网络进行线性和非线性的变化得到结果</li>
<li>变换后的结果和目标值进行计算得到损失函数，比如对数似然损失等</li>
<li>通过最小化损失函数，去更新原来模型中的参数</li>
</ol>
<h1 id="fastText实现文本分类"><a href="#fastText实现文本分类" class="headerlink" title="fastText实现文本分类"></a>fastText实现文本分类</h1><h2 id="目标-18"><a href="#目标-18" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道fastext是什么</li>
<li>能够应用fasttext进行文本分类</li>
<li>能够完成项目中意图识别的代码</li>
</ol>
<h2 id="1-fastText的介绍"><a href="#1-fastText的介绍" class="headerlink" title="1.  fastText的介绍"></a>1.  fastText的介绍</h2><p>文档地址：<code>https://fasttext.cc/docs/en/support.html</code></p>
<p>fastText is a library for efficient learning of word representations and sentence classification.</p>
<p>fastText是一个单词表示学习和文本分类的库</p>
<p>优点：在标准的多核CPU上， 在10分钟之内能够训练10亿词级别语料库的词向量，能够在1分钟之内给30万多类别的50多万句子进行分类。</p>
<p>fastText 模型输入一个词的序列（一段文本或者一句话)，输出这个词序列属于不同类别的概率。</p>
<h2 id="2-安装和基本使用"><a href="#2-安装和基本使用" class="headerlink" title="2. 安装和基本使用"></a>2. 安装和基本使用</h2><h3 id="2-1-安装步骤："><a href="#2-1-安装步骤：" class="headerlink" title="2.1 安装步骤："></a>2.1 安装步骤：</h3><ol>
<li>下载 <code>git clone https://github.com/facebookresearch/fastText.git</code></li>
<li>cd <code>cd fastText</code></li>
<li>安装 <code>python setup.py install</code></li>
</ol>
<h4 id="2-2-基本使用"><a href="#2-2-基本使用" class="headerlink" title="2.2 基本使用"></a>2.2 基本使用</h4><ol>
<li><p>把数据准备为需要的格式</p>
</li>
<li><p>进行模型的训练、保存和加载、预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#1. 训练</span><br>model = fastText.train_supervised(<span class="hljs-string">&quot;./data/text_classify.txt&quot;</span>,wordNgrams=<span class="hljs-number">1</span>,epoch=<span class="hljs-number">20</span>)<br><span class="hljs-comment">#2. 保存</span><br>model.save_model(<span class="hljs-string">&quot;./data/ft_classify.model&quot;</span>)<br><span class="hljs-comment">#3. 加载</span><br>model = fastText.load_model(<span class="hljs-string">&quot;./data/ft_classify.model&quot;</span>)<br><br>textlist = [句子<span class="hljs-number">1</span>，句子<span class="hljs-number">2</span>]<br><span class="hljs-comment">#4. 预测，传入句子列表</span><br>ret = model.predict(textlist)<br></code></pre></td></tr></table></figure></li>
</ol>
<h2 id="3-意图识别实现"><a href="#3-意图识别实现" class="headerlink" title="3.  意图识别实现"></a>3.  意图识别实现</h2><h3 id="3-1-数据准备"><a href="#3-1-数据准备" class="headerlink" title="3.1 数据准备"></a>3.1 数据准备</h3><p>数据准备最终需要的形式如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%871.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%872.png" srcset="/img/loading.gif" lazyload></p>
<p>以上格式是fastText要求的格式，其中chat、QA字段可以自定义，就是目标值，<code>__label__</code>之前的为特征值，需要使用<code>\t</code>进行分隔，特征值需要进行分词，<code>__label__</code>后面的是目标值</p>
<h4 id="3-1-1-准备特征文本"><a href="#3-1-1-准备特征文本" class="headerlink" title="3.1.1 准备特征文本"></a>3.1.1 准备特征文本</h4><p>使用之前通过模板构造的样本和通过爬虫抓取的百度上的相似问题，</p>
<h4 id="3-1-2-准备闲聊文本"><a href="#3-1-2-准备闲聊文本" class="headerlink" title="3.1.2 准备闲聊文本"></a>3.1.2 准备闲聊文本</h4><p>使用小黄鸡的语料，地址：<a target="_blank" rel="noopener" href="https://github.com/fateleak/dgk_lost_conv/tree/master/results">https://github.com/fateleak/dgk_lost_conv/tree/master/results</a></p>
<h4 id="3-1-3-把文本转化为需要的格式"><a href="#3-1-3-把文本转化为需要的格式" class="headerlink" title="3.1.3 把文本转化为需要的格式"></a>3.1.3 把文本转化为需要的格式</h4><p>对两部分文本进行分词、合并，转化为需要的格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepar_data</span>():<br>    <span class="hljs-comment">#小黄鸡 作为闲聊</span><br>    xiaohaungji = <span class="hljs-string">&quot;./corpus/recall/小黄鸡未分词.conv&quot;</span><br>    handle_chat_corpus(xiaohaungji)<br>    <span class="hljs-comment"># mongodb中的数据，问题和相似问题作为 问答</span><br>    handle_mongodb_corpus()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">keywords_in_line</span>(<span class="hljs-params">line</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;相似问题中去除关键字不在其中的句子</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    keywords_list = [<span class="hljs-string">&quot;传智播客&quot;</span>,<span class="hljs-string">&quot;传智&quot;</span>,<span class="hljs-string">&quot;黑马程序员&quot;</span>,<span class="hljs-string">&quot;黑马&quot;</span>,<span class="hljs-string">&quot;python&quot;</span><br>    <span class="hljs-string">&quot;人工智能&quot;</span>,<span class="hljs-string">&quot;c语言&quot;</span>,<span class="hljs-string">&quot;c++&quot;</span>,<span class="hljs-string">&quot;java&quot;</span>,<span class="hljs-string">&quot;javaee&quot;</span>,<span class="hljs-string">&quot;前端&quot;</span>,<span class="hljs-string">&quot;移动开发&quot;</span>,<span class="hljs-string">&quot;ui&quot;</span>,<br>    <span class="hljs-string">&quot;ue&quot;</span>,<span class="hljs-string">&quot;大数据&quot;</span>,<span class="hljs-string">&quot;软件测试&quot;</span>,<span class="hljs-string">&quot;php&quot;</span>,<span class="hljs-string">&quot;h5&quot;</span>,<span class="hljs-string">&quot;产品经理&quot;</span>,<span class="hljs-string">&quot;linux&quot;</span>,<span class="hljs-string">&quot;运维&quot;</span>,<span class="hljs-string">&quot;go语言&quot;</span>,<br>    <span class="hljs-string">&quot;区块链&quot;</span>,<span class="hljs-string">&quot;影视制作&quot;</span>,<span class="hljs-string">&quot;pmp&quot;</span>,<span class="hljs-string">&quot;项目管理&quot;</span>,<span class="hljs-string">&quot;新媒体&quot;</span>,<span class="hljs-string">&quot;小程序&quot;</span>,<span class="hljs-string">&quot;前端&quot;</span>]<br>    <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywords_list:<br>        <span class="hljs-keyword">if</span> keyword <span class="hljs-keyword">in</span> line:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">handle_chat_corpus</span>(<span class="hljs-params">path</span>):<br>    chat_num = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./corpus/recall/text_classify.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(path,<span class="hljs-string">&quot;r&quot;</span>):<br>            <span class="hljs-keyword">if</span> line.strip() == <span class="hljs-string">&quot;E&quot;</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(line.strip())&lt;<span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">elif</span> keywords_in_line(line):<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">elif</span> line.startswith(<span class="hljs-string">&quot;M&quot;</span>):<br>                line = line[<span class="hljs-number">2</span>:]<br>                line = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,line)<br>                line_cuted = <span class="hljs-string">&quot; &quot;</span>.join(jieba_cut(line.strip())).strip()<br>                lable = <span class="hljs-string">&quot;\t__label__&#123;&#125;\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">&quot;chat&quot;</span>)<br>                f.write(line_cuted+lable)<br>                chat_num +=<span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(chat_num)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">handle_QA_corpus</span>():<br>  <br>    by_hand_data_path = <span class="hljs-string">&quot;./corpus/recall/手动构造的问题.json&quot;</span> <span class="hljs-comment">#手动构造的数据</span><br>    by_hand_data = json.load(<span class="hljs-built_in">open</span>(by_hand_data_path))<br><br>    qa_num = <span class="hljs-number">0</span><br><br>    f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./corpus/recall/text_classify.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> by_hand_data:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> by_hand_data[i]:<br>            <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> j:<br>                x = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, x)<br>                line_cuted = <span class="hljs-string">&quot; &quot;</span>.join(jieba_cut(x.strip())).strip()<br>                lable = <span class="hljs-string">&quot;\t__label__&#123;&#125;\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">&quot;QA&quot;</span>)<br>                f.write(line_cuted + lable)<br>                qa_num+=<span class="hljs-number">1</span><br><br>    <span class="hljs-comment">#mogodb导出的数据</span><br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./corpus/recall/爬虫抓取的问题.csv&quot;</span>):<br>        line = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, line)<br>        line_cuted = <span class="hljs-string">&quot; &quot;</span>.join(jieba_cut(line.strip()))<br>        lable = <span class="hljs-string">&quot;\t__label__&#123;&#125;\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">&quot;QA&quot;</span>)<br>        f.write(line_cuted + lable)<br>        qa_num += <span class="hljs-number">1</span><br><br>    f.close()<br>    <span class="hljs-built_in">print</span>(qa_num)<br></code></pre></td></tr></table></figure>

<h4 id="3-1-4-思考："><a href="#3-1-4-思考：" class="headerlink" title="3.1.4 思考："></a>3.1.4 思考：</h4><p>是否可以把文本分割为单个字作为特征呢？</p>
<p>修改上述代码，准备一份以单个字作为特征的符合要求的文本</p>
<h3 id="3-2-模型的训练"><a href="#3-2-模型的训练" class="headerlink" title="3.2 模型的训练"></a>3.2 模型的训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> fastText<br><span class="hljs-keyword">import</span> pickle<br><br>logging.basicConfig(<span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.DEBUG)<br><br><br>ft_model = fastText.train_supervised(<span class="hljs-string">&quot;./data/text_classify.txt&quot;</span>,wordNgrams=<span class="hljs-number">1</span>,epoch=<span class="hljs-number">20</span>)<br>ft_model.save_model(<span class="hljs-string">&quot;./data/ft_classify.model&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>训练完成后看看测试的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">ft_model = fastText.load_model(<span class="hljs-string">&quot;./data/ft_classify.model&quot;</span>)<br><br>textlist = [<br>    <span class="hljs-comment"># &quot;人工智能 和 人工智障 有 啥 区别&quot;, #QA</span><br>    <span class="hljs-comment"># &quot;我 来 学 python 是不是 脑袋 有 问题 哦&quot;, #QA</span><br>    <span class="hljs-comment"># &quot;什么 是 python&quot;, #QA</span><br>    <span class="hljs-comment"># &quot;人工智能 和 python 有 什么 区别&quot;,  #QA</span><br>    <span class="hljs-comment"># &quot;为什么 要 学 python&quot;, #QA</span><br>    <span class="hljs-comment"># &quot;python 该 怎么 学&quot;,  #CHAT</span><br>    <span class="hljs-comment"># &quot;python&quot;, #QA</span><br>    <span class="hljs-string">&quot;jave&quot;</span>, <span class="hljs-comment">#CHAT</span><br>    <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-comment">#QA</span><br>    <span class="hljs-string">&quot;理想 很 骨感 ，现实 很 丰满&quot;</span>,<br>    <span class="hljs-string">&quot;今天 天气 真好 啊&quot;</span>,<br>    <span class="hljs-string">&quot;你 怎么 可以 这样 呢&quot;</span>,<br>    <span class="hljs-string">&quot;哎呀 ， 我 错 了&quot;</span>,<br>]<br>ret = ft_model.predict(textlist)<br><span class="hljs-built_in">print</span>(ret)<br></code></pre></td></tr></table></figure>

<h4 id="3-2-2-模型的准确率该如何观察呢？"><a href="#3-2-2-模型的准确率该如何观察呢？" class="headerlink" title="3.2.2 模型的准确率该如何观察呢？"></a>3.2.2 模型的准确率该如何观察呢？</h4><p>观察准备去，首先需要对文本进行划分，分为训练集和测试集，之后再使用测试集观察模型的准确率</p>
<h3 id="3-3-模型的封装"><a href="#3-3-模型的封装" class="headerlink" title="3.3 模型的封装"></a>3.3 模型的封装</h3><p>为了在项目中更好的使用模型，需要对模型进行简单的封装，输入文本，返回结果</p>
<p>这里我们可以使用把单个字作为特征和把词语作为特征的手段结合起来实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">构造模型进行预测</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> fastText<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> cut<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Classify</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.ft_word_model = fastText.load_model(config.fasttext_word_model_path)<br>        self.ft_model = fastText.load_model(config.fasttext_model_path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">is_qa</span>(<span class="hljs-params">self,sentence_info</span>):<br>        python_qs_list = [<span class="hljs-string">&quot; &quot;</span>.join(sentence_info[<span class="hljs-string">&quot;cuted_sentence&quot;</span>])]<br>        result = self.ft_mode.predict(python_qs_list)<br><br>        python_qs_list = [<span class="hljs-string">&quot; &quot;</span>.join(cut(sentence_info[<span class="hljs-string">&quot;sentence&quot;</span>],by_word=<span class="hljs-literal">True</span>))]<br>        words_result = self.ft_word_mode.predict(python_qs_list)<br><br>        acc,word_acc = self.get_qa_prob(result,words_result)<br>        <span class="hljs-keyword">if</span> acc&gt;<span class="hljs-number">0.95</span> <span class="hljs-keyword">or</span> word_acc&gt;<span class="hljs-number">0.95</span>:<br>            <span class="hljs-comment">#是QA</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_qa_prob</span>(<span class="hljs-params">self,result,words_result</span>):<br>        label, acc, word_label, word_acc = <span class="hljs-built_in">zip</span>(*result, *words_result)<br>        label = label[<span class="hljs-number">0</span>]<br>        acc = acc[<span class="hljs-number">0</span>]<br>        word_label = word_label[<span class="hljs-number">0</span>]<br>        word_acc = word_acc[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">if</span> label == <span class="hljs-string">&quot;__label__chat&quot;</span>:<br>            acc = <span class="hljs-number">1</span> - acc<br>        <span class="hljs-keyword">if</span> word_label == <span class="hljs-string">&quot;__label__chat&quot;</span>:<br>            word_acc = <span class="hljs-number">1</span> - word_acc<br>        <span class="hljs-keyword">return</span> acc,word_acc<br></code></pre></td></tr></table></figure>

<h1 id="fastText的原理剖析"><a href="#fastText的原理剖析" class="headerlink" title="fastText的原理剖析"></a>fastText的原理剖析</h1><h2 id="目标-19"><a href="#目标-19" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够说出fasttext的架构</li>
<li>能够说出fasttext速度快的原因</li>
<li>能够说出fastText中层次化的softmax是如何实现的</li>
</ol>
<h2 id="1-fastText的模型架构"><a href="#1-fastText的模型架构" class="headerlink" title="1. fastText的模型架构"></a>1. fastText的模型架构</h2><p>fastText的架构非常简单，有三层：输入层、隐含层、输出层（Hierarchical Softmax）</p>
<p>输入层：是对文档embedding之后的向量，包含有N-garm特征</p>
<p>隐藏层：是对输入数据的求和平均</p>
<p>输出层：是文档对应标签</p>
<p>如下图所示：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/fasttext%E5%8E%9F%E7%90%86.jpg" srcset="/img/loading.gif" lazyload></p>
<h3 id="1-1-N-garm的理解"><a href="#1-1-N-garm的理解" class="headerlink" title="1.1 N-garm的理解"></a>1.1 N-garm的理解</h3><h3 id="1-1-1-bag-of-word"><a href="#1-1-1-bag-of-word" class="headerlink" title="1.1.1 bag of word"></a>1.1.1 bag of word</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bow%E6%A8%A1%E5%9E%8B.png" srcset="/img/loading.gif" lazyload></p>
<p>bag of word 又称为bow，称为词袋。是一种只统计词频的手段。</p>
<p>例如：在机器学习的课程中通过朴素贝叶斯来预测文本的类别，我们学习的countVectorizer和TfidfVectorizer都可以理解为一种bow模型。</p>
<h3 id="1-1-2-N-gram模型"><a href="#1-1-2-N-gram模型" class="headerlink" title="1.1.2 N-gram模型"></a>1.1.2 N-gram模型</h3><p>但是在很多情况下，词袋模型是不满足我们的需求的。</p>
<p>例如：<code>我爱她</code>  和<code>她爱我</code>在词袋模型下面，概率完全相同，但是其含义确实差别非常大。</p>
<p>为了解决这个问题，就有了N-gram模型，它不仅考虑词频，还会考虑当前词前面的词语，比如<code>我爱</code>，<code>她爱</code>。</p>
<p>N-gram模型的描述是：第n个词出现与前n-1个词相关，而与其他任何词不相关。（当然在很多场景下和前n-1个词也会相关，但是为了简化问题，经常会这样去计算）</p>
<p>例如：<code>I love deep learning</code>这个句子，在n&#x3D;2的情况下，可以表示为<code>&#123;i love&#125;,&#123;love deep&#125;,&#123;deep learning&#125;，</code>n&#x3D;3的情况下，可以表示为<code>&#123;I love deep&#125;,&#123;love deep learning&#125;</code>。</p>
<p>在n&#x3D;2的情况下，这个模型被称为Bi-garm（二元n-garm模型）</p>
<p>在n&#x3D;3 的情况下，这个模型被称为Tri-garm（三元n-garm模型）</p>
<p>具体可以参考 <a target="_blank" rel="noopener" href="http://web.stanford.edu/~jurafsky/slp3/ed3book.pdf">ed3book chapter3 </a></p>
<p>所以在fasttext的输入层，不仅有分词之后的词语，还有包含有N-gram的组合词语一起作为输入</p>
<h2 id="2-fastText中的层次化的softmax-对传统softmax的优化方法1"><a href="#2-fastText中的层次化的softmax-对传统softmax的优化方法1" class="headerlink" title="2. fastText中的层次化的softmax-对传统softmax的优化方法1"></a>2. fastText中的层次化的softmax-对传统softmax的优化方法1</h2><p>为了提高效率，在fastText中计算分类标签的概率的时候，不再是使用传统的softmax来进行多分类的计算，而是使用的哈夫曼树(Huffman，也成为霍夫曼树),使用层次化的softmax（Hierarchial softmax）来进行概率的计算。</p>
<h3 id="2-1-哈夫曼树和哈夫曼编码"><a href="#2-1-哈夫曼树和哈夫曼编码" class="headerlink" title="2.1 哈夫曼树和哈夫曼编码"></a>2.1 哈夫曼树和哈夫曼编码</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Inked%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91.jpg" srcset="/img/loading.gif" lazyload></p>
<h4 id="2-1-1-哈夫曼树的定义"><a href="#2-1-1-哈夫曼树的定义" class="headerlink" title="2.1.1 哈夫曼树的定义"></a>2.1.1 哈夫曼树的定义</h4><p>哈夫曼树概念：给定n个权值作为n个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。</p>
<p>哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。</p>
<h4 id="2-1-2-哈夫曼树的相关概念"><a href="#2-1-2-哈夫曼树的相关概念" class="headerlink" title="2.1.2 哈夫曼树的相关概念"></a>2.1.2 哈夫曼树的相关概念</h4><p><strong>二叉树</strong>：每个节点最多有2个子树的有序树，两个子树分别称为左子树、右子树。有序的意思是：树有左右之分，不能颠倒</p>
<p><strong>叶子节点</strong>：一棵树当中没有子结点的结点称为叶子结点，简称“叶子”</p>
<p><strong>路径和路径长度</strong>：在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。</p>
<p><strong>结点的权及带权路径长度</strong>：若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度与该结点的权的<strong>乘积</strong>。</p>
<p><strong>树的带权路径长度</strong>：树的带权路径长度规定为所有叶子结点的带权路径长度之和</p>
<p><strong>树的高度</strong>：树中结点的最大层次。包含n个结点的二叉树的高度至少为**log2 (n+1)**。</p>
<h4 id="2-1-3-哈夫曼树的构造算法"><a href="#2-1-3-哈夫曼树的构造算法" class="headerlink" title="2.1.3 哈夫曼树的构造算法"></a>2.1.3 哈夫曼树的构造算法</h4><ol>
<li>把${W_1,W_2,W_3 \dots W_n}$看成n棵树的森林</li>
<li>在森林中选择两个根节点权值最小的树进行合并，作为一颗新树的左右子树，新树的根节点权值为左右子树的和</li>
<li>删除之前选择出的子树，把新树加入森林</li>
<li>重复2-3步骤，直到森林只有一棵树为止，概树就是所求的哈夫曼树</li>
</ol>
<p>例如：圆圈中的表示每个词语出现的次数，以这些词语为叶子节点构造的哈夫曼树过程如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91%E6%9E%84%E9%80%A0%E8%BF%87%E7%A8%8B.png" srcset="/img/loading.gif" lazyload></p>
<p>可见：</p>
<ol>
<li>权重越大，距离根节点越近</li>
<li>叶子的个数为n，构造哈夫曼树中新增的节点的个数为n-1</li>
</ol>
<h4 id="2-2-1-哈夫曼编码"><a href="#2-2-1-哈夫曼编码" class="headerlink" title="2.2.1 哈夫曼编码"></a>2.2.1 哈夫曼编码</h4><p>在数据通信中，需要将传送的文字转换成二进制的字符串，用0，1码的不同排列来表示字符。</p>
<p>例如，需传送的报文为<code>AFTER DATA EAR ARE ART AREA</code>，这里用到的字符集为<code>A，E，R，T，F，D</code>，各字母出现的次数为{8，4，5，3，1，1}。现要求为这些字母设计编码。要区别6个字母，最简单的二进制编码方式是等长编码，固定采用3位二进制，可分别用<code>000、001、010、011、100、101</code>对<code>A，E，R，T，F，D</code>进行编码发送</p>
<p>但是很明显，上述的编码的方式并不是最优的，即整理传送的字节数量并不是最少的。</p>
<p>为了提高数据传送的效率，同时为了保证<code>任一字符的编码都不是另一个字符编码的前缀，这种编码称为前缀编码[前缀编码]</code>,可以使用哈夫曼树生成哈夫曼编码解决问题</p>
<p>可用字符集中的每个字符作为叶子结点生成一棵编码二叉树，为了获得传送报文的最短长度，可将每个字符的出现频率作为字符结点的权值赋予该结点上，显然字使用频率越小权值越小，权值越小叶子就越靠下，于是频率小编码长，频率高编码短，这样就保证了此树的最小带权路径长度效果上就是传送报文的最短长度</p>
<p>因此，求传送报文的最短长度问题转化为求由字符集中的所有字符作为叶子结点，由字符出现频率作为其权值所产生的哈夫曼树的问题。利用哈夫曼树来设计二进制的前缀编码，既满足前缀编码的条件，又保证报文编码总长最短。</p>
<p>下图中<code>label1 .... label6</code>分别表示<code>A，E，R，T，F，D</code></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81.jpg" srcset="/img/loading.gif" lazyload></p>
<h4 id="2-3-梯度计算"><a href="#2-3-梯度计算" class="headerlink" title="2.3 梯度计算"></a>2.3 梯度计算</h4><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81%20-%20%E5%89%AF%E6%9C%AC.jpg" srcset="/img/loading.gif" lazyload></p>
<p>上图中，红色为哈夫曼编码，即label5的哈夫曼编码为1001，那么此时如何定义条件概率$P(Label5|contex)$呢？</p>
<p>以Label5为例，从根节点到Label5中间经历了4次分支，每次分支都可以认为是进行了一次2分类，根据哈夫曼编码，可以把路径中的每个非叶子节点0认为是负类，1认为是正类（也可以把0认为是正类）</p>
<p>由机器学习课程中逻辑回归使用sigmoid函数进行2分类的过程中，一个节点被分为正类的概率是$\delta(X^{T}\theta) &#x3D; \frac{1}{1+e^{-X^T\theta}}$,被分类负类的概率是：$1-\delta(X^T\theta)$，其中$\theta$就是图中非叶子节点对应的参数$\theta$。</p>
<p>对于从根节点出发，到达Label5一共经历4次2分类，将每次分类结果的概率写出来就是：</p>
<ol>
<li>第一次：$P(1|X,\theta_1) &#x3D; \delta(X^T\theta_1) $ ,即从根节点到23节点的概率是在知道X和$\theta_1$的情况下取值为1的概率</li>
<li>第二次：$P(0|X,\theta_2) &#x3D;1- \delta(X^T\theta_2) $  </li>
<li>第三次：$P(0 |X,\theta_3) &#x3D;1- \delta(X^T\theta_4) $</li>
<li>第四次：$P(1|X,\theta_4) &#x3D; \delta(X^T\theta_4) $</li>
</ol>
<p>但是我们需要求的是$P(Label|contex)$, 他等于前4词的概率的乘积，公式如下（$d_j^w$是第j个节点的哈夫曼编码）<br>$$<br>P(Label|context) &#x3D; \prod_{j&#x3D;2}^5P(d_j|X,\theta_{j-1})<br>$$</p>
<p>其中：<br>$$<br>P(d_j|X,\theta_{j-1}) &#x3D; \left{<br>\begin{aligned}<br>&amp;\delta(X^T\theta_{j-1}), &amp; d_j&#x3D;1;\<br>&amp;1-\delta(X^T\theta_{j-1}) &amp; d_j&#x3D;0;<br>\end{aligned}<br>\right.<br>$$</p>
<p>或者也可以写成一个整体,把目标值作为指数，之后取log之后会前置：<br>$$<br>P(d_j|X,\theta_{j-1}) &#x3D; [\delta(X^T\theta_{j-1})]^{d_j} \cdot [1-\delta(X^T\theta_{j-1})]^{1-d_j}<br>$$</p>
<p>在机器学习中的逻辑回归中，我们经常把二分类的损失函数(目标函数)定义为对数似然损失，即<br>$$<br>l &#x3D;-\frac{1}{M} \sum_{label\in labels} log\ P(label|context)<br>$$</p>
<p>式子中，求和符号表示的是使用样本的过程中，每一个label对应的概率取对数后的和，之后求取均值。</p>
<p>带入前面对$P(label|context)$的定义得到：<br>$$<br>\begin{align*}<br>l &amp; &#x3D; -\frac{1}{M}\sum_{label\in labels}log \prod_{j&#x3D;2}{[\delta(X^T\theta_{j-1})]^{d_j} \cdot [1-\delta(X^T\theta_{j-1})]^{1-d_j}} \<br>&amp; &#x3D;-\frac{1}{M} \sum_{label\in labels} \sum_{j&#x3D;2}{d_j\cdot log[\delta(X^T\theta_{j-1})]+ (1-d_j) \cdot log [1-\delta(X^T\theta_{j-1})]}<br>\end{align*}<br>$$<br>有了损失函数之后，接下来就是对其中的$X,\theta$进行求导，并更新，最终还需要更新最开始的每个词语词向量</p>
<p><strong>层次化softmax的好处</strong>：传统的softmax的时间复杂度为L（Labels的数量），但是使用层次化softmax之后时间复杂度的log(L) （二叉树高度和宽度的近似），从而在多分类的场景提高了效率</p>
<h2 id="3-fastText中的negative-sampling-负采样-对传统softmax的优化方法2"><a href="#3-fastText中的negative-sampling-负采样-对传统softmax的优化方法2" class="headerlink" title="3. fastText中的negative sampling(负采样)-对传统softmax的优化方法2"></a>3. fastText中的negative sampling(负采样)-对传统softmax的优化方法2</h2><p>negative sampling，即每次从除当前label外的其他label中，随机的选择几个作为负样本。具体的采样方法：</p>
<p>如果所有的label为$V$,那么我们就将一段长度为1的线段分成$V$份，每份对应所有label中的一类label。当然每个词对应的线段长度是不一样的，高频label对应的线段长，低频label对应的线段短。每个label的线段长度由下式决定：<br>$$<br>len(w) &#x3D; \frac{count(label)^{\alpha}}{\sum_{w \in labels} count(labels)^{\alpha}},a在fasttext中为0.75，即负采样的数量和原来词频的平方根成正比<br>$$<br>在采样前，我们将这段长度为1的线段划分成$M$等份，这里$M&gt;&gt;V$，这样可以保证每个label对应的线段都会划分成对应的小块。而M份中的每一份都会落在某一个label对应的线段上。在采样的时候，我们只需要从$M$个位置中采样出neg个位置就行，此时采样到的每一个位置对应到的线段所属的词就是我们的负例。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%B4%9F%E9%87%87%E6%A0%B7.png" srcset="/img/loading.gif" lazyload></p>
<p>简单的理解就是，从原来所有的样本中，等比例的选择neg个负样本作（遇到自己则跳过），作为训练样本，添加到训练数据中，和正例样本一起来进行训练。</p>
<p>Negative Sampling也是采用了二元逻辑回归来求解模型参数，通过负采样，我们得到了neg个负例，将正例定义为$label_0$,负例定义为$label_i,i&#x3D;1,2,3…neg$</p>
<p>定义正例的概率为$P\left( label_{0}|\text {context}\right)&#x3D;\sigma\left(x_{\mathrm{k}}^{T} \theta\right), y_{i}&#x3D;1$</p>
<p>则负例的概率为：$P\left( label_{i}|\text {context}\right)&#x3D;1-\sigma\left(x_{\mathrm{k}}^{T} \theta\right), y_{i}&#x3D;0,i&#x3D;1,2,3..neg$</p>
<p>此时对应的对数似然函数为：<br>$$<br>L&#x3D;\sum_{i&#x3D;0}^{n e g} y_{i} \log \left(\sigma\left(x_{label_0}^{T} \theta\right)\right)+\left(1-y_{i}\right) \log \left(1-\sigma\left(x_{label_0}^{T} \theta\right)\right)<br>$$<br>具体的训练时候损失的计算过程(源代码已经更新)：</p>
<p><img src="/../../../../BaiduNetdiskDownload/%25E9%2598%25B6%25E6%25AE%25B59-%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BDNLP%25E9%25A1%25B9%25E7%259B%25AE/NLP%25E8%25AF%25BE%25E4%25BB%25B6%25E7%25BC%2596%25E5%2586%2599/markdown/doc/images/2.2/fasttext%25E8%25B4%259F%25E9%2587%2587%25E6%25A0%25B7.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看出：一个neg+1个样本进行了训练，得到了总的损失。</p>
<p>之后会使用梯度上升的方法进行梯度计算和参数更新，仅仅每次只用一波样本(一个正例和neg个反例)更新梯度，来进行迭代更新</p>
<p>具体的更新伪代码如下:</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%B4%9F%E9%87%87%E6%A0%B7%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87.png" srcset="/img/loading.gif" lazyload></p>
<p>其中内部大括号部分为w相关参数的梯度计算过程，e为w的梯度和学习率的乘积，具体参考:<a target="_blank" rel="noopener" href="https://blog.csdn.net/itplus/article/details/37998797">https://blog.csdn.net/itplus/article/details/37998797</a></p>
<p>好处：</p>
<ol>
<li>提高训练速度，选择了部分数据进行计算损失，同时整个对每一个label而言都是一个二分类，损失计算更加简单，只需要让当前label的值的概率尽可能大，其他label的都为反例，概率会尽可能小</li>
<li>改进效果，增加部分负样本，能够模拟真实场景下的噪声情况，能够让模型的稳健性更强</li>
</ol>
<h1 id="闲聊机器人的介绍"><a href="#闲聊机器人的介绍" class="headerlink" title="闲聊机器人的介绍"></a>闲聊机器人的介绍</h1><h2 id="目标-20"><a href="#目标-20" class="headerlink" title="目标"></a>目标</h2><ol>
<li>了解闲聊机器人是什么</li>
</ol>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在项目准备阶段我们知道，用户说了一句话后，会判断其意图，如果是想进行闲聊，那么就会调用闲聊模型返回结果，这是我们会在项目中实现的功能。</p>
<p>目前市面上的常见闲聊机器人有<code>微软小冰</code>这种类型的模型，很久之前还有<code>小黄鸡</code>这种体验更差的模型</p>
<p>常见的闲聊模型都是一种seq2seq的结构，在后面的课程中我们会学习并使用seq2seq来实现我们的闲聊机器人</p>
<h1 id="Seq2Seq模型的原理"><a href="#Seq2Seq模型的原理" class="headerlink" title="Seq2Seq模型的原理"></a>Seq2Seq模型的原理</h1><h2 id="目标-21"><a href="#目标-21" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道seq2seq的常见应用场景</li>
<li>能够说出常见的seq2seq的结构</li>
<li>能够使用代码完成基础的seq2seq的结构</li>
</ol>
<h2 id="1-Seq2Seq的介绍"><a href="#1-Seq2Seq的介绍" class="headerlink" title="1. Seq2Seq的介绍"></a>1. Seq2Seq的介绍</h2><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/seq2seq.png" srcset="/img/loading.gif" lazyload></p>
<p><code>Sequence to sequence (seq2seq)</code>是由<code>encoder（编码器）</code>和<code>decoder（解码器）</code>两个RNN的组成的。其中encoder负责对输入句子的理解，转化为<code>context vector</code>，decoder负责对理解后的句子的向量进行处理，解码，获得输出。上述的过程和我们大脑理解东西的过程很相似，<code>听到一句话，理解之后，尝试组装答案，进行回答</code></p>
<p>那么此时，就有一个问题，在encoder的过程中得到的context vector作为decoder的输入，那么这样一个输入，怎么能够得到多个输出呢？</p>
<p>其实就是<code>当前一步的输出，作为下一个单元的输入，然后得到结果</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = []<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    output = decoderd(output)<br>    outputs.append(output)<br></code></pre></td></tr></table></figure>

<p>那么循环什么时候停止呢？</p>
<p>在训练数据集中，可以再输出的最后面添加一个结束符<code>&lt;END&gt;</code>，如果遇到该结束符，则可以终止循环</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = []<br><span class="hljs-keyword">while</span> output!=<span class="hljs-string">&quot;&lt;END&gt;&quot;</span>:<br>    output = decoderd(output)<br>    outputs.append(output)<br></code></pre></td></tr></table></figure>

<p>这个结束符只是一个标记，很多人也会使用<code>&lt;EOS&gt;(End Of Sentence)</code></p>
<p>总之：Seq2seq模型中的encoder接受一个长度为M的序列，得到1个 context vector，之后decoder把这一个context vector转化为长度为N的序列作为输出，从而构成一个<code>M to N</code>的模型，能够处理很多不定长输入输出的问题，比如：<code>文本翻译，问答，文章摘要，关键字写诗等等</code></p>
<h2 id="2-Seq2Seq模型的实现"><a href="#2-Seq2Seq模型的实现" class="headerlink" title="2. Seq2Seq模型的实现"></a>2. Seq2Seq模型的实现</h2><p>下面，我们通过一个简单的列子，来看看普通的Seq2Seq模型应该如何实现。</p>
<p><strong>需求</strong>：完成一个模型，实现往模型输入一串数字，输出这串数字+0</p>
<p><strong>例如</strong>：</p>
<ul>
<li>输入<code>123456789</code>，输出<code>1234567890</code>；</li>
<li>输入<code>52555568</code>，输出<code>525555680</code></li>
</ul>
<h3 id="2-1-实现流程"><a href="#2-1-实现流程" class="headerlink" title="2.1 实现流程"></a>2.1 实现流程</h3><ol>
<li>文本转化为序列（数字序列，<code>torch.LongTensor</code>）</li>
<li>使用序列，准备数据集，准备<code>Dataloader</code></li>
<li>完成编码器</li>
<li>完成解码器</li>
<li>完成seq2seq模型</li>
<li>完成模型训练的逻辑，进行训练</li>
<li>完成模型评估的逻辑，进行模型评估</li>
</ol>
<h3 id="2-2-文本转化为序列"><a href="#2-2-文本转化为序列" class="headerlink" title="2.2 文本转化为序列"></a>2.2 文本转化为序列</h3><p>由于输入的是数字，为了把这写数字和词典中的真实数字进行对应，可以把这些数字理解为字符串</p>
<p>那么我们需要做的就是：</p>
<ol>
<li>把字符串对应为数字</li>
<li>把数字转化为字符串</li>
</ol>
<p>完成逻辑和之前相同，创建<code>word_sequence.py</code>文件，实现上述逻辑</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NumSequence</span>:<br>    UNK_TAG = <span class="hljs-string">&quot;UNK&quot;</span> <span class="hljs-comment">#未知词</span><br>    PAD_TAG = <span class="hljs-string">&quot;PAD&quot;</span> <span class="hljs-comment">#填充词，实现文本对齐，即一个batch中的句子长度都是相同的，短句子会被padding</span><br>    EOS_TAG = <span class="hljs-string">&quot;EOS&quot;</span> <span class="hljs-comment">#句子的开始</span><br>    SOS_TAG = <span class="hljs-string">&quot;SOS&quot;</span> <span class="hljs-comment">#句子的结束</span><br><br>    UNK = <span class="hljs-number">0</span><br>    PAD = <span class="hljs-number">1</span><br>    EOS = <span class="hljs-number">2</span><br>    SOS = <span class="hljs-number">3</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.<span class="hljs-built_in">dict</span> = &#123;<br>            self.UNK_TAG : self.UNK,<br>            self.PAD_TAG : self.PAD,<br>            self.EOS_TAG : self.EOS,<br>            self.SOS_TAG : self.SOS<br>        &#125;<br>        <span class="hljs-comment">#得到字符串和数字对应的字典</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            self.<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>(i)] = <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br>		<span class="hljs-comment">#得到数字和字符串对应的字典</span><br>        self.index2word = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.<span class="hljs-built_in">dict</span>.values(),self.<span class="hljs-built_in">dict</span>.keys()))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self,sequence,max_len=<span class="hljs-literal">None</span>,add_eos=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        sequence：句子</span><br><span class="hljs-string">        max_len :句子的最大长度</span><br><span class="hljs-string">        add_eos:是否添加结束符</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <br>        sequence_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">str</span>(sequence))<br>        seq_len = <span class="hljs-built_in">len</span>(sequence_list)+<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> add_eos <span class="hljs-keyword">else</span> <span class="hljs-built_in">len</span>(sequence_list)<br><br>        <span class="hljs-keyword">if</span> add_eos <span class="hljs-keyword">and</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">assert</span> max_len&gt;= seq_len, <span class="hljs-string">&quot;max_len 需要大于seq+eos的长度&quot;</span><br>        _sequence_index = [self.<span class="hljs-built_in">dict</span>.get(i,self.UNK) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sequence_list]<br>        <span class="hljs-keyword">if</span> add_eos:<br>            _sequence_index += [self.EOS]<br>        <span class="hljs-keyword">if</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            sequence_index = [self.PAD]*max_len<br>            sequence_index[:seq_len] =  _sequence_index<br>            <span class="hljs-keyword">return</span> sequence_index<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> _sequence_index<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inverse_transform</span>(<span class="hljs-params">self,sequence_index</span>):<br>        result = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sequence_index:<br>            <span class="hljs-keyword">if</span> i==self.EOS:<br>                <span class="hljs-keyword">break</span><br>            result.append(self.index2word.get(<span class="hljs-built_in">int</span>(i),self.UNK_TAG))<br>        <span class="hljs-keyword">return</span> result<br><span class="hljs-comment"># 实例化，供后续调用</span><br>num_sequence = NumSequence()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    num_sequence = NumSequence()<br>    <span class="hljs-built_in">print</span>(num_sequence.<span class="hljs-built_in">dict</span>)<br>    <span class="hljs-built_in">print</span>(num_sequence.index2word)<br>    <span class="hljs-built_in">print</span>(num_sequence.transform(<span class="hljs-string">&quot;1231230&quot;</span>,add_eos=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure>



<h3 id="2-3-准备数据集"><a href="#2-3-准备数据集" class="headerlink" title="2.3 准备数据集"></a>2.3 准备数据集</h3><h4 id="2-3-1-准备Dataset"><a href="#2-3-1-准备Dataset" class="headerlink" title="2.3.1 准备Dataset"></a>2.3.1 准备<code>Dataset</code></h4><p>这里，我们使用随机创建的<code>[0,100000000]</code>的整型，来准备数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> config<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RandomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(RandomDataset,self).__init__()<br>        self.total_data_size = <span class="hljs-number">500000</span><br>        np.random.seed(<span class="hljs-number">10</span>)<br>        self.total_data = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">100000000</span>,size=[self.total_data_size])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;返回input，target，input_length,target_length(真实长度)&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">input</span> = <span class="hljs-built_in">str</span>(self.total_data[idx])<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>, <span class="hljs-built_in">input</span>+ <span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>),<span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>)+<span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.total_data_size<br></code></pre></td></tr></table></figure>

<p>通过随机数的结果，可以看到，大部分的数字长度为8，在目标值后面添加上0和EOS之后，最大长度为10</p>
<p>所以常见config配置文件，添加上<code>max_len：文本最大长度</code>，方便后续的修改</p>
<h4 id="2-3-2-准备DataLoader"><a href="#2-3-2-准备DataLoader" class="headerlink" title="2.3.2 准备DataLoader"></a>2.3.2 准备<code>DataLoader</code></h4><p>在准备<code>DataLoader</code>的过程中，可以通过定义的collate_fn来实现对dataset中batch数据的处理</p>
<p>其中需要注意：</p>
<ol>
<li>需要对batch中的数据进行排序，根据数据的真实长度进行降序排序（后面需要用到）</li>
<li>需要调用<code>文本序列化</code>的方法，把文本进行序列化的操作，同时target需要进行<code>add eos</code>的操作</li>
<li>最后返回序列的LongTensor格式</li>
<li>在<code>DataLoader中有drop_last参数</code>，当数据量无法被batch_size整除时，最后一个batch的数据个数和之前的数据个数长度不同，可以考虑进行删除</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):<br>    <span class="hljs-comment">#1. 对batch进行排序，按照长度从长到短的顺序排序</span><br>    batch = <span class="hljs-built_in">sorted</span>(batch,key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">3</span>],reverse=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">input</span>,target,input_length,target_length = <span class="hljs-built_in">zip</span>(*batch)<br><br>    <span class="hljs-comment">#2.进行padding的操作</span><br>    <span class="hljs-built_in">input</span> = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>])<br>    target = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len,add_eos=<span class="hljs-literal">True</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> target])<br>    input_length = torch.LongTensor(input_length)<br>    target_length = torch.LongTensor(target_length)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>,target,input_length,target_length<br><br>data_loader = DataLoader(dataset=RandomDataset(),batch_size=config.batch_size,collate_fn=collate_fn,drop_last=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>



<h3 id="2-4-准备编码器"><a href="#2-4-准备编码器" class="headerlink" title="2.4 准备编码器"></a>2.4 准备编码器</h3><p>编码器（encoder）的目的就是为了对文本进行编码，把编码后的结果交给后续的程序使用，所以在这里我们可以使用<code>Embedding+GRU</code>的结构来使用，使用最后一个<code>time step</code>的输出(<code>hidden state</code>)作为<code>句子的编码结果</code></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Encoder.png" srcset="/img/loading.gif" lazyload></p>
<p>注意点：</p>
<ol>
<li>Embedding和GRU的参数,这里我们让GRU中batch放在前面</li>
<li>输出结果的形状</li>
<li>在LSTM和GRU中，每个<code>time step</code>的输入会进行计算，得到结果，整个过程是一个和句子长度相关的一个循环，手动实现速度较慢<ol>
<li>pytorch中实现了<code>nn.utils.rnn.pack_padded_sequence</code> 对padding后的句子进行打包的操作能够更快获得LSTM or GRU的结果</li>
<li>同时实现了<code>nn.utils.rnn.pad_packed_sequence</code>对打包的内容进行解包的操作</li>
</ol>
</li>
<li><code>nn.utils.rnn.pack_padded_sequence</code>使用过程中需要对batch中的内容按照句子的长度<strong>降序排序</strong></li>
</ol>
<p>实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence<br><span class="hljs-keyword">import</span> config<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NumEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(NumEncoder,self).__init__()<br>        self.vocab_size = <span class="hljs-built_in">len</span>(num_sequence)<br>        self.dropout = config.dropout<br>        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=config.embedding_dim,padding_idx=num_sequence.PAD)<br>        self.gru = nn.GRU(input_size=config.embedding_dim,<br>                          hidden_size=config.hidden_size,<br>                          num_layers=<span class="hljs-number">1</span>,<br>                          batch_first=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>,input_length</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        input:[batch_size,max_len]</span><br><span class="hljs-string">        input_length:[batch_size]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        embeded = self.embedding(<span class="hljs-built_in">input</span>) <span class="hljs-comment">#[batch_size,max_len , embedding_dim]</span><br>        <br>        <span class="hljs-comment">#对文本对齐之后的句子进行打包，能够加速在LSTM or GRU中的计算过程</span><br>        embeded = nn.utils.rnn.pack_padded_sequence(embeded,lengths=input_length,batch_first=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment">#hidden:[1,batch_size,vocab_size]</span><br>        out,hidden = self.gru(embeded)<br>        <br>        <span class="hljs-comment">#对前面打包后的结果再进行解包</span><br>        out,outputs_length = nn.utils.rnn.pad_packed_sequence(out,batch_first=<span class="hljs-literal">True</span>,padding_value=num_sequence.PAD)<br>        <span class="hljs-comment"># out [batch_size,seq_len,hidden_size]</span><br>        <span class="hljs-keyword">return</span> out,hidden<br></code></pre></td></tr></table></figure>



<h3 id="2-5-实现解码器"><a href="#2-5-实现解码器" class="headerlink" title="2.5 实现解码器"></a>2.5 实现解码器</h3><p>加码器主要负责实现对编码之后结果的处理，得到预测值，为后续计算损失做准备</p>
<p>此时需要思考：</p>
<ol>
<li><p>使用什么样的损失函数，预测值需要是什么格式的</p>
<ul>
<li>结合之前的经验，我们可以理解为当前的问题是一个分类的问题，即每次的输出其实对选择一个概率最大的词</li>
<li>真实值的形状是<code>[batch_size,max_len]</code>，从而我们知道输出的结果需要是一个<code>[batch_size,max_len,vocab_size]</code>的形状</li>
<li>即预测值的最后一个维度进行计算log_softmax,然后和真实值进行相乘，从而得到损失</li>
</ul>
</li>
<li><p>如何把编码结果<code>[1,batch_size,hidden_size]</code>进行操作，得到预测值。解码器也是一个RNN，即也可以使用LSTM or GRU的结构，所以在解码器中：</p>
<ul>
<li><p>通过循环，每次计算的一个time step的内容</p>
</li>
<li><p>编码器的结果作为初始的隐层状态，定义一个<code>[batch_size,1]</code>的全为<code>SOS</code>的数据作为最开始的输入，告诉解码器，要开始工作了</p>
</li>
<li><p>通过解码器预测一个输出<code>[batch_size,hidden_size]</code>(会进行形状的调整为<code>[batch_size,vocab_size]</code>)，把这个输出作为输入再使用解码器进行解码</p>
</li>
<li><p>上述是一个循环，循环次数就是句子的最大长度，那么就可以得到<code>max_len</code>个输出</p>
</li>
<li><p>把所有输出的结果进行concate，得到<code>[batch_size,max_len,vocab_size]</code></p>
</li>
</ul>
</li>
<li><p>在RNN的训练过程中，使用前一个预测的结果作为下一个step的输入，可能会导致<code>一步错，步步错的结果</code>，如果提高模型的收敛速度？</p>
<ul>
<li>可以考虑在训练的过程中，把真实值作为下一步的输入，这样可以避免<code>步步错的局面</code></li>
<li>同时在使用真实值的过程中，仍然使用预测值作为下一步的输入，两种输入随机使用</li>
<li>上述这种机制我们把它称为<code>Teacher forcing</code>，就像是一个指导老师，在每一步都会对我们的行为进行纠偏，从而达到在多次训练之后能够需要其中的规律</li>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/teacher%20forcing.jpg" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NumDecoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(NumDecoder,self).__init__()<br>        self.max_seq_len = config.max_len<br>        self.vocab_size = <span class="hljs-built_in">len</span>(num_sequence)<br>        self.embedding_dim = config.embedding_dim<br>        self.dropout = config.dropout<br><br>        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=self.embedding_dim,padding_idx=num_sequence.PAD)<br>        self.gru = nn.GRU(input_size=self.embedding_dim,<br>                          hidden_size=config.hidden_size,<br>                          num_layers=<span class="hljs-number">1</span>,<br>                          batch_first=<span class="hljs-literal">True</span>,<br>                          dropout=self.dropout)<br>        self.log_softmax = nn.LogSoftmax()<br><br>        self.fc = nn.Linear(config.hidden_size,self.vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_hidden,target,target_length</span>):<br>        <span class="hljs-comment"># encoder_hidden [batch_size,hidden_size]</span><br>        <span class="hljs-comment"># target [batch_size,max_len]</span><br>		<br>        <span class="hljs-comment">#初始的全为SOS的输入</span><br>        decoder_input = torch.LongTensor([[num_sequence.SOS]]*config.batch_size)<br><br>        <span class="hljs-comment">#解码器的输出，用来后保存所有的输出结果</span><br>        decoder_outputs = torch.zeros(config.batch_size,config.max_len,self.vocab_size) <br>		<br>        decoder_hidden = encoder_hidden <span class="hljs-comment">#[batch_size,hidden_size]</span><br><br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>            decoder_output_t , decoder_hidden = self.forward_step(decoder_input,decoder_hidden)<br>            <br>            <span class="hljs-comment">#在不同的time step上进行复制，decoder_output_t [batch_size,vocab_size]</span><br>            decoder_outputs[:,t,:] = decoder_output_t<br>			<br>            <span class="hljs-comment">#在训练的过程中，使用 teacher forcing，进行纠偏</span><br>            use_teacher_forcing = random.random() &gt; <span class="hljs-number">0.5</span><br>            <span class="hljs-keyword">if</span> use_teacher_forcing:<br>                <span class="hljs-comment">#下一次的输入使用真实值</span><br>                decoder_input =target[:,t].unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment">#[batch_size,1]</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment">#使用预测值，topk中k=1，即获取最后一个维度的最大的一个值</span><br>                value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>) <span class="hljs-comment"># index [batch_size,1]</span><br>                decoder_input = index<br>        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self,decoder_input,decoder_hidden</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param decoder_input:[batch_size,1]</span><br><span class="hljs-string">        :param decoder_hidden: [1,batch_size,hidden_size]</span><br><span class="hljs-string">        :return: out:[batch_size,vocab_size],decoder_hidden:[1,batch_size,didden_size]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        embeded = self.embedding(decoder_input)  <span class="hljs-comment">#embeded: [batch_size,1 , embedding_dim]</span><br><br>        out,decoder_hidden = self.gru(embeded,decoder_hidden) <span class="hljs-comment">#out [1, batch_size, hidden_size]</span><br><br>       	out = out.squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment">#去除第0维度的1</span><br>        <span class="hljs-comment">#进行全连接形状变化，同时进行求取log_softmax</span><br>        out = F.log_softmax(self.fc(out),dim=-<span class="hljs-number">1</span>)<span class="hljs-comment">#out [batch_Size,1, vocab_size]</span><br>        out = out.squeeze(<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> out,decoder_hidden<br><br></code></pre></td></tr></table></figure>



<h3 id="2-6-完成seq2seq模型"><a href="#2-6-完成seq2seq模型" class="headerlink" title="2.6 完成seq2seq模型"></a>2.6 完成seq2seq模型</h3><p>调用之前的encoder和decoder，完成模型的搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,encoder,decoder</span>):<br>        <span class="hljs-built_in">super</span>(Seq2Seq,self).__init__()<br>        self.encoder = encoder<br>        self.decoder = decoder<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>,target,input_length,target_length</span>):<br>        <span class="hljs-comment">#进行编码</span><br>        encoder_outputs,encoder_hidden = self.encoder(<span class="hljs-built_in">input</span>,input_length)<br>        <span class="hljs-comment">#进行解码</span><br>        decoder_outputs,decoder_hidden = self.decoder(encoder_hidden,target,target_length)<br>        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden<br></code></pre></td></tr></table></figure>



<h3 id="2-7-完成训练逻辑"><a href="#2-7-完成训练逻辑" class="headerlink" title="2.7 完成训练逻辑"></a>2.7 完成训练逻辑</h3><p>思路流程和之前相同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> encoder <span class="hljs-keyword">import</span> NumEncoder<br><span class="hljs-keyword">from</span> decoder <span class="hljs-keyword">import</span> NumDecoder<br><span class="hljs-keyword">from</span> seq2seq <span class="hljs-keyword">import</span> Seq2Seq<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> data_loader <span class="hljs-keyword">as</span> train_dataloader<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence<br><br><br><br>encoder = NumEncoder()<br>decoder = NumDecoder()<br>model = Seq2Seq(encoder,decoder)<br><span class="hljs-built_in">print</span>(model)<br><br><span class="hljs-comment">#自定义初始化参数</span><br><span class="hljs-comment">#for name, param in model.named_parameters():</span><br><span class="hljs-comment">#    if &#x27;bias&#x27; in name:</span><br><span class="hljs-comment">#        torch.nn.init.constant_(param, 0.0)</span><br><span class="hljs-comment">#    elif &#x27;weight&#x27; in name:</span><br><span class="hljs-comment">#        torch.nn.init.xavier_normal_(param)</span><br><br><span class="hljs-comment"># model.load_state_dict(torch.load(&quot;model/seq2seq_model.pkl&quot;))</span><br>optimizer =  optim.Adam(model.parameters())<br><span class="hljs-comment"># optimizer.load_state_dict(torch.load(&quot;model/seq2seq_optimizer.pkl&quot;))</span><br>criterion= nn.NLLLoss(ignore_index=num_sequence.PAD,reduction=<span class="hljs-string">&quot;mean&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_loss</span>(<span class="hljs-params">decoder_outputs,target</span>):<br>    <span class="hljs-comment">#很多时候如果tensor进行了转置等操作，直接调用view进行形状的修改是无法成功的</span><br>    <span class="hljs-comment">#target = target.contiguous().view(-1) #[batch_size*max_len]</span><br>    target = target.view(-<span class="hljs-number">1</span>)<br>    decoder_outputs = decoder_outputs.view(config.batch_size*config.max_len,-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> criterion(decoder_outputs,target)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    <span class="hljs-keyword">for</span> idx,(<span class="hljs-built_in">input</span>,target,input_length,target_len) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        optimizer.zero_grad()<br>        <span class="hljs-comment">##[seq_len,batch_size,vocab_size] [batch_size,seq_len]</span><br>        decoder_outputs,decoder_hidden = model(<span class="hljs-built_in">input</span>,target,input_length,target_len)<br>        loss = get_loss(decoder_outputs,target)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>            epoch, idx * <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                   <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item()))<br><br>        torch.save(model.state_dict(), <span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>)<br>        torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;model/seq2seq_optimizer.pkl&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(i)<br></code></pre></td></tr></table></figure>



<h3 id="2-8-完成模型评估逻辑"><a href="#2-8-完成模型评估逻辑" class="headerlink" title="2.8 完成模型评估逻辑"></a>2.8 完成模型评估逻辑</h3><p>完成评估逻辑，和decoder中的训练过程稍微不同，可以在其中新建<code>evaluation</code>的方法，传入<code>encoder_hidden</code>，得到预测的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluation</span>(<span class="hljs-params">self,encoder_hidden</span>): <span class="hljs-comment">#[1, 20, 14]</span><br>    batch_size = encoder_hidden.size(<span class="hljs-number">1</span>) <span class="hljs-comment">#评估的时候和训练的batch_size不同，不适用config的配置</span><br><br>    decoder_input = torch.LongTensor([[num_sequence.SOS] * batch_size])<br>    decoder_outputs = torch.zeros(batch_size,config.max_len, self.vocab_size)  <span class="hljs-comment"># [batch_size，seq_len,vocab_size]</span><br>    decoder_hidden = encoder_hidden<br>		<br>    <span class="hljs-comment">#评估，不再使用teacher forcing，完全使用预测值作为下一次的输入</span><br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>        decoder_output_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)<br>        decoder_outputs[:,t,:] = decoder_output_t<br>        value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>)  <span class="hljs-comment"># index [20,1]</span><br>        decoder_input = index.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment">#获取输出的id</span><br>    decoder_indices = []  <span class="hljs-comment">#[[1,2,4],[23,3,2]]</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>        value,index = torch.topk(decoder_outputs[:,i,:],k=<span class="hljs-number">1</span>,dim=-<span class="hljs-number">1</span>)<br>        decoder_indices.append(index.view(-<span class="hljs-number">1</span>).numpy())<br>    <span class="hljs-comment">#transpose 调整为按句子输出</span><br>    decoder_indices = np.array(decoder_indices).transpose() <br>    <span class="hljs-keyword">return</span> decoder_indices<br></code></pre></td></tr></table></figure>

<p>之后再seq2seq的model中，添加<code>evaluation</code>的逻辑</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,encoder,decoder</span>):<br>        <span class="hljs-built_in">super</span>(Seq2Seq,self).__init__()<br>        self.encoder = encoder<br>        self.decoder = decoder<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>,target,input_length,target_length</span>):<br>        encoder_outputs,encoder_hidden = self.encoder(<span class="hljs-built_in">input</span>,input_length)<br>        decoder_outputs,decoder_hidden = self.decoder(encoder_hidden,target,target_length)<br>        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluation</span>(<span class="hljs-params">self,inputs,input_length</span>):<br>        encoder_outputs,encoder_hidden = self.encoder(inputs,input_length)<br>        decoded_sentence = self.decoder.evaluation(encoder_hidden)<br>        <span class="hljs-keyword">return</span> decoded_sentence<br></code></pre></td></tr></table></figure>

<p>创建<code>eval.py</code>，完成模型评估的逻辑</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> encoder <span class="hljs-keyword">import</span> NumEncoder<br><span class="hljs-keyword">from</span> decoder <span class="hljs-keyword">import</span> NumDecoder<br><span class="hljs-keyword">from</span> seq2seq <span class="hljs-keyword">import</span> Seq2Seq<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> data_loader <span class="hljs-keyword">as</span> train_dataloader<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><br><br><br>encoder = NumEncoder()<br>decoder = NumDecoder()<br>model = Seq2Seq(encoder,decoder)<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evalaute</span>():<br>    data = [<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000</span>, [<span class="hljs-number">10</span>])]<br>    data = <span class="hljs-built_in">sorted</span>(data,key=<span class="hljs-keyword">lambda</span> x:<span class="hljs-built_in">len</span>(x),reverse=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">print</span>(data)<br><br>    _data_length = torch.LongTensor([<span class="hljs-built_in">len</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])<br>    _data = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])<br>    output = seq2seq.evaluate(_data,_data_length)<br>    <span class="hljs-built_in">print</span>([num_sequence.inverse_transform(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> output])<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    evalaute()<br></code></pre></td></tr></table></figure>

<p>在model训练一个epoch之后，loss已经很低了,评估输出如下（为True表示预测正确）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">39304187</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">393041870</span> <span class="hljs-literal">True</span><br><span class="hljs-number">41020882</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">410208820</span> <span class="hljs-literal">True</span><br><span class="hljs-number">85784317</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">857843170</span> <span class="hljs-literal">True</span><br><span class="hljs-number">1394232</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">13942320</span> <span class="hljs-literal">True</span><br><span class="hljs-number">44548446</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">445484460</span> <span class="hljs-literal">True</span><br><span class="hljs-number">49457730</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">494577300</span> <span class="hljs-literal">True</span><br><span class="hljs-number">82451872</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">824518720</span> <span class="hljs-literal">True</span><br><span class="hljs-number">64380958</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">643809580</span> <span class="hljs-literal">True</span><br><span class="hljs-number">97501723</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">975017230</span> <span class="hljs-literal">True</span><br><span class="hljs-number">21656800</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">216568000</span> <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<p>完整代码参考：<a target="_blank" rel="noopener" href="https://github.com/SpringMagnolia/PytorchTutorial/tree/master/seq2seq">https://github.com/SpringMagnolia/PytorchTutorial/tree/master/seq2seq</a></p>
<h1 id="Seq2Seq实现闲聊机器人"><a href="#Seq2Seq实现闲聊机器人" class="headerlink" title="Seq2Seq实现闲聊机器人"></a>Seq2Seq实现闲聊机器人</h1><h2 id="目标-22"><a href="#目标-22" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道如何处理文本数据</li>
<li>知道如何使用seq2seq完成闲聊机器人代码的编写</li>
</ol>
<h2 id="1-准备训练数据"><a href="#1-准备训练数据" class="headerlink" title="1. 准备训练数据"></a>1. 准备训练数据</h2><p><code>单轮次</code>的聊天数据非常不好获取，所以这里我们从github上使用一些开放的数据集来训练我们的闲聊模型</p>
<p>数据地址：<a target="_blank" rel="noopener" href="https://github.com/codemayq/chaotbot_corpus_Chinese">https://github.com/codemayq/chaotbot_corpus_Chinese</a></p>
<p>主要的数据有两个：</p>
<ol>
<li>小黄鸡的聊天语料：噪声很大<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%B0%8F%E9%BB%84%E9%B8%A1%E8%AF%AD%E6%96%99.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li>微博的标题和评论：质量相对较高<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BE%AE%E5%8D%9A%E8%AF%AD%E6%96%991.png" srcset="/img/loading.gif" lazyload></li>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BE%AE%E5%8D%9A%E8%AF%AD%E6%96%992.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
</ol>
<h2 id="2-数据的处理和保存"><a href="#2-数据的处理和保存" class="headerlink" title="2. 数据的处理和保存"></a>2. 数据的处理和保存</h2><p>由于数据中存到大量的噪声，可以对其进行基础的处理，然后分别把input和target使用两个文件保存，即input中的第N行尾问，target的第N行为答</p>
<p>后续可能我们可能会把单个字作为特征（存放在input_word.txt），也可能会把词语作为特征(input.txt)</p>
<h3 id="2-1-小黄鸡的语料的处理"><a href="#2-1-小黄鸡的语料的处理" class="headerlink" title="2.1 小黄鸡的语料的处理"></a>2.1 小黄鸡的语料的处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_xiaohuangji_corpus</span>(<span class="hljs-params">word=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;处理小黄鸡的语料&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> word:<br>        corpus_path = <span class="hljs-string">&quot;./chatbot/corpus/xiaohuangji50w_nofenci.conv&quot;</span><br>        input_path = <span class="hljs-string">&quot;./chatbot/corpus/input_word.txt&quot;</span><br>        output_path = <span class="hljs-string">&quot;./chatbot/corpus/output_word.txt&quot;</span><br>    <span class="hljs-keyword">else</span>:<br><br>        corpus_path = <span class="hljs-string">&quot;./chatbot/corpus/xiaohuangji50w_nofenci.conv&quot;</span><br>        input_path = <span class="hljs-string">&quot;./chatbot/corpus/input.txt&quot;</span><br>        output_path = <span class="hljs-string">&quot;./chatbot/corpus/output.txt&quot;</span><br><br>    f_input = <span class="hljs-built_in">open</span>(input_path,<span class="hljs-string">&quot;a&quot;</span>)<br>    f_output = <span class="hljs-built_in">open</span>(output_path,<span class="hljs-string">&quot;a&quot;</span>)<br>    pair = []<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">open</span>(corpus_path),<span class="hljs-built_in">ascii</span>=<span class="hljs-literal">True</span>):<br>        <span class="hljs-keyword">if</span> line.strip() == <span class="hljs-string">&quot;E&quot;</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> pair:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(pair) == <span class="hljs-number">2</span>,<span class="hljs-string">&quot;长度必须是2&quot;</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pair[<span class="hljs-number">0</span>].strip())&gt;=<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(pair[<span class="hljs-number">1</span>].strip())&gt;=<span class="hljs-number">1</span>:<br>                    f_input.write(pair[<span class="hljs-number">0</span>]+<span class="hljs-string">&quot;\n&quot;</span>)<br>                    f_output.write(pair[<span class="hljs-number">1</span>]+<span class="hljs-string">&quot;\n&quot;</span>)<br>                pair = []<br>        <span class="hljs-keyword">elif</span> line.startswith(<span class="hljs-string">&quot;M&quot;</span>):<br>            line = line[<span class="hljs-number">1</span>:]<br>            <span class="hljs-keyword">if</span> word:<br>                pair.append(<span class="hljs-string">&quot; &quot;</span>.join(<span class="hljs-built_in">list</span>(line.strip())))<br>            <span class="hljs-keyword">else</span>:<br>                pair.append(<span class="hljs-string">&quot; &quot;</span>.join(jieba_cut(line.strip())))<br><br></code></pre></td></tr></table></figure>

<h3 id="2-2-微博语料的处理"><a href="#2-2-微博语料的处理" class="headerlink" title="2.2 微博语料的处理"></a>2.2 微博语料的处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_weibo</span>(<span class="hljs-params">word=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    微博数据存在一些噪声，未处理</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> word:<br>        origin_input = <span class="hljs-string">&quot;./chatbot/corpus/stc_weibo_train_post&quot;</span><br>        input_path = <span class="hljs-string">&quot;./chatbot/corpus/input_word.txt&quot;</span><br><br>        origin_output = <span class="hljs-string">&quot;./chatbot/corpus/stc_weibo_train_response&quot;</span><br>        output_path = <span class="hljs-string">&quot;./chatbot/corpus/output_word.txt&quot;</span><br><br>    <span class="hljs-keyword">else</span>:<br>        origin_input = <span class="hljs-string">&quot;./chatbot/corpus/stc_weibo_train_post&quot;</span><br>        input_path = <span class="hljs-string">&quot;./chatbot/corpus/input.txt&quot;</span><br><br>        origin_output = <span class="hljs-string">&quot;./chatbot/corpus/stc_weibo_train_response&quot;</span><br>        output_path = <span class="hljs-string">&quot;./chatbot/corpus/output.txt&quot;</span><br><br>    f_input = <span class="hljs-built_in">open</span>(input_path,<span class="hljs-string">&quot;a&quot;</span>)<br>    f_output = <span class="hljs-built_in">open</span>(output_path, <span class="hljs-string">&quot;a&quot;</span>)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(origin_input) <span class="hljs-keyword">as</span> in_o,<span class="hljs-built_in">open</span>(origin_output) <span class="hljs-keyword">as</span> out_o:<br>        <span class="hljs-keyword">for</span> _<span class="hljs-keyword">in</span>,_out <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">zip</span>(in_o,out_o),<span class="hljs-built_in">ascii</span>=<span class="hljs-literal">True</span>):<br>            _<span class="hljs-keyword">in</span> = _<span class="hljs-keyword">in</span>.strip()<br>            _out = _out.strip()<br><br>            <span class="hljs-keyword">if</span> _<span class="hljs-keyword">in</span>.endswith(<span class="hljs-string">&quot;）&quot;</span>) <span class="hljs-keyword">or</span> _<span class="hljs-keyword">in</span>.endswith(<span class="hljs-string">&quot;」&quot;</span>) <span class="hljs-keyword">or</span> _<span class="hljs-keyword">in</span>.endswith(<span class="hljs-string">&quot;)&quot;</span>):<br>                _<span class="hljs-keyword">in</span> = re.sub(<span class="hljs-string">&quot;（.*）|「.*?」|\(.*?\)&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,_<span class="hljs-keyword">in</span>)<br>            _<span class="hljs-keyword">in</span> = re.sub(<span class="hljs-string">&quot;我在.*?alink|alink|（.*?\d+x\d+.*?）|#|】|【|-+|_+|via.*?：*.*&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,_<span class="hljs-keyword">in</span>)<br><br>            _<span class="hljs-keyword">in</span> = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot; &quot;</span>,_<span class="hljs-keyword">in</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(_<span class="hljs-keyword">in</span>)&lt;<span class="hljs-number">1</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(_out)&lt;<span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">continue</span><br><br>            <span class="hljs-keyword">if</span> word:<br>                _<span class="hljs-keyword">in</span> = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot;&quot;</span>,_<span class="hljs-keyword">in</span>)  <span class="hljs-comment">#转化为一整行，不含空格</span><br>                _out = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>,<span class="hljs-string">&quot;&quot;</span>,_out)<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(_<span class="hljs-keyword">in</span>)&gt;=<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(_out)&gt;=<span class="hljs-number">1</span>:<br>                    f_input.write(<span class="hljs-string">&quot; &quot;</span>.join(<span class="hljs-built_in">list</span>(_<span class="hljs-keyword">in</span>)) + <span class="hljs-string">&quot;\n&quot;</span>)<br>                    f_output.write(<span class="hljs-string">&quot; &quot;</span>.join(<span class="hljs-built_in">list</span>(_out)) + <span class="hljs-string">&quot;\n&quot;</span>)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(_<span class="hljs-keyword">in</span>) &gt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(_out) &gt;= <span class="hljs-number">1</span>:<br>                    f_input.write(_<span class="hljs-keyword">in</span>.strip()+<span class="hljs-string">&quot;\n&quot;</span>)<br>                    f_output.write(_out.strip()+<span class="hljs-string">&quot;\n&quot;</span>)<br><br>    f_input.close()<br>    f_output.close()<br></code></pre></td></tr></table></figure>

<h3 id="2-3-处理后的结果"><a href="#2-3-处理后的结果" class="headerlink" title="2.3 处理后的结果"></a>2.3 处理后的结果</h3><p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%90%8E.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%90%8E2.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-构造文本序列化和反序列化方法"><a href="#3-构造文本序列化和反序列化方法" class="headerlink" title="3. 构造文本序列化和反序列化方法"></a>3. 构造文本序列化和反序列化方法</h3><p>和之前的操作相同，需要把文本能转化为数字，同时还需实现方法把数字转化为文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># word_sequence.py</span><br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">import</span> pickle<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Word2Sequence</span>():<br>    UNK_TAG = <span class="hljs-string">&quot;UNK&quot;</span><br>    PAD_TAG = <span class="hljs-string">&quot;PAD&quot;</span><br>    SOS_TAG = <span class="hljs-string">&quot;SOS&quot;</span><br>    EOS_TAG = <span class="hljs-string">&quot;EOS&quot;</span><br><br>    UNK = <span class="hljs-number">0</span><br>    PAD = <span class="hljs-number">1</span><br>    SOS = <span class="hljs-number">2</span><br>    EOS = <span class="hljs-number">3</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.<span class="hljs-built_in">dict</span> = &#123;<br>            self.UNK_TAG :self.UNK,<br>            self.PAD_TAG :self.PAD,<br>            self.SOS_TAG :self.SOS,<br>            self.EOS_TAG :self.EOS<br>        &#125;<br>        self.count = &#123;&#125;<br>        self.fited = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_index</span>(<span class="hljs-params">self,word</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;word -&gt; index&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited == <span class="hljs-literal">True</span>,<span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br>        <span class="hljs-keyword">return</span> self.<span class="hljs-built_in">dict</span>.get(word,self.UNK)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_word</span>(<span class="hljs-params">self,index</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;index -&gt; word&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited , <span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br>        <span class="hljs-keyword">if</span> index <span class="hljs-keyword">in</span> self.inversed_dict:<br>            <span class="hljs-keyword">return</span> self.inversed_dict[index]<br>        <span class="hljs-keyword">return</span> self.UNK_TAG<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, sentence</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param sentence:[word1,word2,word3]</span><br><span class="hljs-string">        :param min_count: 最小出现的次数</span><br><span class="hljs-string">        :param max_count: 最大出现的次数</span><br><span class="hljs-string">        :param max_feature: 总词语的最大数量</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> sentence:<br>            <span class="hljs-keyword">if</span> a <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.count:<br>                self.count[a] = <span class="hljs-number">0</span><br>            self.count[a] += <span class="hljs-number">1</span><br><br>        self.fited = <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_vocab</span>(<span class="hljs-params">self, min_count=<span class="hljs-number">1</span>, max_count=<span class="hljs-literal">None</span>, max_feature=<span class="hljs-literal">None</span></span>):<br><br>        <span class="hljs-comment"># 比最小的数量大和比最大的数量小的需要</span><br>        <span class="hljs-keyword">if</span> min_count <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.count = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.count.items() <span class="hljs-keyword">if</span> v &gt;= min_count&#125;<br>        <span class="hljs-keyword">if</span> max_count <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.count = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.count.items() <span class="hljs-keyword">if</span> v &lt;= max_count&#125;<br><br>        <span class="hljs-comment"># 限制最大的数量</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(max_feature, <span class="hljs-built_in">int</span>):<br>            count = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(self.count.items()), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">if</span> max_feature <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(count) &gt; max_feature:<br>                count = count[-<span class="hljs-built_in">int</span>(max_feature):]<br>            <span class="hljs-keyword">for</span> w, _ <span class="hljs-keyword">in</span> count:<br>                self.<span class="hljs-built_in">dict</span>[w] = <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(self.count.keys()):<br>                self.<span class="hljs-built_in">dict</span>[w] = <span class="hljs-built_in">len</span>(self.<span class="hljs-built_in">dict</span>)<br><br>        <span class="hljs-comment"># 准备一个index-&gt;word的字典</span><br>        self.inversed_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.<span class="hljs-built_in">dict</span>.values(), self.<span class="hljs-built_in">dict</span>.keys()))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self, sentence,max_len=<span class="hljs-literal">None</span>,add_eos=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        实现吧句子转化为数组（向量）</span><br><span class="hljs-string">        :param sentence:</span><br><span class="hljs-string">        :param max_len:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited, <span class="hljs-string">&quot;必须先进行fit操作&quot;</span><br><br>        r = [self.to_index(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sentence]<br>        <span class="hljs-keyword">if</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">if</span> max_len&gt;<span class="hljs-built_in">len</span>(sentence):<br>                <span class="hljs-keyword">if</span> add_eos:<br>                    r+=[self.EOS]+[self.PAD <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_len-<span class="hljs-built_in">len</span>(sentence)-<span class="hljs-number">1</span>)]<br>                <span class="hljs-keyword">else</span>:<br>                    r += [self.PAD <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_len - <span class="hljs-built_in">len</span>(sentence))]<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> add_eos:<br>                    r = r[:max_len-<span class="hljs-number">1</span>]<br>                    r += [self.EOS]<br>                <span class="hljs-keyword">else</span>:<br>                    r = r[:max_len]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> add_eos:<br>                r += [self.EOS]<br>        <span class="hljs-comment"># print(len(r),r)</span><br>        <span class="hljs-keyword">return</span> r<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inverse_transform</span>(<span class="hljs-params">self,indices</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        实现从数组 转化为 向量</span><br><span class="hljs-string">        :param indices: [1,2,3....]</span><br><span class="hljs-string">        :return:[word1,word2.....]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        sentence = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> indices:<br>            word = self.to_word(i)<br>            sentence.append(word)<br>        <span class="hljs-keyword">return</span> sentence<br><br><span class="hljs-comment">#之后导入该word_sequence使用</span><br>word_sequence = pickle.load(<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./pkl/ws.pkl&quot;</span>,<span class="hljs-string">&quot;rb&quot;</span>)) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> config.use_word <span class="hljs-keyword">else</span> pickle.load(<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./pkl/ws_word.pkl&quot;</span>,<span class="hljs-string">&quot;rb&quot;</span>))<br><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> Word2Sequence<br>    <span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br>    <span class="hljs-keyword">import</span> pickle<br><br>    word_sequence = Word2Sequence()<br>    <span class="hljs-comment">#词语级别</span><br>    input_path = <span class="hljs-string">&quot;../corpus/input.txt&quot;</span><br>    target_path = <span class="hljs-string">&quot;../corpus/output.txt&quot;</span><br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">open</span>(input_path).readlines()):<br>        word_sequence.fit(line.strip().split())<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">open</span>(target_path).readlines()):<br>        word_sequence.fit(line.strip().split())<br>	<br>    <span class="hljs-comment">#使用max_feature=5000个数据</span><br>    word_sequence.build_vocab(min_count=<span class="hljs-number">5</span>,max_count=<span class="hljs-literal">None</span>,max_feature=<span class="hljs-number">5000</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(word_sequence))<br>    pickle.dump(word_sequence,<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./pkl/ws.pkl&quot;</span>,<span class="hljs-string">&quot;wb&quot;</span>))<br></code></pre></td></tr></table></figure>



<h3 id="4-构建Dataset和DataLoader"><a href="#4-构建Dataset和DataLoader" class="headerlink" title="4. 构建Dataset和DataLoader"></a>4. 构建Dataset和DataLoader</h3><p>创建<code>dataset.py</code>	文件，准备数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> word_sequence<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(ChatDataset,self).__init__()<br><br>        input_path = <span class="hljs-string">&quot;../corpus/input.txt&quot;</span><br>        target_path = <span class="hljs-string">&quot;../corpus/output.txt&quot;</span><br>        <span class="hljs-keyword">if</span> config.use_word:<br>            input_path = <span class="hljs-string">&quot;../corpus/input_word.txt&quot;</span><br>            target_path = <span class="hljs-string">&quot;../corpus/output_word.txt&quot;</span><br><br>        self.input_lines = <span class="hljs-built_in">open</span>(input_path).readlines()<br>        self.target_lines = <span class="hljs-built_in">open</span>(target_path).readlines()<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(self.input_lines) == <span class="hljs-built_in">len</span>(self.target_lines) ,<span class="hljs-string">&quot;input和target文本的数量必须相同&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-built_in">input</span> = self.input_lines[index].strip().split()<br>        target = self.target_lines[index].strip().split()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(target)==<span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">input</span> = self.input_lines[index+<span class="hljs-number">1</span>].strip().split()<br>            target = self.target_lines[index+<span class="hljs-number">1</span>].strip().split()<br>        <span class="hljs-comment">#此处句子的长度如果大于max_len，那么应该返回max_len</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>,target,<span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>),config.max_len),<span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(target),config.max_len)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.input_lines)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):<br>    <span class="hljs-comment">#1.排序</span><br>    batch = <span class="hljs-built_in">sorted</span>(batch,key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">2</span>],reverse=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">input</span>, target, input_length, target_length = <span class="hljs-built_in">zip</span>(*batch)<br><br>    <span class="hljs-comment"># 2.进行padding的操作</span><br>    <span class="hljs-built_in">input</span> = torch.LongTensor([word_sequence.transform(i, max_len=config.max_len) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>])<br>    target = torch.LongTensor([word_sequence.transform(i, max_len=config.max_len, add_eos=<span class="hljs-literal">True</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> target])<br>    input_length = torch.LongTensor(input_length)<br>    target_length = torch.LongTensor(target_length)<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>, target, input_length, target_length<br><br>data_loader = DataLoader(dataset=ChatDataset(),batch_size=config.batch_size,shuffle=<span class="hljs-literal">True</span>,collate_fn=collate_fn,drop_last=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> idx, (<span class="hljs-built_in">input</span>, target, input_lenght, target_length) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data_loader):<br>        <span class="hljs-built_in">print</span>(idx)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-built_in">print</span>(target)<br>        <span class="hljs-built_in">print</span>(input_lenght)<br>        <span class="hljs-built_in">print</span>(target_length)<br></code></pre></td></tr></table></figure>



<h2 id="5-完成encoder编码器逻辑"><a href="#5-完成encoder编码器逻辑" class="headerlink" title="5. 完成encoder编码器逻辑"></a>5. 完成<code>encoder</code>编码器逻辑</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> word_sequence<br><span class="hljs-keyword">import</span> config<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Encoder,self).__init__()<br>        self.vocab_size = <span class="hljs-built_in">len</span>(word_sequence)<br>        self.dropout = config.dropout<br>        self.embedding_dim = config.embedding_dim<br>        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=self.embedding_dim,padding_idx=word_sequence.PAD)<br>        self.gru = nn.GRU(input_size=self.embedding_dim,<br>                          hidden_size=config.hidden_size,<br>                          num_layers=<span class="hljs-number">1</span>,<br>                          batch_first=<span class="hljs-literal">True</span>,<br>                          dropout=config.dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>,input_length</span>):<br>        embeded = self.embedding(<span class="hljs-built_in">input</span>)<br>        embeded = nn.utils.rnn.pack_padded_sequence(embeded,lengths=input_length,batch_first=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment">#hidden:[1,batch_size,vocab_size]</span><br>        out,hidden = self.gru(embeded)<br>        out,outputs_length = nn.utils.rnn.pad_packed_sequence(out,batch_first=<span class="hljs-literal">True</span>,padding_value=word_sequence.PAD)<br>        <span class="hljs-comment">#hidden [1,batch_size,hidden_size]</span><br>        <span class="hljs-keyword">return</span> out,hidden<br></code></pre></td></tr></table></figure>

<h2 id="6-完成decoder解码器的逻辑"><a href="#6-完成decoder解码器的逻辑" class="headerlink" title="6. 完成decoder解码器的逻辑"></a>6. 完成<code>decoder</code>解码器的逻辑</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> word_sequence<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Decoder,self).__init__()<br>        self.max_seq_len = config.max_len<br>        self.vocab_size = <span class="hljs-built_in">len</span>(word_sequence)<br>        self.embedding_dim = config.embedding_dim<br>        self.dropout = config.dropout<br><br>        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=self.embedding_dim,padding_idx=word_sequence.PAD)<br>        self.gru = nn.GRU(input_size=self.embedding_dim,<br>                          hidden_size=config.hidden_size,<br>                          num_layers=<span class="hljs-number">1</span>,<br>                          batch_first=<span class="hljs-literal">True</span>,<br>                          dropout=self.dropout)<br>        self.log_softmax = nn.LogSoftmax()<br><br>        self.fc = nn.Linear(config.hidden_size,self.vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_hidden,target,target_length</span>):<br>        <span class="hljs-comment"># encoder_hidden [batch_size,hidden_size]</span><br>        <span class="hljs-comment"># target [batch_size,seq-len]</span><br><br>        decoder_input = torch.LongTensor([[word_sequence.SOS]]*config.batch_size).to(config.device)<br>        decoder_outputs = torch.zeros(config.batch_size,config.max_len,self.vocab_size).to(config.device) <span class="hljs-comment">#[batch_size,seq_len,14]</span><br><br>        decoder_hidden = encoder_hidden <span class="hljs-comment">#[batch_size,hidden_size]</span><br><br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>            decoder_output_t , decoder_hidden = self.forward_step(decoder_input,decoder_hidden)<br>            decoder_outputs[:,t,:] = decoder_output_t<br>            value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>) <span class="hljs-comment"># index [batch_size,1]</span><br>            decoder_input = index<br>        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self,decoder_input,decoder_hidden</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param decoder_input:[batch_size,1]</span><br><span class="hljs-string">        :param decoder_hidden: [1,batch_size,hidden_size]</span><br><span class="hljs-string">        :return: out:[batch_size,vocab_size],decoder_hidden:[1,batch_size,didden_size]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        embeded = self.embedding(decoder_input)  <span class="hljs-comment">#embeded: [batch_size,1 , embedding_dim]</span><br>        out,decoder_hidden = self.gru(embeded,decoder_hidden) <span class="hljs-comment">#out [1, batch_size, hidden_size]</span><br>        out = out.squeeze(<span class="hljs-number">0</span>)<br>        out = F.log_softmax(self.fc(out),dim=-<span class="hljs-number">1</span>)<span class="hljs-comment">#[batch_Size, vocab_size]</span><br>        out = out.squeeze(<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># print(&quot;out size:&quot;,out.size(),decoder_hidden.size())</span><br>        <span class="hljs-keyword">return</span> out,decoder_hidden<br></code></pre></td></tr></table></figure>

<h2 id="7-完成seq2seq的模型"><a href="#7-完成seq2seq的模型" class="headerlink" title="7.完成seq2seq的模型"></a>7.完成seq2seq的模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2Seq</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,encoder,decoder</span>):<br>        <span class="hljs-built_in">super</span>(Seq2Seq,self).__init__()<br>        self.encoder = encoder<br>        self.decoder = decoder<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>,target,input_length,target_length</span>):<br>        encoder_outputs,encoder_hidden = self.encoder(<span class="hljs-built_in">input</span>,input_length)<br>        decoder_outputs,decoder_hidden = self.decoder(encoder_hidden,target,target_length)<br>        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluation</span>(<span class="hljs-params">self,inputs,input_length</span>):<br>        encoder_outputs,encoder_hidden = self.encoder(inputs,input_length)<br>        decoded_sentence = self.decoder.evaluation(encoder_hidden)<br>        <span class="hljs-keyword">return</span> decoded_sentence<br></code></pre></td></tr></table></figure>

<h2 id="8-完成训练逻辑"><a href="#8-完成训练逻辑" class="headerlink" title="8. 完成训练逻辑"></a>8. 完成训练逻辑</h2><p>为了加速训练，可以考虑在gpu上运行，那么在我们自顶一个所以的tensor和model都需要转化为CUDA支持的类型。</p>
<p>当前的数据量为500多万条，在GTX1070（8G显存）上训练，大概需要90分一个epoch，耐心的等待吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> encoder <span class="hljs-keyword">import</span> Encoder<br><span class="hljs-keyword">from</span> decoder <span class="hljs-keyword">import</span> Decoder<br><span class="hljs-keyword">from</span> seq2seq <span class="hljs-keyword">import</span> Seq2Seq<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> data_loader <span class="hljs-keyword">as</span> train_dataloader<br><span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> word_sequence<br><br>encoder = Encoder()<br>decoder = Decoder()<br>model = Seq2Seq(encoder,decoder)<br><br><span class="hljs-comment">#device在config文件中实现</span><br>model.to(config.device)<br><br><span class="hljs-built_in">print</span>(model)<br><br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>))<br>optimizer =  optim.Adam(model.parameters())<br>optimizer.load_state_dict(torch.load(<span class="hljs-string">&quot;model/seq2seq_optimizer.pkl&quot;</span>))<br>criterion= nn.NLLLoss(ignore_index=word_sequence.PAD,reduction=<span class="hljs-string">&quot;mean&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_loss</span>(<span class="hljs-params">decoder_outputs,target</span>):<br>    target = target.view(-<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size*max_len]</span><br>    decoder_outputs = decoder_outputs.view(config.batch_size*config.max_len,-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> criterion(decoder_outputs,target)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    <span class="hljs-keyword">for</span> idx,(<span class="hljs-built_in">input</span>,target,input_length,target_len) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        <span class="hljs-built_in">input</span> = <span class="hljs-built_in">input</span>.to(config.device)<br>        target = target.to(config.device)<br>        input_length = input_length.to(config.device)<br>        target_len = target_len.to(config.device)<br><br>        optimizer.zero_grad()<br>        <span class="hljs-comment">##[seq_len,batch_size,vocab_size] [batch_size,seq_len]</span><br>        decoder_outputs,decoder_hidden = model(<span class="hljs-built_in">input</span>,target,input_length,target_len)<br>        loss = get_loss(decoder_outputs,target)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>            epoch, idx * <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>), <span class="hljs-built_in">len</span>(train_dataloader.dataset),<br>                   <span class="hljs-number">100.</span> * idx / <span class="hljs-built_in">len</span>(train_dataloader), loss.item()))<br><br>        torch.save(model.state_dict(), <span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>)<br>        torch.save(optimizer.state_dict(), <span class="hljs-string">&#x27;model/seq2seq_optimizer.pkl&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(i)<br></code></pre></td></tr></table></figure>

<p>训练10个epoch之后的效果如下,可以看出损失依然很高：</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs dns">Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2444544</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.923604</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2444800</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.364594</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2445056</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.613254</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2445312</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.143538</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2445568</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.412729</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2445824</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.516526</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2446080</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.124945</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2446336</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.777015</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2446592</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.358538</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2446848</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.513412</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2447104</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.202757</span><br>Train Epoch: <span class="hljs-number">9</span> [<span class="hljs-number">2447360</span>/<span class="hljs-number">4889919</span> (<span class="hljs-number">50</span>%)]	Loss: <span class="hljs-number">4.589584</span><br></code></pre></td></tr></table></figure>



<h2 id="9-小结"><a href="#9-小结" class="headerlink" title="9.小结"></a>9.小结</h2><p>效果不好</p>
<h1 id="Attention的原理和实现"><a href="#Attention的原理和实现" class="headerlink" title="Attention的原理和实现"></a>Attention的原理和实现</h1><h2 id="目标-23"><a href="#目标-23" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道Attention的作用</li>
<li>知道Attention的实现机制</li>
<li>能够使用代码完成Attention代码的编写</li>
</ol>
<h2 id="1-Attention的介绍"><a href="#1-Attention的介绍" class="headerlink" title="1. Attention的介绍"></a>1. Attention的介绍</h2><p>在普通的RNN结构中，Encoder需要把一个句子转化为一个向量，然后在Decoder中使用，这就要求Encoder把源句子中所有的信息都包含进去，但是当句子长度过长的时候，这个要求就很难达到，或者说会产生瓶颈（比如，输入一篇文章等场长内容），当然我们可以使用更深的RNN和大多的单元来解决这个问题，但是这样的代价也很大。那么有没有什么方法能够优化现有的RNN结构呢？</p>
<p>为此，Bahdanau等人在2015年提出了<code>Attenion</code>机制，<code>Attention</code>翻译成为中文叫做注意力，把这种模型称为<code>Attention based model</code>。就像我们自己看到一副画，我们能够很快的说出画的主要内容，而忽略画中的背景，因为我们注意的，更关注的往往是其中的主要内容。</p>
<p>通过这种方式，在我们的RNN中，我们有通过LSTM或者是GRU得到的所有信息，那么这些信息中只去关注重点，而不需要在Decoder的每个time step使用全部的encoder的信息，这样就可以解决第一段所说的问题了</p>
<p>那么现在要讲的<code>Attention机制</code>就能够帮助我们解决这个问题</p>
<h2 id="2-Attenion的实现机制"><a href="#2-Attenion的实现机制" class="headerlink" title="2. Attenion的实现机制"></a>2. Attenion的实现机制</h2><p>假设我们现在有一个文本翻译的需求，即<code>机器学习</code>翻译为<code>machine learning</code>。那么这个过程通过前面所学习的Seq2Seq就可以实现</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention1.png" srcset="/img/loading.gif" lazyload></p>
<p>上图的左边是Encoder，能够得到<code>hidden_state</code>在右边使用</p>
<p>Deocder中<strong>蓝色方框</strong>中的内容，是为了提高模型的训练速度而使用teacher forcing手段，否则的话会把前一次的输出作为下一次的输入（<strong>但是在Attention模型中不再是这样了</strong>）</p>
<p>那么整个过程中如果使用Attention应该怎么做呢？</p>
<p>在之前我们把encoder的最后一个输出，作为decoder的初始的隐藏状态，现在我们不再这样做</p>
<h3 id="2-1-Attention的实现过程"><a href="#2-1-Attention的实现过程" class="headerlink" title="2.1 Attention的实现过程"></a>2.1 Attention的实现过程</h3><ol>
<li><p>初始化一个Decoder的隐藏状态$z_0$</p>
</li>
<li><p>这个$z_o$会和encoder第一个time step的output进行match操作（或者是socre操作），得到$\alpha_0^1$ ，这里的match可以使很多中操作，比如：</p>
<ul>
<li>z和h的余弦值</li>
<li>是一个神经网络，输入为z和h</li>
<li>或者$\alpha &#x3D; h^T W z$等</li>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention2.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li><p>encoder中的每个output都和$z_0$进行计算之后，得到的结果进行softmax，让他们的和为1(可以理解为权重)</p>
</li>
<li><p>之后把所有的softmax之后的结果和原来encoder的输出$h_i$进行相加求和得到$c^0$<br>$$<br>即： c^0 &#x3D; \sum\hat{\alpha}_0^ih^i<br>$$</p>
<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention3.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li><p>得到$c^0$之后，把它作为decoder的input，同和传入初始化的$z^0$，得到第一个time step的输出和hidden_state（$Z^1$）</p>
<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention4.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li><p>把$Z_1$再和所有的encoder的output进行match操作，得到的结果进行softmax之后作为权重和encoder的每个timestep的结果相乘求和得到$c^1$</p>
</li>
<li><p>再把$c^1$作为decoder的input，和$Z^1$作为输入得到下一个输出，如此循环,只到最终decoder的output为终止符</p>
<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Attention5.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li><p>上述参考：<a target="_blank" rel="noopener" href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html">http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html</a></p>
</li>
<li><p>整个过程写成数学公式如下：<br>$$<br>\begin{align*}<br>\alpha_{ij} &amp;&#x3D; \frac{exp(score(h_i,\overline{h}_j))}{\sum exp(score(h_n,\overline{h}<em>m))} &amp; [attention \quad weight]\<br>c_i &amp;&#x3D;\sum \alpha</em>{ij}\overline{h}_s  &amp; [context\quad vector] \<br>\alpha_i &amp;&#x3D; f(c_i,h_i) &#x3D; tanh(W_c[c_i;h_i]) &amp;[attenton \quad result]<br>\end{align*}<br>$$</p>
<ol>
<li>先计算attention权重</li>
<li>在计算上下文向量，图中的$c^i$</li>
<li>最后计算结果，往往会把当前的output([batch_size,1,hidden_size])和上下文向量进行拼接然后使用</li>
</ol>
</li>
</ol>
<h3 id="2-2-不同Attention的介绍"><a href="#2-2-不同Attention的介绍" class="headerlink" title="2.2 不同Attention的介绍"></a>2.2 不同Attention的介绍</h3><p>在上述过程中，使用decoder的状态和encoder的状态的计算后的结果作为权重，乘上encoder每个时间步的输出，这需要我们去训练一个合适的match函数，得到的结果就能够在不同的时间步上使用不同的encoder的相关信息，从而达到只关注某一个局部的效果，也就是注意力的效果</p>
<h3 id="2-2-1-Soft-Attention-和-Hard-Attention"><a href="#2-2-1-Soft-Attention-和-Hard-Attention" class="headerlink" title="2.2.1 Soft-Attention 和 Hard-Attention"></a>2.2.1 <code>Soft-Attention 和 Hard-Attention</code></h3><p>最开始<code>Bahdanau</code>等人提出的Attention机制通常被称为<code>soft-attention</code>,所谓的<code>soft-attention</code>指的是encoder中输入的每个词语都会计算得到一个注意力的概率。</p>
<p>在进行图像捕捉的时候，提出了一种<code>hard-attenion</code>的方法，希望直接从input中找到一个和输出的某个词对应的那一个词。但是由于NLP中词语和词语之间往往存在联系，不会只关注某一个词语，所以都会使用soft-attention，所以这里的就不多介绍hard-attention</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/soft-hard%20attention.jpg" srcset="/img/loading.gif" lazyload></p>
<h3 id="2-2-3-Global-Attention-和Local-Attention"><a href="#2-2-3-Global-Attention-和Local-Attention" class="headerlink" title="2.2.3 Global-Attention 和Local Attention"></a>2.2.3 <code>Global-Attention 和Local Attention</code></h3><p><code>Bahdanau</code>等人提出的<code>Bahdanau Attention</code> 被称为<code>local attention</code>,后来<code>Luong</code>等人提出的<code>Luong Attention</code>是一种全局的attenion。</p>
<p>所谓全局的attenion指的是：使用的全部的encoder端的输入的attenion的权重</p>
<p><code>local-attenion</code>就是使用了部分的encoder端的输入的权重(当前时间步上的encoder的hidden state)，这样可以减少计算量，特别是当句子的长度比较长的时候。</p>
<h3 id="2-2-4-Bahdanau-Attention和-Luong-Attenion的区别"><a href="#2-2-4-Bahdanau-Attention和-Luong-Attenion的区别" class="headerlink" title="2.2.4  Bahdanau Attention和 Luong Attenion的区别"></a>2.2.4  <code>Bahdanau Attention和 Luong Attenion</code>的区别</h3><p>区别在于两个地方：</p>
<ol>
<li><p>attention的计算数据和位置</p>
<ol>
<li><code>Bahdanau Attention</code>会使用<code>前一次的隐藏</code>状态来计算attention weight，所以我们会在代码中的GRU之前使用attention的操作，同时会把attention的结果和word embedding的结果进行concat，作为GRU的输出(参考的是pytorch Toritul)。Bahdanau使用的是双向的GRU，会使用正反的encoder的output的concat的结果作为encoder output,如下图所示<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Bahdanau.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
<li><code>Luong Attenion</code>使用的是<code>当前一次的decoder的output</code>来计算得到attention weight，所以在代码中会在GRU的后面进行attention的操作，同时会把<code>context vector</code>和gru的结果进行concat的操作，最终的output。Luong使用的是多层GRU，只会使用最后一层的输出(encoder output)<ul>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Luong.png" srcset="/img/loading.gif" lazyload></li>
</ul>
</li>
</ol>
</li>
<li><p>计算attention weights的方法不同</p>
<ol>
<li><p><code>Bahdanau Attention</code>的match函数，$a_i^j &#x3D; v^T_a tanh (W_aZ_{i-1},+U_ah_j)$，计算出所有的$a_i^j$之后，在计算softmax，得到$\hat{a}_i^j$，即$\hat{a}_i^j &#x3D; \frac{exp(a_i^j)}{\sum exp(a_i^j)}$</p>
<p>其中</p>
<ol>
<li>$v_a^T是一个参数矩阵，需要被训练，W_a是实现对Z_{i-1}的形状变化$，</li>
<li>$U_a实现对h_j的形状变化（矩阵乘法，理解为线性回归，实现数据形状的对齐）$，</li>
<li>$Z_{i-1}是decoder端前一次的隐藏状态，h_j是encoder的output$</li>
</ol>
</li>
<li><p><code>Luong Attenion</code>整体比<code>Bahdanau Attention</code>更加简单，他使用了三种方法来计算得到权重</p>
<ol>
<li>矩阵乘法：general<ul>
<li>直接对decoder的隐藏状态进行一个矩阵变换（线性回归），然后和encoder outputs进行矩阵乘法</li>
</ul>
</li>
<li>dot<ul>
<li>直接对decoder的隐藏状态和encoder outputs进行矩阵乘法</li>
</ul>
</li>
<li>concat<ul>
<li>把decoder的隐藏状态和encoder的output进行concat，把这个结果使用tanh进行处理后的结果进行对齐计算之后，和encoder outputs进行矩阵乘法</li>
</ul>
</li>
<li><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/scores.png" srcset="/img/loading.gif" lazyload><ul>
<li>$h_t\text{是当前的decoder hidden state,}h_s\text{是所有的encoder 的hidden state(encoder outputs)}$</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>最终两个attention的结果区别并不太大，所以以后我们可以考虑使用Luong attention完成代码</p>
<h2 id="3-Attention的代码实现"><a href="#3-Attention的代码实现" class="headerlink" title="3. Attention的代码实现"></a>3. Attention的代码实现</h2><p>完成代码之前，我们需要确定我们的思路，通过attention的代码，需要实现计算的是attention weight</p>
<p>通过前面的学习，我们知道<code>attention_weight = f(hidden,encoder_outputs)</code>，主要就是实现Luong attention中的三种操作</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/attention6.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,method,batch_size,hidden_size</span>):<br>        <span class="hljs-built_in">super</span>(Attention,self).__init__()<br>        self.method = method<br>        self.hidden_size = hidden_size<br><br>        <span class="hljs-keyword">assert</span> self.method <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;dot&quot;</span>,<span class="hljs-string">&quot;general&quot;</span>,<span class="hljs-string">&quot;concat&quot;</span>],<span class="hljs-string">&quot;method 只能是 dot,general,concat,当前是&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(self.method)<br><br>        <span class="hljs-keyword">if</span> self.method == <span class="hljs-string">&quot;dot&quot;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> self.method == <span class="hljs-string">&quot;general&quot;</span>:<br>            self.Wa = nn.Linear(hidden_size,hidden_size,bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> self.method == <span class="hljs-string">&quot;concat&quot;</span>:<br>            self.Wa = nn.Linear(hidden_size*<span class="hljs-number">2</span>,hidden_size,bias=<span class="hljs-literal">False</span>)<br>            self.Va = nn.Parameter(torch.FloatTensor(batch_size,hidden_size))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden,encoder_outputs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param hidden:[1,batch_size,hidden_size]</span><br><span class="hljs-string">        :param encoder_outputs: [batch_size,seq_len,hidden_size]</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        batch_size,seq_len,hidden_size = encoder_outputs.size()<br><br>        hidden = hidden.squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment">#[batch_size,hidden_size]</span><br><br>        <span class="hljs-keyword">if</span> self.method == <span class="hljs-string">&quot;dot&quot;</span>:<br>            <span class="hljs-keyword">return</span> self.dot_score(hidden,encoder_outputs)<br>        <span class="hljs-keyword">elif</span> self.method == <span class="hljs-string">&quot;general&quot;</span>:<br>            <span class="hljs-keyword">return</span> self.general_score(hidden,encoder_outputs)<br>        <span class="hljs-keyword">elif</span> self.method == <span class="hljs-string">&quot;concat&quot;</span>:<br>            <span class="hljs-keyword">return</span> self.concat_score(hidden,encoder_outputs)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_score</span>(<span class="hljs-params">self,batch_size,seq_len,hidden,encoder_outputs</span>):<br>        <span class="hljs-comment"># 速度太慢</span><br>        <span class="hljs-comment"># [batch_size,seql_len]</span><br>        attn_energies = torch.zeros(batch_size,seq_len).to(config.device)<br>        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(seq_len):<br>                <span class="hljs-comment">#encoder_output : [batch_size,seq_len,hidden_size]</span><br>                <span class="hljs-comment">#deocder_hidden :[batch_size,hidden_size]</span><br>                <span class="hljs-comment">#torch.Size([256, 128]) torch.Size([128]) torch.Size([256, 24, 128]) torch.Size([128])</span><br>                <span class="hljs-comment"># print(&quot;attn size:&quot;,hidden.size(),hidden[b,:].size(),encoder_output.size(),encoder_output[b,i].size())</span><br>                    attn_energies[b,i] = hidden[b,:].dot(encoder_outputs[b,i]) <span class="hljs-comment">#dot score</span><br>        <span class="hljs-keyword">return</span> F.softmax(attn_energies).unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size,1,seq_len]</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dot_score</span>(<span class="hljs-params">self,hidden,encoder_outputs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        dot attention</span><br><span class="hljs-string">        :param hidden:[batch_size,hidden_size] ---&gt;[batch_size,hidden_size,1]</span><br><span class="hljs-string">        :param encoder_outputs: [batch_size,seq_len,hidden_size]</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">#hiiden :[hidden_size] --&gt;[hidden_size,1] ，encoder_output:[seq_len,hidden_size]</span><br>        <br>        <br>        hidden = hidden.unsqueeze(-<span class="hljs-number">1</span>)<br>        attn_energies = torch.bmm(encoder_outputs, hidden)<br>        attn_energies = attn_energies.squeeze(-<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size,seq_len,1] ==&gt;[batch_size,seq_len]</span><br><br>        <span class="hljs-keyword">return</span> F.softmax(attn_energies).unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size,1,seq_len]</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">general_score</span>(<span class="hljs-params">self,hidden,encoder_outputs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        general attenion</span><br><span class="hljs-string">        :param batch_size:int</span><br><span class="hljs-string">        :param hidden: [batch_size,hidden_size]</span><br><span class="hljs-string">        :param encoder_outputs: [batch_size,seq_len,hidden_size]</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        x = self.Wa(hidden) <span class="hljs-comment">#[batch_size,hidden_size]</span><br>        x = x.unsqueeze(-<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size,hidden_size,1]</span><br>        attn_energies = torch.bmm(encoder_outputs,x).squeeze(-<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size,seq_len,1]</span><br>        <span class="hljs-keyword">return</span> F.softmax(attn_energies,dim=-<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">1</span>)      <span class="hljs-comment"># [batch_size,1,seq_len]</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">concat_score</span>(<span class="hljs-params">self,hidden,encoder_outputs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        concat attention</span><br><span class="hljs-string">        :param batch_size:int</span><br><span class="hljs-string">        :param hidden: [batch_size,hidden_size]</span><br><span class="hljs-string">        :param encoder_outputs: [batch_size,seq_len,hidden_size]</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">#需要先进行repeat操作，变成和encoder_outputs相同的形状,让每个batch有seq_len个hidden_size</span><br>        x = hidden.repeat(<span class="hljs-number">1</span>,encoder_outputs.size(<span class="hljs-number">1</span>),<span class="hljs-number">1</span>) <span class="hljs-comment">##[batch_size,seq_len,hidden_size]</span><br>        x = torch.tanh(self.Wa(torch.cat([x,encoder_outputs],dim=-<span class="hljs-number">1</span>))) <span class="hljs-comment">#[batch_size,seq_len,hidden_size*2] --&gt; [batch_size,seq_len,hidden_size]</span><br>        <span class="hljs-comment">#va [batch_size,hidden_size] ---&gt; [batch_size,hidden_size,1]</span><br>        attn_energis = torch.bmm(x,self.Va.unsqueeze(<span class="hljs-number">2</span>))  <span class="hljs-comment">#[batch_size,seq_len,1]</span><br>        attn_energis = attn_energis.squeeze(-<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># print(&quot;concat attention:&quot;,attn_energis.size(),encoder_outputs.size())</span><br>        <span class="hljs-keyword">return</span> F.softmax(attn_energis,dim=-<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size,1,seq_len]</span><br></code></pre></td></tr></table></figure>



<p>完成了<code>attention weight</code>的计算之后，需要再对代码中<code>forward_step</code>的内容进行修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self,decoder_input,decoder_hidden,encoder_outputs</span>):<br>       <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       :param decoder_input:[batch_size,1]</span><br><span class="hljs-string">       :param decoder_hidden: [1,batch_size,hidden_size]</span><br><span class="hljs-string">       :param encoder_outputs: encoder中所有的输出，[batch_size,seq_len,hidden_size]</span><br><span class="hljs-string">       :return: out:[batch_size,vocab_size],decoder_hidden:[1,batch_size,didden_size]</span><br><span class="hljs-string">       &quot;&quot;&quot;</span><br>       embeded = self.embedding(decoder_input)  <span class="hljs-comment">#embeded: [batch_size,1 , embedding_dim]</span><br>       <br>       <span class="hljs-comment">#TODO 可以把embeded的结果和前一次的context（初始值为全0tensor） concate之后作为结果</span><br>       <span class="hljs-comment">#rnn_input = torch.cat((embeded, last_context.unsqueeze(0)), 2)</span><br>       <br>       <span class="hljs-comment"># gru_out:[256,1, 128]  decoder_hidden: [1, batch_size, hidden_size]</span><br>       gru_out,decoder_hidden = self.gru(embeded,decoder_hidden)<br>       gru_out = gru_out.squeeze(<span class="hljs-number">1</span>)<br>       <br>       <span class="hljs-comment">#TODO 注意：如果是单层，这里使用decoder_hidden没问题（output和hidden相同）</span><br>       <span class="hljs-comment"># 如果是多层，可以使用GRU的output作为attention的输入</span><br>       <span class="hljs-comment">#开始使用attention</span><br>       attn_weights = self.attn(decoder_hidden,encoder_outputs)<br>       <span class="hljs-comment"># attn_weights [batch_size,1,seq_len] * [batch_size,seq_len,hidden_size]</span><br>       context = attn_weights.bmm(encoder_outputs) <span class="hljs-comment">#[batch_size,1,hidden_size]</span><br><br>       gru_out = gru_out.squeeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># [batch_size,hidden_size]</span><br>       context = context.squeeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size,hidden_size]</span><br>       <span class="hljs-comment">#把output和attention的结果合并到一起</span><br>       concat_input = torch.cat((gru_out, context), <span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_size,hidden_size*2]</span><br>       <br>       concat_output = torch.tanh(self.concat(concat_input)) <span class="hljs-comment">#[batch_size,hidden_size]</span><br><br>       output = F.log_softmax(self.fc(concat_output),dim=-<span class="hljs-number">1</span>) <span class="hljs-comment">#[batch_Size, vocab_size]</span><br>       <span class="hljs-comment"># out = out.squeeze(1)</span><br>       <span class="hljs-keyword">return</span> output,decoder_hidden,attn_weights<br></code></pre></td></tr></table></figure>



<p>attetnion的Bahdanau实现可以参考：<a target="_blank" rel="noopener" href="https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb">https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb</a></p>
<h1 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h1><h2 id="目标-24"><a href="#目标-24" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道beam search的概念和原理</li>
<li>能够在代码中使用Beam search 完成预测过程</li>
</ol>
<h2 id="1-Beam-Search的介绍"><a href="#1-Beam-Search的介绍" class="headerlink" title="1. Beam Search的介绍"></a>1. Beam Search的介绍</h2><blockquote>
<p>在进行模型评估的过程中，每次我们选择概率最大的token id作为输出，那么整个输出的句子的概率就是最大的么？</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/greedy%20search.png" srcset="/img/loading.gif" lazyload></p>
</blockquote>
<p><code>Beam search</code>的又被称作<code>束集搜索</code>，是一种seq2seq中用来优化输出结果的算法(不在训练过程中使用)。</p>
<p>例如：传统的获取解码器输出的过程中，每次只选择概率最大的那个结果，作为当前时间步的输出，等到输出结束，我们会发现，整个句子可能并不通顺。虽然在每一个时间步上的输出确实是概率最大的，但是整体的概率确不一定最大的，我们经常把它叫做<code>greedy search[贪心算法]</code></p>
<p>为了解决上述的问题，可以考虑计算全部的输出的概率乘积，选择最大的哪一个，但是这样的话，意味着如果句子很长，候选词很多，那么需要保存的数据就会非常大，需要计算的数据量就很大</p>
<p>那么Beam Search 就是介于上述两种方法的一个这种的方法，假设Beam width&#x3D;2，表示每次保存的最大的概率的个数，这里每次保存两个，在下一个时间步骤一样，也是保留两个，这样就可以达到约束搜索空间大小的目的，从而提高算法的效率。</p>
<p>beam width &#x3D;1 时，就是贪心算法，beam width&#x3D;候选词的时候，就是计算全部的概率。beam width 是一个超参数。</p>
<p>比如在下图中:</p>
<p>使用一个树状图来表示每个time step的可能输出，其中的数字表示是条件概率</p>
<p>黄色的箭头表示的是一种greedy search，概率并不是最大的</p>
<p>如果把beam width设置为2，那么后续可以找到绿色路径的结果，这个结果是最大的</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/greedy%20search.png" srcset="/img/loading.gif" lazyload></p>
<p>下图是要给beam width&#x3D;3的例子</p>
<ol>
<li>首先输入<code>start token &lt;s&gt;</code>,然后得到四个输出(这里假设一个就四个输出:<code>x,y,z,&lt;/s&gt;</code>)，选择概率最大三个，x,y,w</li>
<li>然后分别把x,y,z放到下一个time step中作为输入，分别得到三个不同的输出，找到三个输出中概率最大的三个，x,y,y</li>
<li>继续重复上述步骤，直到获得结束符(概率最大)或者是达到句子的最大长度，那么此时选择概率乘积最大的一个。</li>
<li>拼接整个路径上概率最大的所有结果，比如这里可能是<code>&lt;s&gt;,y,y,x,w,&lt;/s&gt;</code></li>
</ol>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/beamsearch.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="2-Beam-serach的实现"><a href="#2-Beam-serach的实现" class="headerlink" title="2. Beam serach的实现"></a>2. Beam serach的实现</h2><p>在上述描述的思路中，我们需要注意以下几个内容：</p>
<ol>
<li>数据该如何保存，每一次的输出的最大的beam width个结果，和之后之前的结果该如何保存</li>
<li>保存了之后的概率应该如何比较大小，保留下概率最大的三个</li>
<li>不能够仅仅只保存当前概率最大的信息，还需要有当前概率最大的三个中，前面的路径的输出结果</li>
</ol>
<h3 id="2-1-数据结构-堆-的认识"><a href="#2-1-数据结构-堆-的认识" class="headerlink" title="2.1 数据结构-堆-的认识"></a>2.1 数据结构-堆-的认识</h3><p>对于上面所说的，保留有限个数据，同时需要根据大小来保留，可以使用一种带有优先级的数据结构来实现，这里我们可以使用<code>堆</code>这种数据结构</p>
<p><code>堆</code>是一种优先级的队列，但是他其实并不是队列，我们常说的队列都是<code>先进先出或者是先进后出</code>，但是<code>堆</code>只根据优先级的高低来取出数据。</p>
<p>和<code>堆</code>在一起的另外一种数据结构叫做<code>栈</code>,有入栈和出栈的操作，可以理解为是一种先进后出的数据结构，关于栈，大家可以下来在了解。</p>
<p>在python自带的模块中，有一个叫做<code>heapq</code>的模块，提供了堆所有的方法。通过下面的代码我们来了解下heapq的使用方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">my_heap = [] <span class="hljs-comment">#使用列表保存数据</span><br><br> <span class="hljs-comment">#往列表中插入数据，优先级使用插入的内容来表示，就是一个比较大小的操作，越大优先级越高</span><br>heapq.heappush(my_heap,[<span class="hljs-number">29</span>,<span class="hljs-literal">True</span>,<span class="hljs-string">&quot;xiaohong&quot;</span>]) <br>heapq.heappush(my_heap,[<span class="hljs-number">28</span>,<span class="hljs-literal">False</span>,<span class="hljs-string">&quot;xiaowang&quot;</span>])<br>heapq.heappush(my_heap,[<span class="hljs-number">29</span>,<span class="hljs-literal">False</span>,<span class="hljs-string">&quot;xiaogang&quot;</span>])<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    ret= heapq.heappop(my_heap)  <span class="hljs-comment">#pop操作，优先级最小的数据</span><br>    <span class="hljs-built_in">print</span>(ret)<br>    <br><span class="hljs-comment">#输出如下：</span><br>[<span class="hljs-number">28</span>, <span class="hljs-literal">False</span>, <span class="hljs-string">&#x27;xiaowang&#x27;</span>]<br>[<span class="hljs-number">29</span>, <span class="hljs-literal">False</span>, <span class="hljs-string">&#x27;xiaogang&#x27;</span>]<br>[<span class="hljs-number">29</span>, <span class="hljs-literal">True</span>, <span class="hljs-string">&#x27;xiaohong&#x27;</span>]<br></code></pre></td></tr></table></figure>

<p>可以发现，输出的顺序并不是数据插入的顺序，而是根据其优先级，从小往大pop（False&lt;True）。</p>
<h3 id="2-2-使用堆来实现beam-search"><a href="#2-2-使用堆来实现beam-search" class="headerlink" title="2.2 使用堆来实现beam search"></a>2.2 使用堆来实现beam search</h3><p>为了实现数据的的保存，我们可以把beam search中的数据保存在堆中，同时在往这个堆中添加数据的同时，判断数据的个数，仅仅保存beam width个数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Beam</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.heap = <span class="hljs-built_in">list</span>() <span class="hljs-comment">#保存数据的位置</span><br>        self.beam_width = config.beam_width <span class="hljs-comment">#保存数据的总数</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self,probility,complete,seq,decoder_input,decoder_hidden</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        添加数据，同时判断总的数据个数，多则删除</span><br><span class="hljs-string">        :param probility: 概率乘积</span><br><span class="hljs-string">        :param complete: 最后一个是否为EOS</span><br><span class="hljs-string">        :param seq: list，所有token的列表</span><br><span class="hljs-string">        :param decoder_input: 下一次进行解码的输入，通过前一次获得</span><br><span class="hljs-string">        :param decoder_hidden: 下一次进行解码的hidden，通过前一次获得</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        heapq.heappush(self.heap,[probility,complete,seq,decoder_input,decoder_hidden])<br>        <span class="hljs-comment">#判断数据的个数，如果大，则弹出。保证数据总个数小于等于3</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.heap)&gt;self.beam_width:<br>            heapq.heappop(self.heap)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<span class="hljs-comment">#让该beam能够被迭代</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">iter</span>(self.heap)<br></code></pre></td></tr></table></figure>

<p>实现方法，完成模型eval过程中的beam search搜索</p>
<p>思路：</p>
<ol>
<li>构造<code>&lt;SOS&gt;</code>开始符号等第一次输入的信息，保存在堆中</li>
<li>取出堆中的数据，进行forward_step的操作，获得当前时间步的output，hidden</li>
<li>从output中选择topk（k&#x3D;beam width）个输出，作为下一次的input</li>
<li>把下一个时间步骤需要的输入等数据保存在一个新的堆中</li>
<li>获取新的堆中的优先级最高（概率最大）的数据，判断数据是否是EOS结尾或者是否达到最大长度，如果是，停止迭代</li>
<li>如果不是，则重新遍历新的堆中的数据</li>
</ol>
<p>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># decoder中的新方法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluatoin_beamsearch_heapq</span>(<span class="hljs-params">self,encoder_outputs,encoder_hidden</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;使用 堆 来完成beam search，对是一种优先级的队列，按照优先级顺序存取数据&quot;&quot;&quot;</span><br><br>    batch_size = encoder_hidden.size(<span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#1. 构造第一次需要的输入数据，保存在堆中</span><br>    decoder_input = torch.LongTensor([[word_sequence.SOS] * batch_size]).to(config.device)<br>    decoder_hidden = encoder_hidden <span class="hljs-comment">#需要输入的hidden</span><br><br>    prev_beam = Beam()<br>    prev_beam.add(<span class="hljs-number">1</span>,<span class="hljs-literal">False</span>,[decoder_input],decoder_input,decoder_hidden)<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        cur_beam = Beam()<br>        <span class="hljs-comment">#2. 取出堆中的数据，进行forward_step的操作，获得当前时间步的output，hidden</span><br>        <span class="hljs-comment">#这里使用下划线进行区分</span><br>        <span class="hljs-keyword">for</span> _probility,_complete,_seq,_decoder_input,_decoder_hidden <span class="hljs-keyword">in</span> prev_beam:<br>            <span class="hljs-comment">#判断前一次的_complete是否为True，如果是，则不需要forward</span><br>            <span class="hljs-comment">#有可能为True，但是概率并不是最大</span><br>            <span class="hljs-keyword">if</span> _complete == <span class="hljs-literal">True</span>:<br>                cur_beam.add(_probility,_complete,_seq,_decoder_input,_decoder_hidden)<br>            <span class="hljs-keyword">else</span>:<br>                decoder_output_t, decoder_hidden,_ = self.forward_step(_decoder_input, _decoder_hidden,encoder_outputs)<br>                value, index = torch.topk(decoder_output_t, config.beam_width)  <span class="hljs-comment"># [batch_size=1,beam_widht=3]</span><br>             <span class="hljs-comment">#3. 从output中选择topk（k=beam width）个输出，作为下一次的input</span><br>            	<span class="hljs-keyword">for</span> m, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(value[<span class="hljs-number">0</span>], index[<span class="hljs-number">0</span>]):<br>                    decoder_input = torch.LongTensor([[n]]).to(config.device)<br>                    seq = _seq + [n]<br>                    probility = _probility * m<br>                    <span class="hljs-keyword">if</span> n.item() == word_sequence.EOS:<br>                    	complete = <span class="hljs-literal">True</span><br>                    <span class="hljs-keyword">else</span>:<br>                        complete = <span class="hljs-literal">False</span><br><br>                 	<span class="hljs-comment">#4. 把下一个实践步骤需要的输入等数据保存在一个新的堆中</span><br>                	  cur_beam.add(probility,complete,seq,<br>                                   decoder_input,decoder_hidden)<br>          <span class="hljs-comment">#5. 获取新的堆中的优先级最高（概率最大）的数据，判断数据是否是EOS结尾或者是否达到最大长度，如果是，停止迭代</span><br>          best_prob,best_complete,best_seq,_,_ = <span class="hljs-built_in">max</span>(cur_beam)<br>         <span class="hljs-keyword">if</span> best_complete == <span class="hljs-literal">True</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(best_seq)-<span class="hljs-number">1</span> == config.max_len: <span class="hljs-comment">#减去sos</span><br>            <span class="hljs-keyword">return</span> self._prepar_seq(best_seq)<br>         <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment">#6. 则重新遍历新的堆中的数据</span><br>            prev_beam = cur_beam<br>                                    <br>      <span class="hljs-keyword">def</span> <span class="hljs-title function_">_prepar_seq</span>(<span class="hljs-params">self,seq</span>):<span class="hljs-comment">#对结果进行基础的处理，共后续转化为文字使用</span><br>        <span class="hljs-keyword">if</span> seq[<span class="hljs-number">0</span>].item() == word_sequence.SOS:<br>            seq=  seq[<span class="hljs-number">1</span>:]<br>        <span class="hljs-keyword">if</span>  seq[-<span class="hljs-number">1</span>].item() == word_sequence.EOS:<br>            seq = seq[:-<span class="hljs-number">1</span>]<br>        seq = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> seq]<br>        <span class="hljs-keyword">return</span> seq<br></code></pre></td></tr></table></figure>

<h3 id="2-3-修改seq2seq"><a href="#2-3-修改seq2seq" class="headerlink" title="2.3 修改seq2seq"></a>2.3 修改seq2seq</h3><p>在seq2seq中使用evaluatoin_beamsearch_heapq查看效果，会发现使用beam search的效果比单独使用attention的效果更好</p>
<p>使用小黄鸡语料（50万个问答），单个字作为token，5个epoch之后的训练结果，左边为问，右边是回答</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">你在干什么 &gt;&gt;&gt;&gt;&gt; 你想干啥？<br>你妹 &gt;&gt;&gt;&gt;&gt; 不是我<br>你叫什么名字 &gt;&gt;&gt;&gt;&gt; 你猜<br>你个垃圾 &gt;&gt;&gt;&gt;&gt; 你才是，你<br>你是傻逼 &gt;&gt;&gt;&gt;&gt; 是你是傻<br>笨蛋啊 &gt;&gt;&gt;&gt;&gt; 我不是，你<br></code></pre></td></tr></table></figure>

<h1 id="闲聊机器人的优化"><a href="#闲聊机器人的优化" class="headerlink" title="闲聊机器人的优化"></a>闲聊机器人的优化</h1><h2 id="目标-25"><a href="#目标-25" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道如何优化模型的效果</li>
<li>知道常见的优化手段</li>
</ol>
<h2 id="1-seq2seq中使用teacher-forcing"><a href="#1-seq2seq中使用teacher-forcing" class="headerlink" title="1. seq2seq中使用teacher forcing"></a>1. seq2seq中使用<code>teacher forcing</code></h2><p>在前面的seq2seq的案例中，我们介绍了<code>teacher frocing</code>是什么，当时我们的输入和输出很相似，所以当时我们的<code>teacher forcing</code>是在每个time step中实现的，那么现在我们的输入和输出不同的情况下，该如何使用呢？</p>
<p>我们可以在每个batch遍历time step的外层使用<code>teacher forcing</code></p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">use_teacher_forcing = random.random() &gt; <span class="hljs-number">0.5</span><br><span class="hljs-keyword">if</span> use_teacher_forcing: <span class="hljs-comment">#使用teacher forcing</span><br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>        decoder_output_t, decoder_hidden, decoder_attn_t = self.forward_step(decoder_input, decoder_hidden,<br>                                                                             encoder_outputs)<br>        decoder_outputs[:, t, :] = decoder_output_t<br>        <span class="hljs-comment">#使用正确的输出作为下一步的输入</span><br>        decoder_input = target[:, t].unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size,1]</span><br><br><span class="hljs-keyword">else</span>:<span class="hljs-comment">#不适用teacher forcing，使用预测的输出作为下一步的输入</span><br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.max_len):<br>        decoder_output_t ,decoder_hidden,decoder_attn_t = self.forward_step(decoder_input,decoder_hidden,encoder_outputs)<br>        decoder_outputs[:,t,:] = decoder_output_t<br>        value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>) <span class="hljs-comment"># index [batch_size,1]</span><br>        decoder_input = index<br></code></pre></td></tr></table></figure>

<h2 id="2-使用梯度裁剪"><a href="#2-使用梯度裁剪" class="headerlink" title="2. 使用梯度裁剪"></a>2. 使用梯度裁剪</h2><p>前面，我们给大家介绍了<code>梯度消失(梯度过小，在多层计算后导致其值太小而无法计算)</code>和<code>梯度爆炸（梯度过大，导致其值在多层的计算后太大而无法计算）</code>。</p>
<p>在常见的深度神经网络中，特别是RNN中，我们经常会使用<code>梯度裁剪</code>的手段，来抑制过大的梯度，能够有效防止梯度爆炸。</p>
<p>梯度裁剪的实现非常简单，仅仅只需要设置一个阈值，把梯度大于该阈值时设置为该阈值。</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/grad_clip.png" srcset="/img/loading.gif" lazyload></p>
<p>实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">loss.backward()<br><span class="hljs-comment">#进行梯度裁剪</span><br>nn.utils.clip_grad_norm_(model.parameters(),[<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">15</span>])<br>optimizer.step()<br></code></pre></td></tr></table></figure>

<h2 id="3-其他优化方法"><a href="#3-其他优化方法" class="headerlink" title="3. 其他优化方法"></a>3. 其他优化方法</h2><ol>
<li>根据特定的问题，使用分类模型进行训练，然后再训练单独的回个该为题的为模型<ul>
<li>比如询问名字，可以使用fasttext先进行意图识别，命中<code>询问名字</code>分类后，直接返回名字</li>
<li>或者是手动构造和名字相关的很多问题，来进行训练，从而能够更加个性化的回答出结果</li>
</ul>
</li>
<li>直接对现有的语料进行修改和清洗，把语料中更多的答案进行替换，比如咨询名字的，咨询天气的等，这样能够更大程度上的回答出更加规范的答案</li>
<li>使用2.4 会讲的搜索模型，不再使用这种生成模型</li>
</ol>
<h1 id="问答机器人介绍"><a href="#问答机器人介绍" class="headerlink" title="问答机器人介绍"></a>问答机器人介绍</h1><h2 id="目标-26"><a href="#目标-26" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道问答机器人是什么</li>
<li>知道问答机器人实现的逻辑</li>
</ol>
<h2 id="1-问答机器人"><a href="#1-问答机器人" class="headerlink" title="1. 问答机器人"></a>1. 问答机器人</h2><p>在前面的课程中，我们已经对问答机器人介绍过，这里的问答机器人是我们在分类之后，对特定问题进行回答的一种机器人。至于回答的问题的类型，取决于我们的语料。</p>
<p>当前我们需要实现的问答机器人是一个回答编程语言（比如<code>python是什么</code>，<code>python难么</code>等）相关问题的机器人</p>
<h2 id="2-问答机器人的实现逻辑"><a href="#2-问答机器人的实现逻辑" class="headerlink" title="2. 问答机器人的实现逻辑"></a>2. 问答机器人的实现逻辑</h2><p>主要实现逻辑：从现有的问答对中，选择出和问题最相似的问题，并且获取其相似度（一个数值），如果相似度大于阈值，则返回这个最相似的问题对应的答案</p>
<p>问答机器人的实现可以大致分为三步步骤：</p>
<ol>
<li>对问题的处理</li>
<li>对答案进行的机器学习召回</li>
<li>对召回的结果进行排序</li>
</ol>
<h3 id="2-1-对问题的处理"><a href="#2-1-对问题的处理" class="headerlink" title="2.1 对问题的处理"></a>2.1 对问题的处理</h3><p>对问题的处理过程中，我们可以考虑以下问题：</p>
<ol>
<li>对问题进行基础的清洗，去除特殊符号等</li>
<li>问题主语的识别，判断问题中是否包含特定的主语，比如<code>python</code>等，提取出来之后，方便后续对问题进行过滤。<ul>
<li>可以看出，不仅需要对用户输入的问题进行处理，获取主语，还需要对现有问答对进行处理</li>
</ul>
</li>
<li>获取问题的词向量，可以考虑使用词频，tdidf等值，方便召回的时候使用</li>
</ol>
<h3 id="2-2-问题的召回"><a href="#2-2-问题的召回" class="headerlink" title="2.2 问题的召回"></a>2.2 问题的召回</h3><p>召回：可以理解为是一个海选的操作，就是从现有的问答对中选择可能相似的前K个问题。</p>
<p>为什么要进行召回?</p>
<blockquote>
<p>主要目的是为了后续进行排序的时候，减少需要计算的数据量，比如有10万个问答对，直接通过深度学习肯定是可以获取所有的相似度，但是速度慢。</p>
<p>所以考虑使用机器学习的方法进行一次海选</p>
</blockquote>
<p>那么，如何实现召回呢？</p>
<blockquote>
<p>前面我们介绍，召回就是选择前K个最相似的问题，所以召回的实现就是想办法通过机器学习的手段计算器相似度。</p>
</blockquote>
<p>可以思考的方法：</p>
<ol>
<li>使用词袋模型，获取词频矩阵，计算相似度</li>
<li>使用tfidf，获取tdidf的矩阵，计算相似度</li>
</ol>
<p>上述的方法理论上都可行，知识当候选计算的词语数量太多的时候，需要挨个计算相似度，非常耗时。</p>
<p>所以可以考虑以下两点：</p>
<ol>
<li>通过前面获取的主语，对问题进行过滤</li>
<li>使用聚类的方法，对数据先聚类，再计算某几个类别中的相似度，而不用去计算全部。</li>
</ol>
<p>但是还有一个问题，供大家慢慢思考：</p>
<blockquote>
<p>不管是词频，还是tdidf，获取的结果肯定是没有考虑文字顺序的，效果不一定是最好的，那么此时，应该如何让最后召回的效果更好呢？</p>
</blockquote>
<h3 id="2-3-问题的排序"><a href="#2-3-问题的排序" class="headerlink" title="2.3 问题的排序"></a>2.3 问题的排序</h3><p>排序过程，使用了召回的结果作为输入，同时输出的是最相似的那一个。</p>
<p>整个过程使用深度学习实现。深度学习虽然训练的速度慢，但是整体效果肯定比机器学习好（机器学习受限于特征工程，数据量等因素，没有办法深入的学会不同问题之间的内在相似度），所以通过自建的模型，获取最后的相似度。</p>
<p>使用深度学习的模型这样一个黑匣子，在训练数据足够多的时候，能够学习到用户的各种不同输入的问题，当我们把目标值（相似的问题）给定的情况下，让模型自己去找到这些训练数据目标值和特征值之间相似的表示方法。</p>
<p>那么此时，有以下两个问题：</p>
<ol>
<li><p>使用什么数据，来训练模型，最后返回模型的相似度</p>
<blockquote>
<p>训练的数据的来源：可以考虑根据现有的问答对去手动构造，但是构造的数据不一定能够覆盖后续用户提问的全部问题。所以可以考虑通过程序去采集网站上相似的问题，比如百度知道的搜索结果。</p>
</blockquote>
</li>
<li><p>模型该如何构建</p>
<blockquote>
<p>模型可以有两个输入，输出为一个数值，两个输入的处理方法肯定是一样的。这种网络结构我们经常把它称作孪生神经网络。</p>
</blockquote>
<p>很明显，我们队输入的数据需要进行编码的操作，比如word embedding + LSTM&#x2F;GRU&#x2F;BIGRU等</p>
<p>两个编码之后的结果，我们可以进行组合，然后通过一个多层的神经网络，输出一个数字，把这个数值定义为我们的相似度。</p>
<p>当然我们的深层的神经网络在最开始的时候也并不是计算的相似度，但是我们的训练数据的目标值是相似度，在N多次的训练之后，确定了输入和输出的表示方法之后，那么最后的模型输出就是相似度了。</p>
</li>
</ol>
<p>前面我们介绍了问答机器人的实现的大致思路，那么接下来，我们就来一步步的实现它</p>
<h1 id="问答机器人的召回"><a href="#问答机器人的召回" class="headerlink" title="问答机器人的召回"></a>问答机器人的召回</h1><h2 id="目标-27"><a href="#目标-27" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道召回的目的</li>
<li>能够说出召回的流程</li>
<li>能够优化基础的召回逻辑</li>
</ol>
<h2 id="1-召回的流程"><a href="#1-召回的流程" class="headerlink" title="1. 召回的流程"></a>1. 召回的流程</h2><p>流程如下：</p>
<ol>
<li>准备数据，问答对的数据等</li>
<li>问题转化为向量</li>
<li>计算相似度</li>
</ol>
<h2 id="2-对现有问答对的准备"><a href="#2-对现有问答对的准备" class="headerlink" title="2. 对现有问答对的准备"></a>2. 对现有问答对的准备</h2><p>这里说的问答对，是带有标准答案的问题，后续命中问答对中的问题后，会返回该问题对应的答案</p>
<p>为了后续使用方便，我们可以把现有问答对的处理成如下的格式，可以考虑存入数据库或者本地文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<br>    <span class="hljs-string">&quot;问题1&quot;</span>:&#123;<br>        <span class="hljs-string">&quot;主体&quot;</span>:[<span class="hljs-string">&quot;主体1&quot;</span>,<span class="hljs-string">&quot;主体3&quot;</span>,<span class="hljs-string">&quot;主体3&quot;</span>..],<br>        <span class="hljs-string">&quot;问题1分词后的句子&quot;</span>:[<span class="hljs-string">&quot;word1&quot;</span>,<span class="hljs-string">&quot;word2&quot;</span>,<span class="hljs-string">&quot;word3&quot;</span>...],<br>        <span class="hljs-string">&quot;答案&quot;</span>:<span class="hljs-string">&quot;答案&quot;</span><br>    &#125;,<br>    <span class="hljs-string">&quot;问题2&quot;</span>:&#123;<br>        ...<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># lib/get_qa_dcit.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_qa_dict</span>():<br>    chuanzhi_q_path = <span class="hljs-string">&quot;./问答对/Q.txt&quot;</span><br>    chuanzhi_a_path = <span class="hljs-string">&quot;./问答对/A.txt&quot;</span><br>    QA_dict = &#123;&#125;<br>    <span class="hljs-keyword">for</span> q,a <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">open</span>(chuanzhi_q_path).readlines(),<span class="hljs-built_in">open</span>(chuanzhi_a_path).readlines()):<br>        QA_dict[q.strip()] = &#123;&#125;<br>        QA_dict[q.strip()][<span class="hljs-string">&quot;ans&quot;</span>] = a.strip()<br>        QA_dict[q.strip()][<span class="hljs-string">&quot;entity&quot;</span>] = sentence_entity(q.strip())[-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-comment">#准备短问答的问题</span><br>    python_duan_path = <span class="hljs-string">&quot;./data/Python短问答-11月汇总.xlsx&quot;</span><br><br>    ret = pd.read_excel(python_duan_path)<br>    column_list = ret.columns<br>    <span class="hljs-keyword">assert</span> <span class="hljs-string">&#x27;问题&#x27;</span> <span class="hljs-keyword">in</span> column_list <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;答案&quot;</span> <span class="hljs-keyword">in</span> column_list, <span class="hljs-string">&quot;excel 中必须包含问题和答案&quot;</span><br>    <span class="hljs-keyword">for</span> q, a <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(ret[<span class="hljs-string">&quot;问题&quot;</span>], ret[<span class="hljs-string">&quot;答案&quot;</span>]):<br>        q = re.sub(<span class="hljs-string">&quot;\s+&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, q)<br>        QA_dict[q.strip()] = &#123;&#125;<br>        QA_dict[q.strip()][<span class="hljs-string">&quot;ans&quot;</span>] = a<br>        cuted,entiry = sentence_entity(q.strip())[-<span class="hljs-number">1</span>]<br>        QA_dict[q.strip()][<span class="hljs-string">&quot;entity&quot;</span>] = entiry<br>        QA_dict[q.strip()][<span class="hljs-string">&quot;q_cuted&quot;</span>] = cuted<br><br>    <span class="hljs-keyword">return</span> QA_dict<br><br>QA_dict = get_qa_dict()<br></code></pre></td></tr></table></figure>

<h2 id="3-把问题转化为向量"><a href="#3-把问题转化为向量" class="headerlink" title="3. 把问题转化为向量"></a>3. 把问题转化为向量</h2><p>把问答对中的问题，和用户输出的问题，转化为向量，为后续计算相似度做准备。</p>
<p>这里，我们使用tfidf对问答对中的问题进行处理，转化为向量矩阵。</p>
<blockquote>
<p>TODO，使用单字，使用n-garm，使用BM25，使用word2vec等，让其结果更加准确</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> QA_dict<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_q_vectors</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;对问题建立索引&quot;&quot;&quot;</span><br>    lines_cuted= [q[<span class="hljs-string">&quot;q_cuted&quot;</span>] <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> QA_dict]<br>    tfidf_vectorizer = TfidfVectorizer()<br>    features_vec = tfidf_vectorizer.fit_transform(lines_cuted)<br>    <span class="hljs-comment">#返回tfidf_vectorizer，后续还需要对用户输入的问题进行同样的处理</span><br>	<span class="hljs-keyword">return</span> tfidf_vectorizer,features_vec，lines_cuted<br></code></pre></td></tr></table></figure>

<h2 id="4-计算相似度"><a href="#4-计算相似度" class="headerlink" title="4. 计算相似度"></a>4. 计算相似度</h2><p>思路很简单。对用户输入的问题使用<code>tfidf_vectorizer</code>进行处理，然后和<code>features_vec</code>中的每一个结果进行计算，获取相似度。</p>
<p>但是由于耗时可能会很久，所以考虑使用其他方法来实现</p>
<h3 id="4-1-pysparnn的介绍"><a href="#4-1-pysparnn的介绍" class="headerlink" title="4.1 pysparnn的介绍"></a>4.1 <code>pysparnn</code>的介绍</h3><p>官方地址：<code>https://github.com/facebookresearch/pysparnn</code></p>
<p><code>pysparnn</code>是一个对sparse数据进行相似邻近搜索的python库，这个库是用来实现 高维空间中寻找最相似的数据的。</p>
<h3 id="4-2-pysparnn的使用方法"><a href="#4-2-pysparnn的使用方法" class="headerlink" title="4.2 pysparnn的使用方法"></a>4.2 <code>pysparnn</code>的使用方法</h3><p>pysparnn的使用非常简单，仅仅需要以下步骤，就能够完成从高维空间中寻找相似数据的结果</p>
<ol>
<li>准备源数据和待搜索数据</li>
<li>对源数据进行向量化，把向量结果和源数据构造搜索的索引</li>
<li>对待搜索的数据向量化，传入索引，获取结果</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pysparnn.cluster_index <span class="hljs-keyword">as</span> ci<br><br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br><br><span class="hljs-comment">#1. 原始数据</span><br>data = [<br>    <span class="hljs-string">&#x27;hello world&#x27;</span>,<br>    <span class="hljs-string">&#x27;oh hello there&#x27;</span>,<br>    <span class="hljs-string">&#x27;Play it&#x27;</span>,<br>    <span class="hljs-string">&#x27;Play it again Sam&#x27;</span>,<br>]  <br><br><span class="hljs-comment">#2. 原始数据向量化</span><br><br>tv = TfidfVectorizer()<br>tv.fit(data)<br><br>features_vec = tv.transform(data)<br><br><span class="hljs-comment"># 原始数据构造索引</span><br>cp = ci.MultiClusterIndex(features_vec, data)<br><br><span class="hljs-comment"># 待搜索的数据向量化</span><br>search_data = [<br>    <span class="hljs-string">&#x27;oh there&#x27;</span>,<br>    <span class="hljs-string">&#x27;Play it again Frank&#x27;</span><br>]<br><br>search_features_vec = tv.transform(search_data)<br><br><span class="hljs-comment">#3. 索引中传入带搜索数据，返回结果</span><br>cp.search(search_features_vec, k=<span class="hljs-number">1</span>, k_clusters=<span class="hljs-number">2</span>, return_distance=<span class="hljs-literal">False</span>)<br>&gt;&gt; [[<span class="hljs-string">&#x27;oh hello there&#x27;</span>], [<span class="hljs-string">&#x27;Play it again Sam&#x27;</span>]]<br></code></pre></td></tr></table></figure>

<p>使用注意点：</p>
<ol>
<li>构造索引是需要传入向量和原数据，最终的结果会返回源数据</li>
<li>传入待搜索的数据时，需要传入一下几个参数：<ol>
<li><code>search_features_vec</code>：搜索的句子的向量</li>
<li><code>k</code>:最大的几个结果，k&#x3D;1，返回最大的一个</li>
<li><code>k_clusters</code>:对数据分为多少类进行搜索</li>
<li><code>return_distance</code>:是否返回距离</li>
</ol>
</li>
</ol>
<h3 id="4-3-使用pysparnn完成召回的过程"><a href="#4-3-使用pysparnn完成召回的过程" class="headerlink" title="4.3 使用pysparnn完成召回的过程"></a>4.3 使用pysparnn完成召回的过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#构造索引</span><br>cp = ci.MultiClusterIndex(features_vec, lines_cuted)<br><br><span class="hljs-comment">#对用户输入的句子进行向量化</span><br>search_vec = tfidf_vec.transform(ret)<br><span class="hljs-comment">#搜索获取结果，返回最大的8个数据，之后根据`main_entiry`进行过滤结果</span><br>cp_search_list = cp.search(search_vec, k=<span class="hljs-number">8</span>, k_clusters=<span class="hljs-number">10</span>, return_distance=<span class="hljs-literal">True</span>)<br><br>exist_same_entiry = <span class="hljs-literal">False</span><br>search_lsit = []<br><span class="hljs-keyword">for</span> _temp_call_line <span class="hljs-keyword">in</span> cp_search_list[<span class="hljs-number">0</span>]:<br>    cur_entity = QA_dict[_temp_call_line[<span class="hljs-number">1</span>]][<span class="hljs-string">&quot;main_entity&quot;</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(main_entity) &amp; <span class="hljs-built_in">set</span>(cur_entity))&gt;<span class="hljs-number">0</span>:  <span class="hljs-comment">#命名体的集合存在交集的时候返回</span><br>        exist_same_entiry  = <span class="hljs-literal">True</span><br>        search_lsit.append(_temp_call_line[<span class="hljs-number">1</span>])<br><br><span class="hljs-keyword">if</span> exist_same_entiry: <span class="hljs-comment">#存在相同的主体的时候</span><br>    <span class="hljs-keyword">return</span> search_lsit<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># print(cp_search_list)</span><br>    <span class="hljs-keyword">return</span> [i[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> cp_search_list[<span class="hljs-number">0</span>]]<br><br></code></pre></td></tr></table></figure>

<p>在这个过程中，需要注意，提前把<code>cp,tfidf_vec</code>等内容提前准备好，而不应该在每次接收到用户的问题之后重新生成一遍，否则效率会很低</p>
<h3 id="4-4-pysparnn的原理介绍"><a href="#4-4-pysparnn的原理介绍" class="headerlink" title="4.4 pysparnn的原理介绍"></a>4.4 <code>pysparnn</code>的原理介绍</h3><p>参考地址：<code>https://nlp.stanford.edu/IR-book/html/htmledition/cluster-pruning-1.html</code></p>
<p>前面我们使用的<code>pysparnn</code>使用的是一种<code>cluster pruning(簇修剪)</code>的技术，即，开始的时候对数据进行聚类，后续再有限个类别中进行数据的搜索，根据计算的余弦相似度返回结果。</p>
<p>数据预处理过程如下：</p>
<ol>
<li>随机选择$\sqrt{N}$个样本作为leader</li>
<li>选择非leader的数据(follower),使用余弦相似度计算找到最近的leader</li>
</ol>
<p>当获取到一个问题q的时候，查询过程：</p>
<ol>
<li>计算每个leader和q的相似度，找到最相似的leader</li>
<li>然后计算问题q和leader所在簇的相似度，找到最相似的k个，作为最终的返回结果</li>
</ol>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pysparnn.png" srcset="/img/loading.gif" lazyload></p>
<p>在上述的过程中，可以设置两个大于0的数字<code>b1和b2</code></p>
<ul>
<li>b1表示在<code>数据预处理</code>阶段，每个follower选择b1个最相似的leader，而不是选择单独一个lader，这样不同的簇是有数据交叉的；</li>
<li>b2表示在查询阶段，找到最相似的b2个leader，然后再计算不同的leader中下的topk的结果</li>
</ul>
<p>前面的描述就是b1&#x3D;b2&#x3D;1的情况，通过增加<code>b1和b2</code>的值，我们能够有更大的机会找到更好的结果，但是这样会需要更加大量的计算。</p>
<p>在pysparnn中实例化索引的过程中</p>
<p> 即：<code>ci.MultiClusterIndex(features, records_data, num_indexes)</code>中，<code>num_indexes</code>能够设置b1的值，默认为2。</p>
<p>在搜索的过程中，<code>cp.search(search_vec, k=8, k_clusters=10, return_distance=True,num_indexes)</code>，<code>num_Indexes</code>可以设置b2的值，默认等于b1的值。</p>
<h1 id="召回过程优化"><a href="#召回过程优化" class="headerlink" title="召回过程优化"></a>召回过程优化</h1><h2 id="目标-28"><a href="#目标-28" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道优化的方法和思路</li>
<li>知道BM25方法的原理和实现</li>
<li>能够使用word2vector完成优化过程</li>
</ol>
<h2 id="1-优化思路"><a href="#1-优化思路" class="headerlink" title="1. 优化思路"></a>1. 优化思路</h2><p>前面的学习，我们能够返回相似的召回结果，但是，如何让这些结果更加准确呢？</p>
<p>我们可以从下面的角度出发：</p>
<ol>
<li>tfidf使用的是词频和整个文档的词语，如果用户问题的某个词语没有出现过，那么此时，计算出来的相似度可能就不准确。该问题的解决思路：<ul>
<li>对用户输入的问题进行文本的对齐，比如，使用训练好的word2vector，往句子中填充非主语的其他词语的相似词语。例如<code>python 好学 么 --&gt;填充后是 ：python 好学 么 简单 难 嘛 </code>，这里假设word2vector同学会了<code>好学，简单，难</code>他们之间是相似的</li>
<li>使用word2vector对齐的好处除了应对未出现的词语，还能够提高主语的重要程度，让主语位置的tfidf的值更大，从而让相似度更加准确</li>
</ul>
</li>
<li>tfidf是一个词袋模型，没有考虑词和词之间的顺序<ul>
<li>使用n-garm和词一起作为特征，转化为特征向量</li>
</ul>
</li>
<li>不去使用tfidf处理句子得到向量。<ul>
<li>使用BM25算法</li>
<li>或者 使用fasttext、word2vector，把句子转化为向</li>
</ul>
</li>
</ol>
<h2 id="2-通过BM25算法代替TFIDF"><a href="#2-通过BM25算法代替TFIDF" class="headerlink" title="2. 通过BM25算法代替TFIDF"></a>2. 通过BM25算法代替TFIDF</h2><h3 id="2-1-BM25算法原理"><a href="#2-1-BM25算法原理" class="headerlink" title="2.1 BM25算法原理"></a>2.1 BM25算法原理</h3><p>BM25(BM&#x3D;best matching)是TDIDF的优化版本，首先我们来看看TFIDF是怎么计算的<br>$$<br>tfidf_i &#x3D; tf*idf &#x3D; \frac{词i的数量}{词语总数}*log\frac{总文档数}{包含词i的文档数}<br>$$<br>其中tf称为词频，idf为逆文档频率</p>
<p>那么BM25是如何计算的呢？<br>$$<br>BM25(i) &#x3D; \frac{词i的数量}{总词数}*\frac{(k+1)C}{C+k(1-b+b\frac{|d|}{avdl}）}*log(\frac{总文档数}{包含i的文档数}) \<br>C &#x3D; tf&#x3D;\frac{词i的数量}{总词数},k&gt;0,b\in [0,1]，d为文档i的长度，avdl是文档平均长度<br>$$<br>大家可以看到，BM25和tfidf的计算结果很相似，唯一的区别在于中多了一项，这一项是用来对tf的结果进行的一种变换。</p>
<p>把$1-b+b\frac{d}{avdl}$中的b看成0，那么此时中间项的结果为$\frac{(k+1)tf}{k+tf}$，通过设置一个k，就能够保证其最大值为$1$，达到限制tf过大的目的。</p>
<p>即：<br>$$<br>\begin{align}<br>&amp;\frac{(k+1)tf}{k+tf}&#x3D; \frac{k+1}{1+\frac{k}{tf}} \qquad \qquad \qquad,上下同除tf<br>\end{align}<br>$$<br>k不变的情况下，上式随着tf的增大而增大，上限为k+1,但是增加的程度会变小，如下图所示。</p>
<p>在一个句子中，某个词重要程度应该是随着词语的数量逐渐衰减的，所以中间项对词频进行了惩罚，随着次数的增加，影响程度的增加会越来越小。通过设置k值，能够保证其最大值为k+1，<code>k往往取值1.2</code>。</p>
<p>其变化如下图（无论k为多少，中间项的变化程度会随着次数的增加，越来越小）：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bm25.png" srcset="/img/loading.gif" lazyload></p>
<p>同时$1-b+b\frac{d}{avdl}$的作用是用来对文本的长度进行归一化。</p>
<p>例如在考虑整个句子的tdidf的时候，如果句子的长度太短，那么计算的总的tdidf的值是要比长句子的tdidf的值要低的。所以可以考虑对句子的长度进行归一化处理。</p>
<p>可以看到，当句子的长度越短，$1-b+b\frac{|d|}{avdl}$的值是越小，作为分母的位置，会让整个第二项越大，从而达到提高短文本句子的BM25的值的效果。当b的值为0，可以禁用归一化，<code>b往往取值0.75</code></p>
<p>其变化效果如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/bm25_2.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="2-2-BM25算法实现"><a href="#2-2-BM25算法实现" class="headerlink" title="2.2 BM25算法实现"></a>2.2 BM25算法实现</h3><p>通过前面的学习，我们知道其实BM25和Tfidf的区别不大，所以我们可以在之前sciket-learn的TfidfVectorizer基础上进行修改，获取我们的BM25的计算结果，主要也是修改其中的<code>fit</code>方法和<code>transform</code>方法</p>
<p>在sklearn的<code>TfidfVectorizer中</code>，首先接受参数，其次会调用<code>TfidfTransformer</code>来完成其他方法的调用</p>
<ol>
<li><p>继承TfidfVectorizer完成 参数的接受</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer,TfidfTransformer,_document_frequency<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator,TransformerMixin<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> normalize<br><span class="hljs-keyword">from</span> sklearn.utils.validation <span class="hljs-keyword">import</span> check_is_fitted<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> scipy.sparse <span class="hljs-keyword">as</span> sp<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bm25Vectorizer</span>(<span class="hljs-title class_ inherited__">CountVectorizer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,k=<span class="hljs-number">1.2</span>,b=<span class="hljs-number">0.75</span>, norm=<span class="hljs-string">&quot;l2&quot;</span>, use_idf=<span class="hljs-literal">True</span>, smooth_idf=<span class="hljs-literal">True</span>,sublinear_tf=<span class="hljs-literal">False</span>,*args,**kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Bm25Vectorizer,self).__init__(*args,**kwargs)<br>        self._tfidf = Bm25Transformer(k=k,b=b,norm=norm, use_idf=use_idf,<br>                                       smooth_idf=smooth_idf,<br>                                       sublinear_tf=sublinear_tf)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">k</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self._tfidf.k<br><br><span class="hljs-meta">    @k.setter</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">k</span>(<span class="hljs-params">self, value</span>):<br>        self._tfidf.k = value<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">b</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self._tfidf.b<br><br><span class="hljs-meta">    @b.setter</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">b</span>(<span class="hljs-params">self, value</span>):<br>        self._tfidf.b = value<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, raw_documents, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Learn vocabulary and idf from training set.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        X = <span class="hljs-built_in">super</span>(Bm25Vectorizer, self).fit_transform(raw_documents)<br>        self._tfidf.fit(X)<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit_transform</span>(<span class="hljs-params">self, raw_documents, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Learn vocabulary and idf, return term-document matrix.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        X = <span class="hljs-built_in">super</span>(Bm25Vectorizer, self).fit_transform(raw_documents)<br>        self._tfidf.fit(X)<br>        <span class="hljs-keyword">return</span> self._tfidf.transform(X, copy=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self, raw_documents, copy=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Transform documents to document-term matrix.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        check_is_fitted(self, <span class="hljs-string">&#x27;_tfidf&#x27;</span>, <span class="hljs-string">&#x27;The tfidf vector is not fitted&#x27;</span>)<br><br>        X = <span class="hljs-built_in">super</span>(Bm25Vectorizer, self).transform(raw_documents)<br>        <span class="hljs-keyword">return</span> self._tfidf.transform(X, copy=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>


</li>
<li><p>完成自己的<code>Bm25transformer</code>,只需要再原来基础的代码上进心修改部分即可。sklearn中的转换器类的实现要求，不能直接继承已有的转换器类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bm25Transformer</span>(BaseEstimator, TransformerMixin):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,k=<span class="hljs-number">1.2</span>,b=<span class="hljs-number">0.75</span>, norm=<span class="hljs-string">&#x27;l2&#x27;</span>, use_idf=<span class="hljs-literal">True</span>, smooth_idf=<span class="hljs-literal">True</span>,</span><br><span class="hljs-params">                 sublinear_tf=<span class="hljs-literal">False</span></span>):<br>        self.k = k<br>        self.b = b<br>        <span class="hljs-comment">##################以下是TFIDFtransform代码##########################</span><br>        self.norm = norm<br>        self.use_idf = use_idf<br>        self.smooth_idf = smooth_idf<br>        self.sublinear_tf = sublinear_tf<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Learn the idf vector (global term weights)</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Parameters</span><br><span class="hljs-string">        ----------</span><br><span class="hljs-string">        X : sparse matrix, [n_samples, n_features]</span><br><span class="hljs-string">            a matrix of term/token counts</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        _X = X.toarray()<br>        self.avdl = _X.<span class="hljs-built_in">sum</span>()/_X.shape[<span class="hljs-number">0</span>] <span class="hljs-comment">#句子的平均长度</span><br>        <span class="hljs-comment"># print(&quot;原来的fit的数据：\n&quot;,X)</span><br><br>        <span class="hljs-comment">#计算每个词语的tf的值</span><br>        self.tf = _X.<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>)/_X.<span class="hljs-built_in">sum</span>()  <span class="hljs-comment">#[M] #M表示总词语的数量</span><br>        self.tf = self.tf.reshape([<span class="hljs-number">1</span>,self.tf.shape[<span class="hljs-number">0</span>]]) <span class="hljs-comment">#[1,M]</span><br>        <span class="hljs-comment"># print(&quot;tf\n&quot;,self.tf)</span><br>        <span class="hljs-comment">##################以下是TFIDFtransform代码##########################</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> sp.issparse(X):<br>            X = sp.csc_matrix(X)<br>        <span class="hljs-keyword">if</span> self.use_idf:<br>            n_samples, n_features = X.shape<br>            df = _document_frequency(X)<br><br>            <span class="hljs-comment"># perform idf smoothing if required</span><br>            df += <span class="hljs-built_in">int</span>(self.smooth_idf)<br>            n_samples += <span class="hljs-built_in">int</span>(self.smooth_idf)<br><br>            <span class="hljs-comment"># log+1 instead of log makes sure terms with zero idf don&#x27;t get</span><br>            <span class="hljs-comment"># suppressed entirely.</span><br>            idf = np.log(<span class="hljs-built_in">float</span>(n_samples) / df) + <span class="hljs-number">1.0</span><br>            self._idf_diag = sp.spdiags(idf, diags=<span class="hljs-number">0</span>, m=n_features,<br>                                        n=n_features, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;csr&#x27;</span>)<br><br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self, X, copy=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Transform a count matrix to a tf or tf-idf representation</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Parameters</span><br><span class="hljs-string">        ----------</span><br><span class="hljs-string">        X : sparse matrix, [n_samples, n_features]</span><br><span class="hljs-string">            a matrix of term/token counts</span><br><span class="hljs-string"></span><br><span class="hljs-string">        copy : boolean, default True</span><br><span class="hljs-string">            Whether to copy X and operate on the copy or perform in-place</span><br><span class="hljs-string">            operations.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns</span><br><span class="hljs-string">        -------</span><br><span class="hljs-string">        vectors : sparse matrix, [n_samples, n_features]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br> 		<span class="hljs-comment">########### 计算中间项  ###############</span><br>        cur_tf = np.multiply(self.tf, X.toarray()) <span class="hljs-comment">#[N,M] #N表示数据的条数，M表示总词语的数量</span><br>        norm_lenght = <span class="hljs-number">1</span> - self.b + self.b*(X.toarray().<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>)/self.avdl) <span class="hljs-comment">#[N] #N表示数据的条数</span><br>        norm_lenght = norm_lenght.reshape([norm_lenght.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>]) <span class="hljs-comment">#[N,1]</span><br>        middle_part = (self.k+<span class="hljs-number">1</span>)*cur_tf /(cur_tf +self.k*norm_lenght)<br>        <span class="hljs-comment">############# 结算结束  ################</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(X, <span class="hljs-string">&#x27;dtype&#x27;</span>) <span class="hljs-keyword">and</span> np.issubdtype(X.dtype, np.floating):<br>            <span class="hljs-comment"># preserve float family dtype</span><br>            X = sp.csr_matrix(X, copy=copy)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># convert counts or binary occurrences to floats</span><br>            X = sp.csr_matrix(X, dtype=np.float64, copy=copy)<br><br>        n_samples, n_features = X.shape<br><br>        <span class="hljs-keyword">if</span> self.sublinear_tf:<br>            np.log(X.data, X.data)<br>            X.data += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> self.use_idf:<br>            check_is_fitted(self, <span class="hljs-string">&#x27;_idf_diag&#x27;</span>, <span class="hljs-string">&#x27;idf vector is not fitted&#x27;</span>)<br><br>            expected_n_features = self._idf_diag.shape[<span class="hljs-number">0</span>]<br>            <span class="hljs-keyword">if</span> n_features != expected_n_features:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Input has n_features=%d while the model&quot;</span><br>                                 <span class="hljs-string">&quot; has been trained with n_features=%d&quot;</span> % (<br>                                     n_features, expected_n_features))<br>            <span class="hljs-comment"># *= doesn&#x27;t work</span><br>            X = X * self._idf_diag<br>		<br>        <span class="hljs-comment">############# 中间项和结果相乘  ############</span><br>        X = X.toarray()*middle_part<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> sp.issparse(X):<br>            X = sp.csr_matrix(X, dtype=np.float64)<br>        <span class="hljs-comment">############# #########</span><br>        <br>        <span class="hljs-keyword">if</span> self.norm:<br>            X = normalize(X, norm=self.norm, copy=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-keyword">return</span> X<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">idf_</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment">##################以下是TFIDFtransform代码##########################</span><br>        <span class="hljs-comment"># if _idf_diag is not set, this will raise an attribute error,</span><br>        <span class="hljs-comment"># which means hasattr(self, &quot;idf_&quot;) is False</span><br>        <span class="hljs-keyword">return</span> np.ravel(self._idf_diag.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>))<br><br></code></pre></td></tr></table></figure>

<p>完整代码参考：<code>https://github.com/SpringMagnolia/Bm25Vectorzier/blob/master/BM25Vectorizer.py</code></p>
</li>
<li><p>测试简单使用，观察和tdidf的区别：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> BM25Vectorizer <span class="hljs-keyword">import</span> Bm25Vectorizer<br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># format_weibo(word=False)</span><br>    <span class="hljs-comment"># format_xiaohuangji_corpus(word=True)</span><br>    bm_vec = Bm25Vectorizer()<br>    tf_vec = TfidfVectorizer()<br>    <span class="hljs-comment"># 1. 原始数据</span><br>    data = [<br>        <span class="hljs-string">&#x27;hello world&#x27;</span>,<br>        <span class="hljs-string">&#x27;oh hello there&#x27;</span>,<br>        <span class="hljs-string">&#x27;Play it&#x27;</span>,<br>        <span class="hljs-string">&#x27;Play it again Sam,24343,123&#x27;</span>,<br>    ]<br><br>    <span class="hljs-comment"># 2. 原始数据向量化</span><br>    bm_vec.fit(data)<br>    tf_vec.fit(data)<br>    features_vec_bm = bm_vec.transform(data)<br>    features_vec_tf = tf_vec.transform(data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Bm25 result:&quot;</span>,features_vec_bm.toarray())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;*&quot;</span>*<span class="hljs-number">100</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Tfidf result:&quot;</span>,features_vec_tf.toarray())<br></code></pre></td></tr></table></figure>



<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">Bm25 result: [[<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.47878333</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.8779331</span> ]<br> [<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.35073401</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.66218791</span><br>  <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.66218791</span> <span class="hljs-number">0.</span>        ]<br> [<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.70710678</span> <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.70710678</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>        ]<br> [<span class="hljs-number">0.47038081</span> <span class="hljs-number">0.47038081</span> <span class="hljs-number">0.47038081</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.23975776</span> <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.23975776</span> <span class="hljs-number">0.47038081</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>        ]]<br>**********************************************************************************<br>Tfidf result: [[<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.6191303</span>  <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.78528828</span>]<br> [<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.48693426</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.61761437</span><br>  <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.61761437</span> <span class="hljs-number">0.</span>        ]<br> [<span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.70710678</span> <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.70710678</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>        ]<br> [<span class="hljs-number">0.43671931</span> <span class="hljs-number">0.43671931</span> <span class="hljs-number">0.43671931</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.34431452</span> <span class="hljs-number">0.</span><br>  <span class="hljs-number">0.34431452</span> <span class="hljs-number">0.43671931</span> <span class="hljs-number">0.</span>         <span class="hljs-number">0.</span>        ]]<br><br></code></pre></td></tr></table></figure>

<h3 id="2-3-修改之前的召回代码"><a href="#2-3-修改之前的召回代码" class="headerlink" title="2.3 修改之前的召回代码"></a>2.3 修改之前的召回代码</h3><p>修改之前召回的代码只需要把调用tfidfvectorizer改成调用Bm25vectorizer</p>
</li>
</ol>
<h2 id="3-使用Fasttext实现获取句子向量"><a href="#3-使用Fasttext实现获取句子向量" class="headerlink" title="3. 使用Fasttext实现获取句子向量"></a>3. 使用Fasttext实现获取句子向量</h2><h3 id="3-1-基础方法介绍"><a href="#3-1-基础方法介绍" class="headerlink" title="3.1 基础方法介绍"></a>3.1 基础方法介绍</h3><p>这里我们可以使用fasttext，word2vector等方式实现获取词向量，然后对一个句子中的所有词语的词向量进行平均，获取整个句子的向量表示，即<code>sentence Vector</code>，该实现方法在fasttext和Word2vector中均有实现，而且通过参数的控制，实现N-garm的效果</p>
<p>假设我们有文本<code>a.txt</code>如下：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">我 很 喜欢 她 <br>今天 天气 不错<br>我 爱 深度学习<br></code></pre></td></tr></table></figure>


<p>那么我们可以实现获取句子向量的方法如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastText <span class="hljs-keyword">import</span> FastText<br><span class="hljs-comment">#训练模型，设置n-garm=2</span><br>model = FastText.train_unsupervised(<span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;./a.txt&quot;</span>,minCount=<span class="hljs-number">1</span>,wordNgrams=<span class="hljs-number">2</span>)<br><span class="hljs-comment">#获取句子向量，是对词向量的平均</span><br>model.get_sentence_vector(<span class="hljs-string">&quot;我 是 谁&quot;</span>)<br></code></pre></td></tr></table></figure>



<h3 id="3-2-训练模型和封装代码"><a href="#3-2-训练模型和封装代码" class="headerlink" title="3.2 训练模型和封装代码"></a>3.2 训练模型和封装代码</h3><p>这里我们使用之前采集的相似文本数据作为训练样本</p>
<p>步骤如下：</p>
<ol>
<li>进行分词之后写入文件中</li>
<li>进行模型的训练</li>
<li>使用模型获取句子向量，并且封装代码</li>
<li>将之前的BM25的代码替换为该代码</li>
</ol>
<h4 id="3-2-1-分词写入文件"><a href="#3-2-1-分词写入文件" class="headerlink" title="3.2.1 分词写入文件"></a>3.2.1 分词写入文件</h4><p>这里我们使用单个字作为特征，只需要注意，英文使用单个词作为特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">使用单个字作为特征，进行fasttext训练，最后封装代码获取召回结果</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> string<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">word_split</span>(<span class="hljs-params">line</span>):<br>    <span class="hljs-comment">#对中文按照字进行处理，对英文不分为字母</span><br>    <span class="hljs-comment">#即 I爱python --&gt; i 爱 python</span><br>    letters = string.ascii_lowercase+<span class="hljs-string">&quot;+&quot;</span>+<span class="hljs-string">&quot;/&quot;</span>  <span class="hljs-comment">#c++,ui/ue</span><br>    result = []<br>    temp = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> line:<br>        <span class="hljs-keyword">if</span> word.lower() <span class="hljs-keyword">in</span> letters:<br>            temp+=word.lower()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> temp !=<span class="hljs-string">&quot;&quot;</span>:<br>                result.append(temp)<br>                temp = <span class="hljs-string">&quot;&quot;</span><br>            result.append(word)<br>    <span class="hljs-keyword">if</span> temp!=<span class="hljs-string">&quot;&quot;</span>:<br>        result.append(temp)<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_data</span>():<br>    path1 = <span class="hljs-string">r&quot;corpus\final_data\merged_q.txt&quot;</span><br>    path2 = <span class="hljs-string">r&quot;corpus\final_data\merged_sim_q.txt&quot;</span><br>    save_path =  <span class="hljs-string">r&quot;corpus\recall_fasttext_data\data.txt&quot;</span><br><br>    <span class="hljs-built_in">filter</span> = <span class="hljs-built_in">set</span>()<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path1) <span class="hljs-keyword">as</span> f,<span class="hljs-built_in">open</span>(save_path,<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> save_f:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>            line = line.strip()<br>            <span class="hljs-keyword">if</span> line <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>:<br>                <span class="hljs-built_in">filter</span>.add(line)<br>                _temp = <span class="hljs-string">&quot; &quot;</span>.join(word_split(line))<br>                save_f.write(_temp+<span class="hljs-string">&quot;\n&quot;</span>)<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path2) <span class="hljs-keyword">as</span> f,<span class="hljs-built_in">open</span>(save_path,<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> save_f:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>            line = line.strip()<br>            <span class="hljs-keyword">if</span> line <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>:<br>                <span class="hljs-built_in">filter</span>.add(line)<br>                _temp = <span class="hljs-string">&quot; &quot;</span>.join(word_split(line))<br>                save_f.write(_temp+<span class="hljs-string">&quot;\n&quot;</span>)<br></code></pre></td></tr></table></figure>



<h4 id="3-2-2-训练模型"><a href="#3-2-2-训练模型" class="headerlink" title="3.2.2 训练模型"></a>3.2.2 训练模型</h4><ol>
<li><p>训练fasttext的model,用来生成词向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">fasttext_model_path</span>):<br> logging.basicConfig(<span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)<br> save_path =  <span class="hljs-string">r&quot;corpus\recall_fasttext_data\data.txt&quot;</span><br><br> model = FastText.train_unsupervised(save_path,epoch=<span class="hljs-number">20</span>,minCount=<span class="hljs-number">3</span>,wordNgrams=<span class="hljs-number">2</span>)<br> model.save_model(fasttext_model_path)<br></code></pre></td></tr></table></figure>
</li>
<li><p>对现有的QA问答对，生成向量，传入pysparnn中构建索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_base_text_vectors</span>(<span class="hljs-params">cp_dump_path,model</span>):<br>    <span class="hljs-comment">#保存到本地pkl文件，防止每次都生成一次</span><br>    <span class="hljs-keyword">if</span> os.path.exists(cp_dump_path):<br>        cp = pickle.load(<span class="hljs-built_in">open</span>(cp_dump_path,<span class="hljs-string">&quot;rb&quot;</span>))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(QA_dict)<br>        q_lines = [q <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> QA_dict]<br>        q_cuted_list = [<span class="hljs-string">&quot; &quot;</span>.join(word_split(i)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> q_lines]<br>        lines_vectors = []<br>        <span class="hljs-keyword">for</span> q_cuted <span class="hljs-keyword">in</span> q_cuted_list:<br>            lines_vectors.append(model.get_sentence_vector(q_cuted))<br>        cp = ci.MultiClusterIndex(lines_vectors,q_lines)<br>        pickle.dump(cp,<span class="hljs-built_in">open</span>(cp_dump_path,<span class="hljs-string">&quot;wb&quot;</span>))<br>    <span class="hljs-keyword">return</span> cp<br></code></pre></td></tr></table></figure>
</li>
<li><p>传入用户的问题，进行分词和句子向量的获取，获取搜索的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_search_vectors</span>(<span class="hljs-params">cp,model,search_line</span>):<br>    line_cuted = <span class="hljs-string">&quot; &quot;</span>.join(word_split(search_line))<br>    line_vec = model.get_sentence_vector(line_cuted)<br>    <span class="hljs-comment">#这里的line_vec中可以有多个句子的向量表示，能够返回每个句子的搜索结果</span><br>    cp_search_list = cp.search(line_vec,k=<span class="hljs-number">10</span>,k_clusters=<span class="hljs-number">10</span>,return_distance=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment">#TODO 对搜索的结果进行关键字的过滤</span><br>    <span class="hljs-keyword">return</span> cp_search_list<br></code></pre></td></tr></table></figure>


</li>
<li><p>测试模型的效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastext_vectors <span class="hljs-keyword">import</span> get_search_vectors,train_model,get_base_text_vectors<br><span class="hljs-keyword">import</span> fastText<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    fasttext_model_path = <span class="hljs-string">&quot;corpus/build_questions/fasttext_recall.model&quot;</span><br>    cp_dump_path = <span class="hljs-string">&quot;corpus/build_questions/cp_recall.pkl&quot;</span><br>    <br>    <span class="hljs-comment"># train_model(fasttext_model_path)</span><br>    <br>    model = fastText.load_model(fasttext_model_path)<br><br>    cp = get_base_text_vectors(cp_dump_path,model)<br><br>    ret = get_search_vectors(cp,model,<span class="hljs-string">&quot;女孩学python容易么？&quot;</span>)<br>    <span class="hljs-built_in">print</span>(ret)<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">[[(<span class="hljs-string">&#x27;0.0890376&#x27;</span>, <span class="hljs-string">&#x27;学习Python需要什么基础，学起来更容易？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.090688944&#x27;</span>, <span class="hljs-string">&#x27;学习PHP的女生多吗？女生可以学吗？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.092773676&#x27;</span>, <span class="hljs-string">&#x27;Python适合什么人学习？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.09416294&#x27;</span>, <span class="hljs-string">&#x27;Python语言适合什么样的人学？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.102790296&#x27;</span>, <span class="hljs-string">&#x27;python语言容易学习吗？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.1050359&#x27;</span>, <span class="hljs-string">&#x27;学习测试的女生多吗？女生可以学吗？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.10546541&#x27;</span>, <span class="hljs-string">&#x27;Python好学吗？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.11058545&#x27;</span>, <span class="hljs-string">&#x27;学习Python怎样？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.11080605&#x27;</span>, <span class="hljs-string">&#x27;怎样学好Python？&#x27;</span>), <br>  (<span class="hljs-string">&#x27;0.11124289&#x27;</span>, <span class="hljs-string">&#x27;学生怎么上课的？&#x27;</span>)]]<br></code></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-2-3-基础封装"><a href="#3-2-3-基础封装" class="headerlink" title="3.2.3  基础封装"></a>3.2.3  基础封装</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#lib/SentenceVectorizer</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">使用fasttext 实现sentence to vector</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> fastText<br><span class="hljs-keyword">from</span> fastText <span class="hljs-keyword">import</span> FastText<br><span class="hljs-keyword">import</span> config<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> cut<br><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SentenceVectorizer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">if</span> os.path.exists(config.recall_fasttext_model_path):<br>            self.model = fastText.load_model(config.recall_fasttext_model_path)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># self.process_data()</span><br>            self.model = self.build_model()<br><br>        self.fited = <span class="hljs-literal">False</span><br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit_transform</span>(<span class="hljs-params">self,sentences</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;处理全部问题数据&quot;&quot;&quot;</span><br>        lines_vectors = self.fit(sentences)<br>        <span class="hljs-keyword">return</span> lines_vectors<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self,lines</span>):<br>        lines_vectors = []<br>        <span class="hljs-keyword">for</span> q_cuted <span class="hljs-keyword">in</span> lines:<br>            lines_vectors.append(self.model.get_sentence_vector(q_cuted))<br>        self.fited = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">return</span> lines_vectors<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">self,sentence</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;处理用户输入的数据&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> self.fited = <span class="hljs-literal">True</span><br>        line_vec = self.model.get_sentence_vector(<span class="hljs-string">&quot; &quot;</span>.join(sentence))<br>        <span class="hljs-keyword">return</span> line_vec<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_model</span>(<span class="hljs-params">self</span>):<br>        logging.basicConfig(<span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)<br>        model = FastText.train_unsupervised(config.recall_fasttext_data_path, epoch=<span class="hljs-number">20</span>, minCount=<span class="hljs-number">3</span>, wordNgrams=<span class="hljs-number">2</span>)<br>        model.save_model(config.recall_fasttext_model_path)<br>        <span class="hljs-keyword">return</span> model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">process_data</span>(<span class="hljs-params">self</span>):<br>        path1 = <span class="hljs-string">r&quot;corpus\final_data\merged_q.txt&quot;</span><br>    	path2 = <span class="hljs-string">r&quot;corpus\final_data\merged_sim_q.txt&quot;</span><br>    	save_path =  <span class="hljs-string">r&quot;corpus\recall_fasttext_data\data.txt&quot;</span><br><br>        <span class="hljs-built_in">filter</span> = <span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path1) <span class="hljs-keyword">as</span> f, <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> save_f:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>                line = line.strip()<br>                <span class="hljs-keyword">if</span> line <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>:<br>                    <span class="hljs-built_in">filter</span>.add(line)<br>                    _temp = <span class="hljs-string">&quot; &quot;</span>.join(cut(line,by_word=<span class="hljs-literal">True</span>))<br>                    save_f.write(_temp + <span class="hljs-string">&quot;\n&quot;</span>)<br><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path2) <span class="hljs-keyword">as</span> f, <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> save_f:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>                line = line.strip()<br>                <span class="hljs-keyword">if</span> line <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>:<br>                    <span class="hljs-built_in">filter</span>.add(line)<br>                    _temp = <span class="hljs-string">&quot; &quot;</span>.join(cut(line,by_word=<span class="hljs-literal">True</span>))<br>                    save_f.write(_temp + <span class="hljs-string">&quot;\n&quot;</span>)<br><br></code></pre></td></tr></table></figure>

<h1 id="问答机器人排序模型"><a href="#问答机器人排序模型" class="headerlink" title="问答机器人排序模型"></a>问答机器人排序模型</h1><h2 id="目标-29"><a href="#目标-29" class="headerlink" title="目标"></a>目标</h2><ol>
<li>知道模型中排序中的概念和目的</li>
<li>知道模型中排序的实现方法</li>
</ol>
<h2 id="1-排序模型的介绍"><a href="#1-排序模型的介绍" class="headerlink" title="1. 排序模型的介绍"></a>1. 排序模型的介绍</h2><p>前面的课程中为了完成一个问答机器人，我们先进行了召回，相当于是通过海选的方法找到呢大致相似的问题。</p>
<p>通过现在的排序模型，我们需要精选出最相似的哪一个问题，返回对应的答案</p>
<h2 id="2-排序模型的实现思路"><a href="#2-排序模型的实现思路" class="headerlink" title="2. 排序模型的实现思路"></a>2. 排序模型的实现思路</h2><p>我们需要实现的排序模型是两个输入，即两个问题，输出的是一个相似度。所以和之前的深度学习模型一样，我们需要实现的步骤如下：</p>
<ol>
<li>准备数据</li>
<li>构建模型</li>
<li>模型评估</li>
<li>对外提供接口返回结果</li>
</ol>
<h3 id="2-1-准备数据"><a href="#2-1-准备数据" class="headerlink" title="2.1 准备数据"></a>2.1 准备数据</h3><p>这里的数据，我们使用之前采集的百度问答的相似问题和手动构造的数据。那么，我们需要把他格式化为最终模型需要的格式，即两个输入和输出的相似度。</p>
<h4 id="2-1-1-两个输入"><a href="#2-1-1-两个输入" class="headerlink" title="2.1.1 两个输入"></a>2.1.1 两个输入</h4><p>这里的输入，我们可以使用单个字作为特征，也可以使用一个分词之后的词语作为特征。所以在实现准备输入数据方法的过程中，可以提前准备。</p>
<h4 id="2-1-2-相似度准备"><a href="#2-1-2-相似度准备" class="headerlink" title="2.1.2 相似度准备"></a>2.1.2 相似度准备</h4><p>这里我们使用每个问题搜索结果的前两页认为他们是相似的，相似度为1，最后两页的结果是不相似的，相似度为0。</p>
<h3 id="2-2-构建模型"><a href="#2-2-构建模型" class="headerlink" title="2.2 构建模型"></a>2.2 构建模型</h3><p>介绍模型的构建之前，我们先介绍下孪生神经网络(Siamese Network)和其名字的由来。</p>
<p>Siamese和Chinese有点像。Siamese是古时候泰国的称呼，中文译作暹罗。Siamese在英语中是“孪生”、“连体”的意思。为什么孪生和泰国有关系呢？</p>
<blockquote>
<p>十九世纪泰国出生了一对连体婴儿，当时的医学技术无法使两人分离出来，于是两人顽强地生活了一生，1829年被英国商人发现，进入马戏团，在全世界各地表演，1839年他们访问美国北卡罗莱那州后来成为马戏团的台柱，最后成为美国公民。1843年4月13日跟英国一对姐妹结婚，恩生了10个小孩，昌生了12个，姐妹吵架时，兄弟就要轮流到每个老婆家住三天。1874年恩因肺病去世，另一位不久也去世，两人均于63岁离开人间。两人的肝至今仍保存在费城的马特博物馆内。从此之后“暹罗双胞胎”（Siamese twins）就成了连体人的代名词，也因为这对双胞胎让全世界都重视到这项特殊疾病。</p>
</blockquote>
<p>所以孪生神经网络就是有两个共享权值的网络的组成，或者只用实现一个，另一个直接调用，有两个输入，一个输出。1993年就已经被用来进行支票签名的验证。</p>
<p>孪生神经网络通过两个输入，被DNN进行编码，得到向量的表示之后，根据实际的用途来制定损失函数。比如我们需要计算相似度的时候，可以使用余弦相似度，或者使用$exp^{-||h^{left}-h^{right}||}$来确定向量的距离。</p>
<p>孪生神经网络被用于有多个输入和一个输出的场景，比如手写字体识别、文本相似度检验、人脸识别等</p>
<p>在计算相似度之前，我们可以考虑在传统的孪生神经网络的基础上，在计算相似度之前，把我们的编码之后的向量通过多层神经网络进行非线性的变化，结果往往会更加好，那么此时其网络结构大致如下：</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/deepqa.png" srcset="/img/loading.gif" lazyload></p>
<p>其中Network1和network2为权重参数共享的两个形状相同的网络，用来对输入的数据进行编码，包括（<code>word-embedding,GRU,biGRU等</code>），Network3部分是一个深层的神经网络，包含（<code>batchnorm、dropout、relu、Linear</code>等层）</p>
<h3 id="2-3-模型的评估"><a href="#2-3-模型的评估" class="headerlink" title="2.3 模型的评估"></a>2.3 模型的评估</h3><p>编写预测和评估的代码，预测的过程只需要修改获得结果，不需要上图中的损失计算的过程</p>
<h2 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3. 代码实现"></a>3. 代码实现</h2><h3 id="3-1-数据准备-1"><a href="#3-1-数据准备-1" class="headerlink" title="3.1 数据准备"></a>3.1 数据准备</h3><h5 id="3-1-1-对文本进行分词分开存储"><a href="#3-1-1-对文本进行分词分开存储" class="headerlink" title="3.1.1 对文本进行分词分开存储"></a>3.1.1 对文本进行分词分开存储</h5><p>这里的分词可以对之前的分词方法进行修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cut_sentence_by_word</span>(<span class="hljs-params">sentence</span>):<br>    <span class="hljs-comment"># 对中文按照字进行处理，对英文不分为字母</span><br>    letters = string.ascii_lowercase + <span class="hljs-string">&quot;+&quot;</span> + <span class="hljs-string">&quot;/&quot;</span>  <span class="hljs-comment"># c++,ui/ue</span><br>    result = []<br>    temp = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> line:<br>        <span class="hljs-keyword">if</span> word.lower() <span class="hljs-keyword">in</span> letters:<br>            temp += word.lower()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>:<br>                result.append(temp)<br>                temp = <span class="hljs-string">&quot;&quot;</span><br>            result.append(word)<br>    <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&quot;&quot;</span>:<br>        result.append(temp)<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">jieba_cut</span>(<span class="hljs-params">sentence,by_word=<span class="hljs-literal">False</span>,with_sg=<span class="hljs-literal">False</span>,use_stopwords=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">if</span> by_word:<br>        <span class="hljs-keyword">return</span> cut_sentence_by_word(sentence)<br>    ret = psg.lcut(sentence)<br>    <span class="hljs-keyword">if</span> use_stopwords:<br>        ret = [(i.word, i.flag) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ret <span class="hljs-keyword">if</span> i.word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords_list]<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> with_sg:<br>        ret = [i[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ret]<br>    <span class="hljs-keyword">return</span> ret<br></code></pre></td></tr></table></figure>

<h5 id="3-1-2-准备word-Sequence代码"><a href="#3-1-2-准备word-Sequence代码" class="headerlink" title="3.1.2 准备word Sequence代码"></a>3.1.2 准备<code>word Sequence</code>代码</h5><p>该处的代码和seq2seq中的代码相同，直接使用</p>
<h5 id="3-1-3-准备Dataset和DataLoader"><a href="#3-1-3-准备Dataset和DataLoader" class="headerlink" title="3.1.3 准备Dataset和DataLoader"></a>3.1.3 准备<code>Dataset</code>和<code>DataLoader</code></h5><p>和seq2seq中的代码大致相同</p>
<h3 id="3-2-模型的搭建"><a href="#3-2-模型的搭建" class="headerlink" title="3.2 模型的搭建"></a>3.2 模型的搭建</h3><p>前面做好了准备工作之后，就需要开始进行模型的搭建。</p>
<p>虽然我们知道了整个结构的大致情况，但是我们还是不知道其中具体的细节。</p>
<p>2016年<code>AAAI</code>会议上，有一篇<code>Siamese Recurrent Architectures for Learning Sentence Similarity</code>的论文（地址：<a target="_blank" rel="noopener" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12195/12023%EF%BC%89%E3%80%82%E6%95%B4%E4%B8%AA%E7%BB%93%E6%9E%84%E5%A6%82%E4%B8%8B%E5%9B%BE%EF%BC%9A">https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12195/12023）。整个结构如下图：</a></p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AAAI.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看到word 经过embedding之后进行LSTM的处理，然后经过exp来确定相似度，可以看到整个模型是非常简单的，之后很多人在这个结构上增加了更多的层，比如加入attention、dropout、pooling等层。</p>
<p>那么这个时候，请思考下面几个问题：</p>
<ol>
<li><p>attention在这个网络结构中该如何实现</p>
<ul>
<li><p>之前我们的attention是用在decoder中，让decoder的hidden和encoder的output进行运算，得到attention的weight，再和decoder的output进行计算，作为下一次decoder的输入</p>
</li>
<li><p>那么在当前我们可以把<code>句子A的output理解为句子B的encoder的output</code>，那么我们就可以进行attention的计算了</p>
<blockquote>
<p>和这个非常相似的有一个attention的变种，叫做<code>self attention</code>。前面所讲的Attention是基于source端和target端的隐变量（hidden state）计算Attention的，得到的结果是源端的每个词与目标端每个词之间的依赖关系。<code>Self Attention</code>不同，它分别在source端和target端进行，仅与source input或者target input自身相关的Self Attention，捕捉source端或target端自身的词与词之间的依赖关系。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>dropout用在什么地方</p>
<ul>
<li>dropout可以用在很多地方，比如embedding之后</li>
<li>BiGRU结构中</li>
<li>或者是相似度计算之前</li>
</ul>
</li>
<li><p>pooling是什么如何使用</p>
<ul>
<li>pooling叫做池化，是一种降采样的技术，用来减少特征(feature)的数量。常用的方法有<code>max pooling</code> 或者是<code>average pooling</code></li>
</ul>
</li>
</ol>
<h4 id="3-2-1-编码部分"><a href="#3-2-1-编码部分" class="headerlink" title="3.2.1 编码部分"></a>3.2.1 编码部分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python">  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *<span class="hljs-built_in">input</span></span>):<br>      <br>      sent1, sent2 = <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">input</span>[<span class="hljs-number">1</span>]<br>      <span class="hljs-comment">#这里使用mask，在后面计算attention的时候，让其忽略pad的位置</span><br>      mask1, mask2 = sent1.eq(<span class="hljs-number">0</span>), sent2.eq(<span class="hljs-number">0</span>)<br><br>      <span class="hljs-comment"># embeds: batch_size * seq_len =&gt; batch_size * seq_len * batch_size</span><br>      x1 = self.embeds(sent1)<br>      x2 = self.embeds(sent2)<br><br>      <span class="hljs-comment"># batch_size * seq_len * dim =&gt; batch_size * seq_len * hidden_size</span><br>      output1, _ = self.lstm1(x1)<br>      output2, _ = self.lstm1(x2)<br><br>      <span class="hljs-comment"># 进行Attention的操作，同时进行形状的对齐</span><br>      <span class="hljs-comment"># batch_size * seq_len * hidden_size</span><br>      q1_align, q2_align = self.soft_attention_align(output1, output2, mask1, mask2)<br><br>      <span class="hljs-comment"># 拼接之后再传入LSTM中进行处理</span><br>      <span class="hljs-comment"># batch_size * seq_len * (8 * hidden_size)</span><br>      q1_combined = torch.cat([output1, q1_align, self.submul(output1, q1_align)], -<span class="hljs-number">1</span>)<br>      q2_combined = torch.cat([output2, q2_align, self.submul(output2, q2_align)], -<span class="hljs-number">1</span>)<br><br>      <span class="hljs-comment"># batch_size * seq_len * (2 * hidden_size)</span><br>      q1_compose, _ = self.lstm2(q1_combined)<br>      q2_compose, _ = self.lstm2(q2_combined)<br><br>      <span class="hljs-comment"># 进行Aggregate操作，也就是进行pooling</span><br>      <span class="hljs-comment"># input: batch_size * seq_len * (2 * hidden_size)</span><br>      <span class="hljs-comment"># output: batch_size * (4 * hidden_size)</span><br>      q1_rep = self.apply_pooling(q1_compose)<br>      q2_rep = self.apply_pooling(q2_compose)<br><br><span class="hljs-comment"># Concate合并到一起，用来进行计算相似度</span><br>      x = torch.cat([q1_rep, q2_rep], -<span class="hljs-number">1</span>)<br>      <br> <span class="hljs-keyword">def</span> <span class="hljs-title function_">submul</span>(<span class="hljs-params">self,x1,x2</span>):<br>      mul = x1 * x2<br>      sub = x1 - x2<br>      <span class="hljs-keyword">return</span> torch.cat([sub,mul],dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h5 id="atttention的计算"><a href="#atttention的计算" class="headerlink" title="atttention的计算"></a>atttention的计算</h5><p>实现思路：</p>
<ol>
<li>先获取attention_weight</li>
<li>在使用attention_weight和encoder_output进行相乘</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">soft_attention_align</span>(<span class="hljs-params">self, x1, x2, mask1, mask2</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    x1: batch_size * seq_len_1 * hidden_size</span><br><span class="hljs-string">    x2: batch_size * seq_len_2 * hidden_size</span><br><span class="hljs-string">    mask1:x1中pad的位置为1，其他为0</span><br><span class="hljs-string">    mask2:x2中pad 的位置为1，其他为0</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># attention: batch_size * seq_len_1 * seq_len_2</span><br>    attention_weight = torch.matmul(x1, x2.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    <span class="hljs-comment">#mask1 : batch_size,seq_len1</span><br>    mask1 = mask1.<span class="hljs-built_in">float</span>().masked_fill_(mask1, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>))<br>    <span class="hljs-comment">#mask2 : batch_size,seq_len2</span><br>    mask2 = mask2.<span class="hljs-built_in">float</span>().masked_fill_(mask2, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>))<br><br>    <span class="hljs-comment"># weight: batch_size * seq_len_1 * seq_len_2</span><br>    weight1 = F.softmax(attention_weight + mask2.unsqueeze(<span class="hljs-number">1</span>), dim=-<span class="hljs-number">1</span>)<br>    <span class="hljs-comment">#batch_size*seq_len_1*hidden_size</span><br>    x1_align = torch.matmul(weight1, x2)<br>    <br>    <span class="hljs-comment">#同理，需要对attention_weight进行permute操作</span><br>    weight2 = F.softmax(attention_weight.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) + mask1.unsqueeze(<span class="hljs-number">1</span>), dim=-<span class="hljs-number">1</span>)<br>    x2_align = torch.matmul(weight2, x1)<br></code></pre></td></tr></table></figure>

<h5 id="Pooling实现"><a href="#Pooling实现" class="headerlink" title="Pooling实现"></a>Pooling实现</h5><p>池化的过程有一个<code>窗口</code>的概念在其中，所以max 或者是average指的是窗口中的值取最大值还是取平均估值。整个过程可以理解为拿着窗口在源数据上取值</p>
<p>窗口有窗口大小(kernel_size，窗口多大)和步长(stride，每次移动多少)两个概念</p>
<ul>
<li>&#96;&#96;&#96;python<blockquote>
<blockquote>
<blockquote>
<p>input &#x3D; torch.tensor([[[1,2,3,4,5,6,7]]])<br>F.avg_pool1d(input, kernel_size&#x3D;3, stride&#x3D;2)<br>tensor([[[ 2.,  4.,  6.]]]) #[1,2,3] [3,4,5] [5,6,7]的平均估值</p>
</blockquote>
</blockquote>
</blockquote>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs llvm"><br>![](<span class="hljs-variable">%E6</span><span class="hljs-variable">%B7</span><span class="hljs-variable">%B1</span><span class="hljs-variable">%E5</span><span class="hljs-variable">%BA</span><span class="hljs-variable">%A6</span><span class="hljs-variable">%E5</span><span class="hljs-variable">%AD</span><span class="hljs-variable">%A6</span><span class="hljs-variable">%E4</span><span class="hljs-variable">%B9</span><span class="hljs-variable">%A0</span>/pooling.png)<br><br>```python<br>def apply_pooling(self<span class="hljs-punctuation">,</span> <span class="hljs-keyword">x</span>):<br>    # input: batch_size * seq_len * (<span class="hljs-number">2</span> * hidden_size)<br>    #进行平均池化<br>    p<span class="hljs-number">1</span> <span class="hljs-operator">=</span> F.avg_pool<span class="hljs-number">1</span>d(<span class="hljs-keyword">x</span>.transpose(<span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span>)<span class="hljs-punctuation">,</span> <span class="hljs-keyword">x</span>.size(<span class="hljs-number">1</span>)).squeeze(<span class="hljs-number">-1</span>)<br>    #进行最大池化<br>    p<span class="hljs-number">2</span> <span class="hljs-operator">=</span> F.max_pool<span class="hljs-number">1</span>d(<span class="hljs-keyword">x</span>.transpose(<span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span>)<span class="hljs-punctuation">,</span> <span class="hljs-keyword">x</span>.size(<span class="hljs-number">1</span>)).squeeze(<span class="hljs-number">-1</span>)<br>    # output: batch_size * (<span class="hljs-number">4</span> * hidden_size)<br>    return torch.cat([p<span class="hljs-number">1</span><span class="hljs-punctuation">,</span> p<span class="hljs-number">2</span>]<span class="hljs-punctuation">,</span> <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure></li>
</ul>
<h5 id="3-2-2-相似度计算部分"><a href="#3-2-2-相似度计算部分" class="headerlink" title="3.2.2 相似度计算部分"></a>3.2.2 相似度计算部分</h5><p>相似度的计算我们可以使用一个传统的距离计算公式，或者是exp的方法来实现，但是其效果不一定好，所以这里我们使用一个深层的神经网络来实现，使用pytorch中的Sequential对象来实现非常简单</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">self.fc = nn.Sequential(<br>    nn.BatchNorm1d(self.hidden_size * <span class="hljs-number">8</span>),<br>    <br>    nn.Linear(self.hidden_size * <span class="hljs-number">8</span>, self.linear_size),<br>    nn.ELU(inplace=<span class="hljs-literal">True</span>),<br>    nn.BatchNorm1d(self.linear_size),<br>    nn.Dropout(self.dropout),<br>    <br>    nn.Linear(self.linear_size, self.linear_size),<br>    nn.ELU(inplace=<span class="hljs-literal">True</span>),<br>    nn.BatchNorm1d(self.linear_size),<br>    nn.Dropout(self.dropout),<br>    <br>    nn.Linear(self.linear_size, <span class="hljs-number">2</span>),<br>    nn.Softmax(dim=-<span class="hljs-number">1</span>)<br>)<br></code></pre></td></tr></table></figure>

<p>在上述过程中，我们使用了激活函数ELU，而没有使用RELU，因为在有噪声的数据中ELU的效果往往会更好。</p>
<p>$ELU(<em>x</em>)&#x3D;max(0,x)+min(0,α∗(exp(x)−1))$,其中$\alpha$在torch中默认值为1。</p>
<p>通过下图可以看出他和RELU的区别，RELU在小于0的位置全部为0,但是ELU在小于零的位置是从0到-1的。可以理解为正常的数据汇总难免出现噪声，小于0的值，而RELU会直接把他处理为0，认为其实正常值，但是ELU却会保留他，所以ELU比RELU更有鲁棒性</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/elu.png" srcset="/img/loading.gif" lazyload></p>
<h5 id="3-2-3-损失函数部分"><a href="#3-2-3-损失函数部分" class="headerlink" title="3.2.3 损失函数部分"></a>3.2.3 损失函数部分</h5><p>在孪生神经网络中我们经常会使用对比损失（Contrastive Loss），作为损失函数，对比损失是<code>Yann LeCun</code>提出的用来判断数据降维之后和源数据是否相似的问题。在这里我们用它来判断两个句子的表示是否相似。</p>
<p>对比损失的计算公式如下：<br>$$<br>L &#x3D; \frac{1}{2N}\sum^N_{n&#x3D;1}(yd^2 + (1-y)max(margin-d,0)^2)<br>$$<br>其中$d &#x3D; ||a_n-b_n||_2$,代表两个两本特征的欧氏距离，y表示是否匹配，y&#x3D;1表示匹配，y&#x3D;0表示不匹配，margin是一个阈值，比如margin&#x3D;1。</p>
<p>上式可分为两个部分，即：</p>
<ol>
<li>y &#x3D; 1时，只剩下左边，$\sum yd^2$，即相似的样本，如果距离太大，则效果不好，损失变大</li>
<li>y&#x3D;0的时候，只剩下右边部分，即样本不相似的时候，如果距离小的话，效果反而不好，损失变大</li>
</ol>
<p>下图红色是相似样本的损失，蓝色是不相似样本的损失</p>
<p><img src="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1.png" srcset="/img/loading.gif" lazyload></p>
<p>但是前面我们已经计算出了相似度，所以在这里我们有两个操作</p>
<ol>
<li>使用前面的相似度的结果，把整个问题转化为分类（相似，不相似）的问题，或者是转化为回归问题（相似度是多少）</li>
<li>不是用前面相似度的计算结果部分，只用编码之后的结果，然后使用对比损失。最后在获取距离的时候使用欧氏距离来计算器相似度</li>
</ol>
<h5 id="使用DNN-均方误差来计算得到结果"><a href="#使用DNN-均方误差来计算得到结果" class="headerlink" title="使用DNN+均方误差来计算得到结果"></a>使用DNN+均方误差来计算得到结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model,optimizer,loss_func,epoch</span>):<br>    model.tarin()<br>        <span class="hljs-keyword">for</span> batch_idx, (q,simq,q_len,simq_len,sim) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>            optimizer.zero_grad()<br>        	output = model(q.to(config.device),simq.to(config.device))<br>            loss = loss_func(output,sim.to(config.deivce))<br>            loss.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">if</span> batch_idx%<span class="hljs-number">100</span>==<span class="hljs-number">0</span>:<br>            	<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;...&quot;</span>)<br>            	torch.save(model.state_dict(), <span class="hljs-string">&#x27;./DNN/data/model_paramters.pkl&#x27;</span>)<br>                torch.save(optimizer.state_dict(),<span class="hljs-string">&quot;./DNN/data/optimizer_paramters.pkl&quot;</span>)<br><br>            <br>model = SiameseNetwork().cuda()<br>loss =  torch.nn.MSELoss()<br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,config.epoch+<span class="hljs-number">1</span>):<br>    train(model,optimizer,loss,epoch)<br></code></pre></td></tr></table></figure>

<h4 id="使用对比损失来计算得到结果"><a href="#使用对比损失来计算得到结果" class="headerlink" title="使用对比损失来计算得到结果"></a>使用对比损失来计算得到结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#contrastive_loss.py</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ContrastiveLoss</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Contrastive loss function.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, margin=<span class="hljs-number">1.0</span></span>):<br>        <span class="hljs-built_in">super</span>(ContrastiveLoss, self).__init__()<br>        self.margin = margin<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x0, x1, y</span>):<br>        <span class="hljs-comment"># 欧式距离</span><br>        diff = x0 - x1<br>        dist_sq = torch.<span class="hljs-built_in">sum</span>(torch.<span class="hljs-built_in">pow</span>(diff, <span class="hljs-number">2</span>), <span class="hljs-number">1</span>)<br>        dist = torch.sqrt(dist_sq)<br><br>        mdist = self.margin - dist<br>        <span class="hljs-comment">#clamp(input,min,max),和numpy中裁剪的效果相同</span><br>        dist = torch.clamp(mdist, <span class="hljs-built_in">min</span>=<span class="hljs-number">0.0</span>)<br>        loss = y * dist_sq + (<span class="hljs-number">1</span> - y) * torch.<span class="hljs-built_in">pow</span>(dist, <span class="hljs-number">2</span>)<br>        loss = torch.<span class="hljs-built_in">sum</span>(loss) / <span class="hljs-number">2.0</span> / x0.size()[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure>

<p>之后只需要把原来的损失函数改为当前的损失函数即可</p>
<h3 id="3-3-不同模型的结果对比"><a href="#3-3-不同模型的结果对比" class="headerlink" title="3.3 不同模型的结果对比"></a>3.3 不同模型的结果对比</h3><h1 id="代码封装和对外提供接口"><a href="#代码封装和对外提供接口" class="headerlink" title="代码封装和对外提供接口"></a>代码封装和对外提供接口</h1><h2 id="目标-30"><a href="#目标-30" class="headerlink" title="目标"></a>目标</h2><ol>
<li>能够完成封装的代码</li>
<li>能够使用grpc对外提供接口</li>
<li>能够使用supervisord完成服务的管理</li>
</ol>
<h2 id="1-完成代码的封装"><a href="#1-完成代码的封装" class="headerlink" title="1. 完成代码的封装"></a>1. 完成代码的封装</h2><p>代码封装过程中，需要注意，在整个结构中，我们有很多的结算结果是dump到本地的，为了防止后续每次的重复计算。所以laod的结果，应该提前加载到内容，而不是每次调用load义词</p>
<h3 id="1-1-完成意图识别代码封装"><a href="#1-1-完成意图识别代码封装" class="headerlink" title="1.1 完成意图识别代码封装"></a>1.1 完成意图识别代码封装</h3><p>完成判断用户意图的代码，即在使用fasttext的模型，判断用户输入句子的分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> fastText<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> jieba_cut<br><br>fc_word_mode = fastText.load_model(<span class="hljs-string">&quot;./classify/data/ft_classify.model&quot;</span>)<br>fc_word_mode = fastText.load_model(<span class="hljs-string">&quot;./classify/data/ft_classify_words.model&quot;</span>)<br><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">is_QA</span>(<span class="hljs-params">sentence_info</span>):<br>    python_qs_list = [<span class="hljs-string">&quot; &quot;</span>.join(sentence_info[<span class="hljs-string">&quot;cuted_sentence&quot;</span>])]<br>    result = fc_word_mode.predict(python_qs_list)<br>	<br>    python_qs_list = [<span class="hljs-string">&quot; &quot;</span>.join(sentence_info[<span class="hljs-string">&quot;cuted_word_sentence&quot;</span>])]<br>    words_result = fc_word_mode.predict(python_qs_list)<br>    <span class="hljs-keyword">for</span> index, (label,acc,word_label,word_acc) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(*result,*words_result)):<br>        label = label[<span class="hljs-number">0</span>]<br>        acc = acc[<span class="hljs-number">0</span>]<br>        word_label = word_label[<span class="hljs-number">0</span>]<br>        word_acc = word_acc[<span class="hljs-number">0</span>]<br>        <span class="hljs-comment">#以label_qa为准，如果预测结果是label_chat，则label_qa的概率=1-labele_chat</span><br>        <span class="hljs-keyword">if</span> label == <span class="hljs-string">&quot;__label__chat&quot;</span>:<br>            label = <span class="hljs-string">&quot;__label__QA&quot;</span><br>            acc = <span class="hljs-number">1</span>-acc<br>        <span class="hljs-keyword">if</span> word_label == <span class="hljs-string">&quot;__label__chat&quot;</span>:<br>            word_label = <span class="hljs-string">&quot;__label__QA&quot;</span><br>            word_acc = <span class="hljs-number">1</span> - word_acc<br>        <span class="hljs-keyword">if</span> acc&gt;<span class="hljs-number">0.95</span> <span class="hljs-keyword">or</span> word_acc&gt;<span class="hljs-number">0.95</span>:<br>            <span class="hljs-comment">#是QA</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure>

<h3 id="1-2-完成对chatbot代码的封装"><a href="#1-2-完成对chatbot代码的封装" class="headerlink" title="1.2 完成对chatbot代码的封装"></a>1.2 完成对chatbot代码的封装</h3><p>提供predict的接口</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">准备闲聊的模型</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> jieba_cut<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> chatbot <span class="hljs-keyword">import</span> Sequence2Sequence<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Chatbot</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,ws_path=<span class="hljs-string">&quot;./chatbot/data/ws.pkl&quot;</span>,save_path=<span class="hljs-string">&quot;./chatbot/model/seq2seq_chatbot.ckpt&quot;</span></span>):<br>        self.ws_chatbot = pickle.load(<span class="hljs-built_in">open</span>(ws_path, <span class="hljs-string">&quot;rb&quot;</span>))<br>        self.save_path = save_path<br>		<span class="hljs-comment">#TODO .....</span><br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,s</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param s:没有分词的</span><br><span class="hljs-string">        :param ws:</span><br><span class="hljs-string">        :param ws_words:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">#TODO ...</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure>

<h3 id="1-3-完成对问答系统召回的封装"><a href="#1-3-完成对问答系统召回的封装" class="headerlink" title="1.3 完成对问答系统召回的封装"></a>1.3 完成对问答系统召回的封装</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">进行召回的方法</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pickle<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Recall</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,topk=<span class="hljs-number">20</span></span>):<br>        <span class="hljs-comment"># 准备问答的mode等模块</span><br>        self.topk = topk<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,sentence</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param sentence:</span><br><span class="hljs-string">        :param debug:</span><br><span class="hljs-string">        :return: [recall list],[entity]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">#TODO recall</span><br>        <span class="hljs-keyword">return</span> recall_list<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_answer</span>(<span class="hljs-params">self,s</span>):<br>        <span class="hljs-keyword">return</span> self.QA_dict[s]<br><br></code></pre></td></tr></table></figure>

<h3 id="1-4-完成对问答排序模型的封装"><a href="#1-4-完成对问答排序模型的封装" class="headerlink" title="1.4 完成对问答排序模型的封装"></a>1.4 完成对问答排序模型的封装</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">深度学习排序</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">from</span> DNN2 <span class="hljs-keyword">import</span> SiamsesNetwork<br><span class="hljs-keyword">from</span> lib <span class="hljs-keyword">import</span> jieba_cut<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DNNSort</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment">#使用词语和单字两个模型的均值作为最后的结果</span><br>        self.dnn_sort_words = DNNSortWords()<br>        self.dnn_sort_single_word = DNNSortSingleWord()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,s,c_list</span>):<br>        sort1 = self.dnn_sort_words.predict(s,c_list)<br>        sort2 = self.dnn_sort_single_word.predict(s,c_list)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sort1:<br>            sort1[i] = (sort1[i]+ sort2[i])/<span class="hljs-number">2</span><br>        sorts = <span class="hljs-built_in">sorted</span>(sort1.items(),key=<span class="hljs-keyword">lambda</span> x:x[-<span class="hljs-number">1</span>],reverse=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> sorts[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>],sorts[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DNNSortWords</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,ws_path=<span class="hljs-string">&quot;./DNN2/data/ws_80000.pkl&quot;</span>,save_path=<span class="hljs-string">&quot;./DNN2/model_keras/esim_model_softmax.ckpt&quot;</span></span>):<br>        self.ws = pickle.load(<span class="hljs-built_in">open</span>(ws_path, <span class="hljs-string">&quot;rb&quot;</span>))<br>        self.save_path = save_path<br>		<span class="hljs-comment">#TOOD ...</span><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,s,c_list</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param s:没有分词的</span><br><span class="hljs-string">        :param c_list: 带比较的列表</span><br><span class="hljs-string">        :param ws:</span><br><span class="hljs-string">        :param ws_words:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment">#TOOD ...</span><br>        <span class="hljs-keyword">return</span> sim_dict<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DNNSortSingleWord</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,ws_path=<span class="hljs-string">&quot;./DNN2/data/ws_word.pkl&quot;</span>,save_path=<span class="hljs-string">&quot;./DNN2/data/esim_word_model_softmax.ckpt&quot;</span></span>):<br>        self.ws = pickle.load(<span class="hljs-built_in">open</span>(ws_path, <span class="hljs-string">&quot;rb&quot;</span>))<br>        self.save_path = save_path<br>        <span class="hljs-comment">#TOOD ...</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,s,c_list</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :param s:没有分词的</span><br><span class="hljs-string">        :param c_list: 带比较的列表</span><br><span class="hljs-string">        :param ws:</span><br><span class="hljs-string">        :param ws_words:</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>		<span class="hljs-comment">#TOOD ...</span><br>        <span class="hljs-keyword">return</span> sim_dict<br></code></pre></td></tr></table></figure>

<h3 id="1-5-实现对聊天记录的保存"><a href="#1-5-实现对聊天记录的保存" class="headerlink" title="1.5 实现对聊天记录的保存"></a>1.5 实现对聊天记录的保存</h3><p>不同的用户，连续10分钟内的对话认为是一轮对话，如果10分还没有下一次对话，认为该轮对话结束，如果10分钟后开始对话，认为是下一轮对话。是要是为了保存不同轮中的聊天主题，后续可以实现基本的对话管理。比如用户刚问了python相关的问题，后续如果问题中不带主体，那么就把redis中的python作为其主体</p>
<p>主要实现逻辑为：</p>
<ol>
<li>使用redis存储用户基本的数据</li>
<li>使用mongodb存储对话记录</li>
</ol>
<p>具体思路如下：</p>
<ol>
<li>根据用户id，获取对话id，根据对话id判断当前的对话是否存在</li>
<li>如果对话id存在：<ol>
<li>更新对话的entity，上一次对话的时间，设置对话id的过期时间</li>
<li>保存数据到mongodb</li>
</ol>
</li>
<li>如果对话id不存在：<ol>
<li>创建用户的基础信息（user_id,entity,对话时间）</li>
<li>把用户的基础信息存入redis，同时设置对话id和过期时间</li>
<li>保存数据到mongodb中</li>
</ol>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">获取，更新用户的信息</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> pymongo <span class="hljs-keyword">import</span> MongoClient<br><span class="hljs-keyword">import</span> redis<br><span class="hljs-keyword">from</span> uuid <span class="hljs-keyword">import</span> uuid1<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">### redis</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">user_id:&quot;id&quot;,</span><br><span class="hljs-string">user_background:&#123;&#125;</span><br><span class="hljs-string">last_entity:[]</span><br><span class="hljs-string">last_conversation_time:int(time):</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">userid_conversation_id:&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">### monodb 存储对话记录</span><br><span class="hljs-string">&#123;user_id:,conversion_id:,from:user/bot,message:&quot;&quot;,create_time,entity:[],attention:[]&#125;</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>HOST = <span class="hljs-string">&quot;localhost&quot;</span><br>CNVERSION_EXPERID_TIME = <span class="hljs-number">60</span> * <span class="hljs-number">10</span>  <span class="hljs-comment"># 10分钟，连续10分钟没有通信，意味着会话结束</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MessageManager</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.client = MongoClient(host=HOST)<br>        self.m = self.client[<span class="hljs-string">&quot;toutiao&quot;</span>][<span class="hljs-string">&quot;dialogue&quot;</span>]<br>        self.r = redis.Redis(host=HOST, port=<span class="hljs-number">6379</span>, db=<span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">last_entity</span>(<span class="hljs-params">self, user_id</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;最近一次的entity&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> json.loads(self.r.hget(user_id, <span class="hljs-string">&quot;entity&quot;</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">gen_conversation_id</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> uuid1().<span class="hljs-built_in">hex</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">bot_message_pipeline</span>(<span class="hljs-params">self, user_id, message</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;保存机器人的回复记录&quot;&quot;&quot;</span><br>        conversation_id_key = <span class="hljs-string">&quot;&#123;&#125;_conversion_id&quot;</span>.<span class="hljs-built_in">format</span>(user_id)<br>        conversation_id = self.user_exist(conversation_id_key)<br>        <span class="hljs-keyword">if</span> conversation_id:<br>            <span class="hljs-comment"># 更新conversation_id的过期时间</span><br>            self.r.expire(conversation_id_key, CNVERSION_EXPERID_TIME)<br>            data = &#123;<span class="hljs-string">&quot;user_id&quot;</span>: user_id,<br>                    <span class="hljs-string">&quot;conversation_id&quot;</span>: conversation_id,<br>                    <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-string">&quot;bot&quot;</span>,<br>                    <span class="hljs-string">&quot;message&quot;</span>: message,<br>                    <span class="hljs-string">&quot;create_time&quot;</span>: <span class="hljs-built_in">int</span>(time.time()),<br>                    &#125;<br>            self.m.save(data)<br><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;没有会话id，但是机器人尝试回复....&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">user_message_pipeline</span>(<span class="hljs-params">self, user_id, message, create_time, attention, entity=[]</span>):<br>        <span class="hljs-comment"># 确定用户相关的信息</span><br>        <span class="hljs-comment"># 1. 用户是否存在</span><br>        <span class="hljs-comment"># 2.1 用户存在，返回用户的最近的entity，存入最近的对话</span><br>        <span class="hljs-comment"># 3.1 判断是否为新的对话，如果是新对话，开启新的回话，update用户的对话信息</span><br>        <span class="hljs-comment"># 3.2 如果不是新的对话，update用户的对话信息</span><br>        <span class="hljs-comment"># 3. 更新用户的基本信息</span><br>        <span class="hljs-comment"># 4  返回用户相关信息</span><br>        <span class="hljs-comment"># 5. 调用预测接口，发来对话的结构</span><br><br>        <span class="hljs-comment"># 要保存的data数据，缺少conversation_id</span><br>        data = &#123;<br>            <span class="hljs-string">&quot;user_id&quot;</span>: user_id,<br>            <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>            <span class="hljs-string">&quot;message&quot;</span>: message,<br>            <span class="hljs-string">&quot;create_time&quot;</span>: create_time,<br>            <span class="hljs-string">&quot;entity&quot;</span>: json.dumps(entity),<br>            <span class="hljs-string">&quot;attention&quot;</span>: attention,<br>        &#125;<br><br>        conversation_id_key = <span class="hljs-string">&quot;&#123;&#125;_conversion_id&quot;</span>.<span class="hljs-built_in">format</span>(user_id)<br>        conversation_id = self.user_exist(conversation_id_key)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;conversation_id&quot;</span>,conversation_id)<br>        <span class="hljs-keyword">if</span> conversation_id:<br>            <span class="hljs-keyword">if</span> entity:<br>                <span class="hljs-comment"># 更新当前用户的 last_entity</span><br>                self.r.hset(user_id, <span class="hljs-string">&quot;last_entity&quot;</span>, json.dumps(entity))<br>            <span class="hljs-comment"># 更新最后的对话时间</span><br>            self.r.hset(user_id, <span class="hljs-string">&quot;last_conversion_time&quot;</span>, create_time)<br>            <span class="hljs-comment"># 设置conversation id的过期时间</span><br>            self.r.expire(conversation_id_key, CNVERSION_EXPERID_TIME)<br><br>            <span class="hljs-comment"># 保存聊天记录到mongodb中</span><br>            data[<span class="hljs-string">&quot;conversation_id&quot;</span>] = conversation_id<br><br>            self.m.save(data)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mongodb 保存数据成功&quot;</span>)<br><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 不存在</span><br>            user_basic_info = &#123;<br>                <span class="hljs-string">&quot;user_id&quot;</span>: user_id,<br>                <span class="hljs-string">&quot;last_conversion_time&quot;</span>: create_time,<br>                <span class="hljs-string">&quot;last_entity&quot;</span>: json.dumps(entity)<br>            &#125;<br>            self.r.hmset(user_id, user_basic_info)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;redis存入 user_basic_info success&quot;</span>)<br>            conversation_id = self.gen_conversation_id()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;生成conversation_id&quot;</span>,conversation_id)<br><br>            <span class="hljs-comment"># 设置会话的id</span><br>            self.r.<span class="hljs-built_in">set</span>(conversation_id_key, conversation_id, ex=CNVERSION_EXPERID_TIME)<br>            <span class="hljs-comment"># 保存聊天记录到mongodb中</span><br>            data[<span class="hljs-string">&quot;conversation_id&quot;</span>] = conversation_id<br>            self.m.save(data)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mongodb 保存数据成功&quot;</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">user_exist</span>(<span class="hljs-params">self, conversation_id_key</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        判断用户是否存在</span><br><span class="hljs-string">        :param user_id:用户id</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        conversation_id = self.r.get(conversation_id_key)<br>        <span class="hljs-keyword">if</span> conversation_id:<br>            conversation_id = conversation_id.decode()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;load conversation_id&quot;</span>,conversation_id)<br>        <span class="hljs-keyword">return</span> conversation_id<br><br></code></pre></td></tr></table></figure>



<h2 id="2-使用GRPC对外提供服务"><a href="#2-使用GRPC对外提供服务" class="headerlink" title="2. 使用GRPC对外提供服务"></a>2. 使用GRPC对外提供服务</h2><h3 id="2-1-安装grpc相关环境"><a href="#2-1-安装grpc相关环境" class="headerlink" title="2.1 安装grpc相关环境"></a>2.1 安装grpc相关环境</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">gRPC 的安装：`pip install grpcio`<br>安装 ProtoBuf 相关的 python 依赖库：`pip install protobuf`<br>安装 python grpc 的 protobuf 编译工具：`pip install grpcio-tools`<br></code></pre></td></tr></table></figure>

<h3 id="2-2-定义GRPC的接口"><a href="#2-2-定义GRPC的接口" class="headerlink" title="2.2 定义GRPC的接口"></a>2.2 定义GRPC的接口</h3><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-comment">//chatbot.proto 文件</span><br>syntax = <span class="hljs-string">&quot;proto3&quot;</span>;<br><br><span class="hljs-keyword">message </span><span class="hljs-title class_">ReceivedMessage</span> &#123;<br>    <span class="hljs-type">string</span> user_id = <span class="hljs-number">1</span>; <span class="hljs-comment">//用户id</span><br>    <span class="hljs-type">string</span> user_message = <span class="hljs-number">2</span>; <span class="hljs-comment">//当前用户传递的消息</span><br>    <span class="hljs-type">int32</span> create_time = <span class="hljs-number">3</span>; <span class="hljs-comment">//当前消息发送的时间</span><br>&#125;<br><br><span class="hljs-keyword">message </span><span class="hljs-title class_">ResponsedMessage</span> &#123;<br>    <span class="hljs-type">string</span> user_response = <span class="hljs-number">1</span>; <span class="hljs-comment">//返回给用户的消息</span><br>    <span class="hljs-type">int32</span> create_time = <span class="hljs-number">2</span>; <span class="hljs-comment">//返回给用户的时间</span><br>&#125;<br><br><span class="hljs-keyword">service </span><span class="hljs-title class_">ChatBotService</span> &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> Chatbot (ReceivedMessage) <span class="hljs-keyword">returns</span> (ResponsedMessage)</span>;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-3-编译生成protobuf文件"><a href="#2-3-编译生成protobuf文件" class="headerlink" title="2.3 编译生成protobuf文件"></a>2.3 编译生成protobuf文件</h3><p>使用下面的命令编译，得到<code>chatbot_pb2.py</code>和<code>chatbot_pb2_grpc.py</code>文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">python -m grpc_tools.protoc -I. –python_out=. –grpc_python_out=. ./chatbot.proto<br></code></pre></td></tr></table></figure>

<h3 id="2-4-使用grpc提供服务"><a href="#2-4-使用grpc提供服务" class="headerlink" title="2.4 使用grpc提供服务"></a>2.4 使用grpc提供服务</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> dialogue<br><span class="hljs-keyword">from</span> classify <span class="hljs-keyword">import</span> is_QA<br><span class="hljs-keyword">from</span> dialogue.process_sentence <span class="hljs-keyword">import</span> process_user_sentence<br><br><span class="hljs-keyword">from</span> chatbot_grpc <span class="hljs-keyword">import</span> chatbot_pb2_grpc<br><span class="hljs-keyword">from</span> chatbot_grpc <span class="hljs-keyword">import</span> chatbot_pb2<br><span class="hljs-keyword">import</span> time<br><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">chatServicer</span>(chatbot_pb2_grpc.ChatBotServiceServicer):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment">#提前加载各种模型</span><br>        self.recall = dialogue.Recall(topk=<span class="hljs-number">20</span>)<br>        self.dnnsort = dialogue.DNNSort()<br>        self.chatbot = dialogue.Chatbot()<br>        self.message_manager = dialogue.MessageManager()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Chatbot</span>(<span class="hljs-params">self, request, context</span>):<br>        user_id = request.user_id<br>        message = request.user_message<br>        create_time = request.create_time<br>        <span class="hljs-comment">#对用户的输出进行基础的处理，如分词</span><br>        message_info = process_user_sentence(message)<br>        <span class="hljs-keyword">if</span> is_QA(message_info):<br>            attention = <span class="hljs-string">&quot;QA&quot;</span><br>            <span class="hljs-comment">#实现对对话数据的保存</span><br>            self.message_manager.user_message_pipeline(user_id, message, create_time, attention, entity=message_info[<span class="hljs-string">&quot;entity&quot;</span>])<br>            recall_list,entity = self.recall.predict(message_info)<br>            line, score = self.dnnsort.predict(message,recall_list)<br>            <span class="hljs-keyword">if</span> score &gt; <span class="hljs-number">0.7</span>:<br>                ans = self.recall.get_answer(line)<br>                user_response = ans[<span class="hljs-string">&quot;ans&quot;</span>]<br><br>            <span class="hljs-keyword">else</span>:<br>                user_response = <span class="hljs-string">&quot;不好意思，这个问题我还没学习到...&quot;</span><br>        <span class="hljs-keyword">else</span>:<br>            attention = <span class="hljs-string">&quot;chat&quot;</span><br>            <span class="hljs-comment"># 实现对对话数据的保存</span><br>            self.message_manager.user_message_pipeline(user_id,message,create_time,attention,entity=message_info[<span class="hljs-string">&quot;entity&quot;</span>])<br>            user_response = self.chatbot.predict(message)<br><br>        self.message_manager.bot_message_pipeline(user_id,user_response)<br><br>        user_response = user_response<br>        create_time = <span class="hljs-built_in">int</span>(time.time())<br>        <span class="hljs-keyword">return</span> chatbot_pb2.ResponsedMessage(user_response=user_response,create_time=create_time)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">serve</span>():<br>    <span class="hljs-keyword">import</span> grpc<br>    <span class="hljs-keyword">from</span> concurrent <span class="hljs-keyword">import</span> futures<br>    <span class="hljs-comment"># 多线程服务器</span><br>    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="hljs-number">10</span>))<br>    <span class="hljs-comment"># 注册本地服务</span><br>    chatbot_pb2_grpc.add_ChatBotServiceServicer_to_server(chatServicer(), server)<br>    <span class="hljs-comment"># 监听端口</span><br>    server.add_insecure_port(<span class="hljs-string">&quot;[::]:9999&quot;</span>)<br>    <span class="hljs-comment"># 开始接收请求进行服务</span><br>    server.start()<br>    <span class="hljs-comment"># 使用 ctrl+c 可以退出服务</span><br>    <span class="hljs-keyword">try</span>:<br>        time.sleep(<span class="hljs-number">1000</span>)<br>    <span class="hljs-keyword">except</span> KeyboardInterrupt:<br>        server.stop(<span class="hljs-number">0</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    serve()<br></code></pre></td></tr></table></figure>

<h2 id="3-使用supervisor完成对服务的管理"><a href="#3-使用supervisor完成对服务的管理" class="headerlink" title="3. 使用supervisor完成对服务的管理"></a>3. 使用supervisor完成对服务的管理</h2><h3 id="3-1-编写简单的执行脚本"><a href="#3-1-编写简单的执行脚本" class="headerlink" title="3.1  编写简单的执行脚本"></a>3.1  编写简单的执行脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><br>cd `$dirname`|exit 0<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">source</span> activate ds</span><br>python grpc_predict.py<br></code></pre></td></tr></table></figure>

<p>添加可执行权限：<code>chmod +x 文件名</code></p>
<h3 id="3-2-安装、配置supervisor"><a href="#3-2-安装、配置supervisor" class="headerlink" title="3.2 安装、配置supervisor"></a>3.2 安装、配置supervisor</h3><p>supervisor现在的官方版本还是python2的，但是可以使用下面的命令安装python3版本</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">pip3 install git+https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/Supervisor/</span>supervisor    <br></code></pre></td></tr></table></figure>

<ol>
<li><p>完成supervisor的配置文件的编写，conf中使用分号作为注释符号</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell">;conf.d<br>[program:chat_service]<br><br>command=/root/chat_service/run.sh  ;执行的命令<br><br>stdout_logfile=/root/chat_service/log/out.log ;log的位置<br><br>stderr_logfile=/root/chat_service/log/error.log  ;错误log的位置<br><br>directory=/root/chat_service  ;路径<br><br>autostart=true  ;是否自动启动<br><br>autorestart=true  ;是否自动重启<br><br>startretries=10 ;失败的最大尝试次数<br></code></pre></td></tr></table></figure>
</li>
<li><p>在supervisor的基础配置中添加上述配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">;/etc/supervisord/supervisor.conf <br>[include]<br>files=/root/chat_service/conf.d<br></code></pre></td></tr></table></figure>
</li>
<li><p>运行supervisord</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">supervisord -c /etc/supervisord/supervisor.conf<br></code></pre></td></tr></table></figure></li>
</ol>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深度学习</div>
      <div>https://kblayt.github.io/2022/10/21/python/深度学习/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Kblayt</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年10月21日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/10/22/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/Git%E6%8F%90%E4%BA%A4%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/" title="Git提交项目笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Git提交项目笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/10/21/python/python%E5%9F%BA%E7%A1%80/" title="python基础">
                        <span class="hidden-mobile">python基础</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
